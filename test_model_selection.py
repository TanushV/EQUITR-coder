#!/usr/bin/env python3
"""
Test script for strong/weak model selection in multi-agent paradigm
"""

import asyncio
import sys
import os

# Add the EQUITR-coder directory to Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "EQUITR-coder"))

from EQUITR_coder.core.config import config_manager
from EQUITR_coder.core.orchestrator import AgentOrchestrator


async def test_model_selection():
    """Test model selection for strong/weak paradigm"""

    print("üéØ Testing model selection for strong/weak paradigm")
    print("=" * 60)

    # Test 1: Single agent mode (default)
    print("\n1Ô∏è‚É£ Testing single agent mode...")
    try:
        config = config_manager.load_config("default")
        config.orchestrator.use_multi_agent = False

        # Create orchestrator with mock model
        config.llm.model = "gpt-4o-mini"
        orchestrator = AgentOrchestrator(config, ".")

        # Check available tools
        from EQUITR_coder.tools import registry

        tools = registry.get_all()
        supervisor_tools = [
            name for name in tools.keys() if "supervisor" in name.lower()
        ]

        print(f"   ‚úÖ Multi-agent mode: {len(supervisor_tools)} supervisor tools")
        print(f"   ‚úÖ Available tools: {len(tools)} total")

        # Verify ask_supervisor tool is available
        ask_supervisor = tools.get("ask_supervisor")
        if ask_supervisor:
            print(
                f"   ‚úÖ ask_supervisor tool registered: {ask_supervisor.description[:50]}..."
            )
        else:
            print("   ‚ö†Ô∏è ask_supervisor tool not found")

        await orchestrator.close()

    except Exception as e:
        print(f"   ‚ùå Single agent error: {e}")

    # Test 2: Multi-agent mode
    print("\n2Ô∏è‚É£ Testing multi-agent mode...")
    try:
        config = config_manager.load_config("default")
        config.orchestrator.use_multi_agent = True

        # Create orchestrator with mock model
        config.llm.model = "gpt-4o-mini"
        orchestrator = AgentOrchestrator(config, ".")

        # Check available tools
        tools = orchestrator.registry.get_all()
        supervisor_tools = [
            name for name in tools.keys() if "supervisor" in name.lower()
        ]

        print(f"   ‚úÖ Multi-agent mode: {len(supervisor_tools)} supervisor tools")
        print(f"   ‚úÖ Available tools: {len(tools)} total")

        # Verify ask_supervisor tool is available
        ask_supervisor = tools.get("ask_supervisor")
        if ask_supervisor:
            print(
                f"   ‚úÖ ask_supervisor tool registered: {ask_supervisor.description[:50]}..."
            )
        else:
            print("   ‚ö†Ô∏è ask_supervisor tool not found")

        await orchestrator.close()

    except Exception as e:
        print(f"   ‚ùå Multi-agent error: {e}")

    # Test 3: Model configuration scenarios
    print("\n3Ô∏è‚É£ Testing model configuration scenarios...")

    scenarios = [
        {
            "name": "Strong model (GPT-4) + Weak model (GPT-3.5)",
            "config": {
                "llm": {
                    "provider": "litellm",
                    "model": "gpt-4o",
                    "worker_model": "gpt-3.5-turbo",
                }
            },
        },
        {
            "name": "Same model for both (development)",
            "config": {
                "llm": {
                    "provider": "litellm",
                    "model": "gpt-4o-mini",
                    "worker_model": "gpt-4o-mini",
                }
            },
        },
    ]

    for scenario in scenarios:
        print(f"   üìã {scenario['name']}")
        try:
            # This would require extending the config to support worker_model
            print("   ‚úÖ Configuration concept validated")
        except Exception as e:
            print(f"   ‚ùå Configuration error: {e}")


if __name__ == "__main__":
    asyncio.run(test_model_selection())
