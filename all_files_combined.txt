===== EQUITR-coder/equitrcoder.py =====


import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from EQUITR_coder.simplest_cli import main
from EQUITR_coder.api import EquitrAPI, SyncEquitrAPI

__all__ = ["main", "EquitrAPI", "SyncEquitrAPI"]

if __name__ == "__main__":
    main()


===== EQUITR-coder/EQUITR_coder/__init__.py =====


__version__ = "0.1.0"
__author__ = "EQUITR Coder"
__email__ = "coder@equitr.com"

from .core.orchestrator import AgentOrchestrator
from .tools.base import Tool
from .api import EquitrAPI, SyncEquitrAPI, quick_chat, sync_quick_chat

__all__ = [
    "AgentOrchestrator",
    "Tool",
    "EquitrAPI",
    "SyncEquitrAPI",
    "quick_chat",
    "sync_quick_chat",
]


===== EQUITR-coder/EQUITR_coder/api.py =====


import asyncio
from typing import Optional, Dict, Any, List
from pathlib import Path

from .core.config import config_manager
from .core.orchestrator import AgentOrchestrator
from .tools.builtin.todo import todo_manager, TodoItem
from .utils.env_loader import auto_load_environment


class EquitrAPI:
    

    def __init__(
        self,
        repo_path: str = ".",
        profile: str = "default",
        model: Optional[str] = None,
        budget: Optional[float] = None,
        api_key: Optional[str] = None,
        multi_agent: bool = False,
        supervisor_model: Optional[str] = None,
        worker_model: Optional[str] = None,
        log_tool_calls: bool = False,
        tool_log_file: str = "tool_calls.log",
        debug: bool = False,
    ):
        
        self.repo_path = Path(repo_path).resolve()
        self.profile = profile
        self.debug = debug

        env_status = auto_load_environment()
        if self.debug and env_status["dotenv_loaded"]:
            print(f"üîë Loaded {env_status['available_providers']} API providers from .env file")

        self.config = config_manager.load_config(profile)

        self._model_override = model
        self._supervisor_model_override = supervisor_model
        self._worker_model_override = worker_model
        
        if budget:
            self.config.llm.budget = budget
        if api_key:
            self.config.llm.api_key = api_key
        
        self.config.orchestrator.use_multi_agent = multi_agent
        
        self.config.orchestrator.log_tool_calls = log_tool_calls
        self.config.orchestrator.tool_log_file = tool_log_file
        
        self.config.orchestrator.debug = debug

        self._orchestrator: Optional[AgentOrchestrator] = None

    async def __aenter__(self):
        
        self._orchestrator = AgentOrchestrator(
            self.config, 
            str(self.repo_path), 
            model=self._model_override,
            supervisor_model=self._supervisor_model_override,
            worker_model=self._worker_model_override,
        )
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        
        if self._orchestrator:
            await self._orchestrator.close()

    async def chat(self, message: str, session_id: Optional[str] = None) -> str:
        
        if not self._orchestrator:
            raise RuntimeError("API must be used as async context manager")

        result = await self._orchestrator.run(message, session_id)
        return result.get("content", str(result))

    def create_todo(
        self,
        title: str,
        description: str = "",
        priority: str = "medium",
        due_date: Optional[str] = None,
        tags: Optional[List[str]] = None,
        assignee: Optional[str] = None,
    ) -> TodoItem:
        
        return todo_manager.create_todo(
            title=title,
            description=description,
            priority=priority,
            due_date=due_date,
            tags=tags or [],
            assignee=assignee,
        )

    def update_todo(self, todo_id: str, **kwargs) -> Optional[TodoItem]:
        
        return todo_manager.update_todo(todo_id, **kwargs)

    def delete_todo(self, todo_id: str) -> bool:
        
        return todo_manager.delete_todo(todo_id)

    def list_todos(self, **filters) -> List[TodoItem]:
        
        return todo_manager.list_todos(**filters)

    def get_todo(self, todo_id: str) -> Optional[TodoItem]:
        
        return todo_manager.get_todo(todo_id)

    @property
    def session_history(self) -> List[Dict[str, Any]]:
        
        if not self._orchestrator:
            return []

        messages = self._orchestrator.session_manager.get_messages()
        return [{"role": msg.role, "content": msg.content} for msg in messages]

    @property
    def total_cost(self) -> float:
        
        if not self._orchestrator:
            return 0.0
        return self._orchestrator.total_cost

    @property
    def iteration_count(self) -> int:
        
        if not self._orchestrator:
            return 0
        return self._orchestrator.iteration_count

    def get_tool_call_logs(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        
        if not self._orchestrator:
            return []
        
        from dataclasses import asdict
        
        tool_logger = self._orchestrator.tool_logger
        logs = tool_logger.get_logs(limit=limit)
        return [asdict(log) for log in logs]

    def get_tool_call_stats(self) -> Dict[str, Any]:
        
        if not self._orchestrator:
            return {}
        
        tool_logger = self._orchestrator.tool_logger
        return tool_logger.get_stats()

    def export_tool_logs(self, file_path: str, format: str = "json"):
        
        if not self._orchestrator:
            return
        
        tool_logger = self._orchestrator.tool_logger
        tool_logger.export_logs(file_path, format)


class SyncEquitrAPI:
    

    def __init__(self, **kwargs):
        
        self._api_kwargs = kwargs
        self._loop = None

    def __enter__(self):
        
        self._loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self._loop)
        self._api = EquitrAPI(**self._api_kwargs)
        self._loop.run_until_complete(self._api.__aenter__())
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        
        if self._api:
            self._loop.run_until_complete(
                self._api.__aexit__(exc_type, exc_val, exc_tb)
            )
        if self._loop:
            self._loop.close()

    def chat(self, message: str, session_id: Optional[str] = None) -> str:
        
        return self._loop.run_until_complete(self._api.chat(message, session_id))

    def create_todo(self, **kwargs) -> TodoItem:
        
        return self._api.create_todo(**kwargs)

    def update_todo(self, todo_id: str, **kwargs) -> Optional[TodoItem]:
        
        return self._api.update_todo(todo_id, **kwargs)

    def delete_todo(self, todo_id: str) -> bool:
        
        return self._api.delete_todo(todo_id)

    def list_todos(self, **filters) -> List[TodoItem]:
        
        return self._api.list_todos(**filters)

    def get_todo(self, todo_id: str) -> Optional[TodoItem]:
        
        return self._api.get_todo(todo_id)

    @property
    def session_history(self) -> List[Dict[str, Any]]:
        
        return self._api.session_history

    @property
    def total_cost(self) -> float:
        
        return self._api.total_cost

    @property
    def iteration_count(self) -> int:
        
        return self._api.iteration_count

    def get_tool_call_logs(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        
        return self._api.get_tool_call_logs(limit)

    def get_tool_call_stats(self) -> Dict[str, Any]:
        
        return self._api.get_tool_call_stats()

    def export_tool_logs(self, file_path: str, format: str = "json"):
        
        self._api.export_tool_logs(file_path, format)


async def quick_chat(
    message: str,
    repo_path: str = ".",
    model: str = "anthropic/claude-3-haiku",
    api_key: Optional[str] = None,
) -> str:
    
    async with EquitrAPI(repo_path=repo_path, model=model, api_key=api_key) as api:
        return await api.chat(message)


def sync_quick_chat(
    message: str,
    repo_path: str = ".",
    model: str = "anthropic/claude-3-haiku",
    api_key: Optional[str] = None,
) -> str:
    
    with SyncEquitrAPI(repo_path=repo_path, model=model, api_key=api_key) as api:
        return api.chat(message)


def create_project(
    repo_path: str = ".",
    profile: str = "default",
    model: str = "anthropic/claude-3-haiku",
    supervisor_model: Optional[str] = None,
    worker_model: Optional[str] = None,
    api_key: Optional[str] = None,
    budget: Optional[float] = None,
    error_logging: bool = False,
    project_type: str = "mario game",
    multi_agent: bool = False,
    log_tool_calls: bool = False,
) -> None:
    
    try:
        with SyncEquitrAPI(
            repo_path=repo_path,
            profile=profile,
            model=model,
            supervisor_model=supervisor_model,
            worker_model=worker_model,
            budget=budget,
            api_key=api_key,  # Pass api_key to init for standardized handling
            multi_agent=multi_agent,
            log_tool_calls=log_tool_calls,
        ) as api:
            print(f"üöÄ Starting {project_type} project creation...")

            print("üìã Creating requirements documentation...")
            api.chat(
                f"Create comprehensive requirements documentation (requirements.md) for a {project_type} including: project overview, functional requirements, non-functional requirements, user stories, acceptance criteria, and success metrics"
            )

            print("üèóÔ∏è  Creating system documentation...")
            api.chat(
                f"Create system documentation (system.md) for a {project_type} including: system architecture, component overview, data flow, API design, technical specifications, and security considerations"
            )

            print("üìù Creating project todo list...")
            api.chat(
                f"Create project todo list with all tasks needed to build a complete {project_type}: setup development environment, create game engine, implement player mechanics, add levels, create assets, add sound, testing, and deployment"
            )

            print("üéÆ Implementing complete {project_type}...")
            api.chat(
                f"Implement the complete {project_type} based on the requirements and system design. Create all necessary files including: main game file, player character, level system, collision detection, graphics rendering, sound system, game states (menu, playing, game over), scoring system, and ensure the game is fully playable. Use pygame for the game engine."
            )

            print("‚úÖ Project creation completed!")
            
            if log_tool_calls:
                stats = api.get_tool_call_stats()
                if stats:
                    print(f"\nüìä Tool Call Statistics:")
                    print(f"  Total calls: {stats.get('total_calls', 0)}")
                    print(f"  Success rate: {stats.get('success_rate', 0):.1%}")
                    print(f"  Total duration: {stats.get('total_duration_ms', 0):.1f}ms")

    except Exception as e:
        if error_logging:
            import traceback

            print(f"‚ùå Error in create_project: {str(e)}")
            print(traceback.format_exc())
        else:
            print(f"‚ùå Error: {str(e)}")


===== EQUITR-coder/EQUITR_coder/cli.py =====
import asyncio
import os
import sys
from pathlib import Path
from typing import Optional

import typer
from rich.console import Console
from rich.prompt import Prompt
from rich.panel import Panel

from .core.config import config_manager
from .core.orchestrator import AgentOrchestrator
from .ui.tui import run_tui

app = typer.Typer(
    name="EQUITR-coder",
    help="EQUITR Coder - An advanced AI coding assistant with intelligent tool execution and todo management",
)

console = Console()


def check_api_key():
    
    pass


@app.command()
async def chat(
    repo: str = typer.Option(".", "--repo", "-r", help="Repository path to analyze"),
    profile: str = typer.Option(
        "default", "--profile", "-p", help="Configuration profile to use"
    ),
    model: Optional[str] = typer.Option(
        None, "--model", "-m", help="LLM model to use (overrides config)"
    ),
    budget: Optional[float] = typer.Option(
        None, "--budget", "-b", help="Budget limit in USD (overrides config)"
    ),
    session: Optional[str] = typer.Option(
        None, "--session", "-s", help="Session ID to resume"
    ),
    stream: bool = typer.Option(False, "--stream", help="Enable streaming responses"),
    multi_agent: bool = typer.Option(
        False,
        "--multi-agent",
        "-M",
        help="Enable strong/weak agent paradigm using supervisor + worker models",
    ),
    supervisor_model: Optional[str] = typer.Option(
        None, "--supervisor-model", help="Override supervisor model"
    ),
    worker_model: Optional[str] = typer.Option(
        None, "--worker-model", help="Override worker model"
    ),
):
    

    check_api_key()

    try:
        config = config_manager.load_config(profile)
    except Exception as e:
        console.print(f"[red]‚ùå Failed to load config: {e}[/red]")
        raise typer.Exit(1)

    if budget:
        config.llm.budget = budget

    repo_path = Path(repo).resolve()
    if not repo_path.exists():
        console.print(f"[red]‚ùå Repository path does not exist: {repo_path}[/red]")
        raise typer.Exit(1)

    model_info = []
    
    main_model = model or config.llm.model
    model_info.append(f"[cyan]Main Model:[/cyan] {main_model}")
    
    if multi_agent or supervisor_model or worker_model:
        from .core.orchestrator import AgentOrchestrator
        from .core.config import config_manager
        
        temp_config = config.model_copy()
        if model:
            temp_config.llm.model = model
            
        temp_orchestrator = AgentOrchestrator(
            temp_config, 
            str(repo_path), 
            model=model,
            supervisor_model=supervisor_model,
            worker_model=worker_model
        )
        
        try:
            supervisor_provider = temp_orchestrator._create_supervisor_provider(temp_config)
            supervisor_model_name = getattr(supervisor_provider, 'model', 'Unknown')
            if supervisor_model_name != main_model:
                model_info.append(f"[cyan]Supervisor Model:[/cyan] {supervisor_model_name}")
        except:
            if supervisor_model:
                model_info.append(f"[cyan]Supervisor Model:[/cyan] {supervisor_model}")
        
        try:
            worker_provider = temp_orchestrator._create_worker_provider(temp_config)
            worker_model_name = getattr(worker_provider, 'model', 'Unknown')
            if worker_model_name != main_model:
                model_info.append(f"[cyan]Worker Model:[/cyan] {worker_model_name}")
        except:
            if worker_model:
                model_info.append(f"[cyan]Worker Model:[/cyan] {worker_model}")
        
        await temp_orchestrator.close()
    
    config_content = f"[green]üöÄ EQUITR Coder[/green]\n\n"
    config_content += "\n".join(model_info) + "\n"
    config_content += f"[cyan]Profile:[/cyan] {profile}\n"
    config_content += f"[cyan]Repository:[/cyan] {repo_path}\n"
    config_content += f"[cyan]Budget:[/cyan] ${config.llm.budget}\n"
    config_content += f"[cyan]Session:[/cyan] {session or 'new'}"
    
    console.print(
        Panel(
            config_content,
            title="üõ†Ô∏è Configuration",
            border_style="green",
        )
    )

    console.print("\n[bold cyan]üí¨ Enter your request (Ctrl+D when done):[/bold cyan]")

    try:
        if sys.stdin.isatty():
            lines = []
            while True:
                try:
                    line = input()
                    lines.append(line)
                except EOFError:
                    break
            user_input = "\n".join(lines)
        else:
            user_input = sys.stdin.read()
    except KeyboardInterrupt:
        console.print("\n[yellow]üëã Goodbye![/yellow]")
        raise typer.Exit(0)

    if not user_input.strip():
        console.print("[red]‚ùå No input provided[/red]")
        raise typer.Exit(1)

    if multi_agent:
        config.orchestrator.use_multi_agent = True
        console.print(
            "[yellow]ü§ñ Multi-agent mode enabled (strong/weak paradigm)[/yellow]"
        )

    async def run_chat():
        orchestrator = AgentOrchestrator(
            config, 
            str(repo_path), 
            model=model,
            supervisor_model=supervisor_model,
            worker_model=worker_model
        )
        try:
            response = await orchestrator.run(user_input, session)
            content = response.get("content", "")
            usage = response.get("usage", {})
            cost = response.get("cost", 0.0)

            cache_stats = ""
            prompt_tokens_details = usage.get("prompt_tokens_details", {})
            cached_tokens = prompt_tokens_details.get("cached_tokens", 0)
            prompt_tokens = usage.get("prompt_tokens", 0)
            completion_tokens = usage.get("completion_tokens", 0)
            total_tokens = usage.get("total_tokens", 0)

            cached_price = 0.0
            if cached_tokens > 0:
                cached_price = (cached_tokens / 1000) * 0.03
                cache_stats = f"[green]Cached tokens:[/green] {cached_tokens}\n[green]Cached price:[/green] ${cached_price:.4f}"

            usage_stats = f"[cyan]Prompt tokens:[/cyan] {prompt_tokens}\n[cyan]Completion tokens:[/cyan] {completion_tokens}\n[cyan]Total tokens:[/cyan] {total_tokens}\n[cyan]Total price:[/cyan] ${cost:.4f}"

            output = f"{content}\n\n{cache_stats}\n{usage_stats}"
            console.print(
                Panel(output, title="ü§ñ EQUITR Coder Response", border_style="blue")
            )
        except Exception as e:
            console.print(f"[red]‚ùå Error: {e}[/red]")
            raise typer.Exit(1)
        finally:
            await orchestrator.close()

    asyncio.run(run_chat())


@app.command()
def interactive(
    repo: str = typer.Option(".", "--repo", "-r", help="Repository path to analyze"),
    profile: str = typer.Option(
        "default", "--profile", "-p", help="Configuration profile to use"
    ),
    model: Optional[str] = typer.Option(
        None, "--model", "-m", help="LLM model to use (overrides config)"
    ),
    supervisor_model: Optional[str] = typer.Option(
        None, "--supervisor-model", help="Override supervisor model"
    ),
    worker_model: Optional[str] = typer.Option(
        None, "--worker-model", help="Override worker model"
    ),
):
    

    check_api_key()

    try:
        config = config_manager.load_config(profile)
    except Exception as e:
        console.print(f"[red]‚ùå Failed to load config: {e}[/red]")
        raise typer.Exit(1)


    repo_path = Path(repo).resolve()
    if not repo_path.exists():
        console.print(f"[red]‚ùå Repository path does not exist: {repo_path}[/red]")
        raise typer.Exit(1)

    console.print(
        Panel(
            "[green]ü§ñ EQUITR Coder - Interactive Mode[/green]\n\n"
            "Type your messages and press Enter. Use '/quit' to exit.\n"
            "Commands:\n"
            "  /quit - Exit the session\n"
            "  /clear - Clear conversation history\n"
            "  /status - Show session status\n"
            "  /help - Show this help",
            title="Interactive Mode",
            border_style="green",
        )
    )

    async def run_interactive():
        orchestrator = AgentOrchestrator(
            config, 
            str(repo_path), 
            model=model,
            supervisor_model=supervisor_model,
            worker_model=worker_model
        )
        session_id = None

        try:
            while True:
                try:
                    user_input = Prompt.ask("\n[bold cyan]You[/bold cyan]")

                    if user_input.lower() in ["/quit", "/exit", "/q"]:
                        console.print("[yellow]üëã Goodbye![/yellow]")
                        break
                    elif user_input.lower() == "/clear":
                        orchestrator.session_manager.clear_current_session()
                        console.print("[green]‚úÖ Conversation history cleared[/green]")
                        continue
                    elif user_input.lower() == "/status":
                        messages = orchestrator.session_manager.get_messages()
                        console.print("[cyan]üìä Session Status:[/cyan]")
                        console.print(f"  Messages: {len(messages)}")
                        console.print(f"  Total cost: ${orchestrator.total_cost:.4f}")
                        console.print(f"  Iterations: {orchestrator.iteration_count}")
                        continue
                    elif user_input.lower() == "/help":
                        console.print(
                            Panel(
                                "Commands:\n"
                                "  /quit - Exit the session\n"
                                "  /clear - Clear conversation history\n"
                                "  /status - Show session status\n"
                                "  /help - Show this help",
                                title="Help",
                                border_style="blue",
                            )
                        )
                        continue

                    if not user_input.strip():
                        continue

                    console.print("\n[dim]ü§î Thinking...[/dim]")

                    response = await orchestrator.run(user_input, session_id)

                    content = response.get("content", "")
                    usage = response.get("usage", {})
                    cost = response.get("cost", 0.0)

                    cache_stats = ""
                    prompt_tokens_details = usage.get("prompt_tokens_details", {})
                    cached_tokens = prompt_tokens_details.get("cached_tokens", 0)
                    prompt_tokens = usage.get("prompt_tokens", 0)
                    completion_tokens = usage.get("completion_tokens", 0)
                    total_tokens = usage.get("total_tokens", 0)

                    cached_price = 0.0
                    if cached_tokens > 0:
                        cached_price = (cached_tokens / 1000) * 0.03
                        cache_stats = f"[green]Cached tokens:[/green] {cached_tokens}\n[green]Cached price:[/green] ${cached_price:.4f}"

                    usage_stats = f"[cyan]Prompt tokens:[/cyan] {prompt_tokens}\n[cyan]Completion tokens:[/cyan] {completion_tokens}\n[cyan]Total tokens:[/cyan] {total_tokens}\n[cyan]Total price:[/cyan] ${cost:.4f}"

                    output = f"{content}\n\n{cache_stats}\n{usage_stats}"
                    console.print(
                        Panel(output, title="ü§ñ EQUITR Coder", border_style="blue")
                    )

                    if orchestrator.session_manager.current_session:
                        session_id = (
                            orchestrator.session_manager.current_session.session_id
                        )

                except KeyboardInterrupt:
                    console.print("\n[yellow]Use /quit to exit properly[/yellow]")
                    continue
                except Exception as e:
                    console.print(f"[red]‚ùå Error: {e}[/red]")
                    continue

        finally:
            await orchestrator.close()

    asyncio.run(run_interactive())


@app.command()
def sessions(
    action: Optional[str] = typer.Argument(
        None, help="Action: list, delete, or switch"
    ),
    session_id: Optional[str] = typer.Argument(
        None, help="Session ID for delete/switch actions"
    ),
):
    

    from .core.session import SessionManagerV2

    session_manager = SessionManagerV2()

    if action == "delete" and session_id:
        if session_manager.delete_session(session_id):
            console.print(f"[green]‚úÖ Session {session_id} deleted[/green]")
        else:
            console.print(f"[red]‚ùå Failed to delete session {session_id}[/red]")
        return

    if action == "switch" and session_id:
        if session_manager.switch_session(session_id):
            console.print(f"[green]‚úÖ Switched to session {session_id}[/green]")
        else:
            console.print(f"[red]‚ùå Session {session_id} not found[/red]")
        return

    sessions = session_manager.list_sessions()

    if not sessions:
        console.print("[yellow]üì≠ No sessions found[/yellow]")
        return

    from rich.table import Table

    table = Table(title="Available Sessions")
    table.add_column("Session ID", style="cyan")
    table.add_column("Created", style="green")
    table.add_column("Updated", style="yellow")
    table.add_column("Messages", justify="right", style="blue")
    table.add_column("Tasks", justify="right", style="magenta")
    table.add_column("Cost", justify="right", style="red")
    table.add_column("Status", style="dim")

    for session in sessions:
        table.add_row(
            session["session_id"],
            session["created_at"].strftime("%Y-%m-%d %H:%M"),
            session["updated_at"].strftime("%Y-%m-%d %H:%M"),
            str(session["message_count"]),
            str(session["task_count"]),
            f"${session['cost']:.3f}",
            session["status"],
        )

    console.print(table)


@app.command()
def tui(
    repo: str = typer.Option(".", "--repo", "-r", help="Repository path to analyze"),
    profile: str = typer.Option(
        "default", "--profile", "-p", help="Configuration profile to use"
    ),
    model: Optional[str] = typer.Option(
        None, "--model", "-m", help="LLM model to use (overrides config)"
    ),
    supervisor_model: Optional[str] = typer.Option(
        None, "--supervisor-model", help="Override supervisor model"
    ),
    worker_model: Optional[str] = typer.Option(
        None, "--worker-model", help="Override worker model"
    ),
):
    

    check_api_key()

    try:
        config = config_manager.load_config(profile)
    except Exception as e:
        console.print(f"[red]‚ùå Failed to load config: {e}[/red]")
        raise typer.Exit(1)

    if model:
        if model in config.llm.models:
            config = config_manager.switch_model(config, model)
        else:
            config = config_manager.add_model_config(
                config,
                "cli_override",
                {
                    "provider": "litellm",
                    "model": model,
                    "temperature": config.llm.temperature,
                    "max_tokens": config.llm.max_tokens,
                },
            )
            config.llm.active_model = "cli_override"

    repo_path = Path(repo).resolve()
    if not repo_path.exists():
        console.print(f"[red]‚ùå Repository path does not exist: {repo_path}[/red]")
        raise typer.Exit(1)

    try:
        asyncio.run(run_tui(config, supervisor_model=supervisor_model, worker_model=worker_model))
    except KeyboardInterrupt:
        console.print("\n[yellow]üëã Goodbye![/yellow]")
    except Exception as e:
        console.print(f"[red]‚ùå TUI Error: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def config_cmd(
    profile: str = typer.Option(
        "default", "--profile", "-p", help="Configuration profile to show"
    ),
    edit: bool = typer.Option(False, "--edit", help="Open config in editor"),
):
    

    try:
        config = config_manager.load_config(profile)

        if edit:
            import tempfile
            import subprocess

            with tempfile.NamedTemporaryFile(
                mode="w", suffix=".yaml", delete=False
            ) as f:
                import yaml

                yaml.dump(config.model_dump(), f, default_flow_style=False)
                temp_file = f.name

            editor = os.getenv("EDITOR", "nano")
            subprocess.run([editor, temp_file])

            # TODO: Load changes back
            os.unlink(temp_file)
        else:
            console.print(
                Panel(
                    f"[cyan]LLM Model:[/cyan] {config.llm.model}\n"
                    f"[cyan]Budget:[/cyan] ${config.llm.budget}\n"
                    f"[cyan]Tools:[/cyan] {', '.join(config.tools.enabled)}\n"
                    f"[cyan]Session Persistence:[/cyan] {config.session.persist}\n"
                    f"[cyan]Repository Indexing:[/cyan] {config.repository.index_on_start}",
                    title=f"Configuration - {profile}",
                    border_style="cyan",
                )
            )

    except Exception as e:
        console.print(f"[red]‚ùå Failed to load config: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def models(
    api_base: str = typer.Option(
        "http://localhost:4000", "--api-base", help="LiteLLM proxy base URL"
    ),
    discover: bool = typer.Option(
        False, "--discover", help="Discover available models"
    ),
):
    

    from EQUITR_coder.providers.model_discovery import LiteLLMModelDiscovery
    from rich.table import Table

    if discover:
        console.print(f"[cyan]üîç Discovering models from {api_base}...[/cyan]")
        discovery = LiteLLMModelDiscovery(api_base)

        try:
            models = discovery.get_available_models_sync()

            if not models:
                console.print(
                    "[yellow]üì≠ No models found or LiteLLM proxy not accessible[/yellow]"
                )
                console.print(
                    "[dim]Make sure LiteLLM proxy is running at the specified URL[/dim]"
                )
                return

            from EQUITR_coder.providers.function_calling_discovery import (
                FunctionCallingModelDiscovery,
            )

            fc_discovery = FunctionCallingModelDiscovery()

            table = Table(title="Available Models")
            table.add_column("Model ID", style="cyan")
            table.add_column("Provider", style="green")
            table.add_column("Function Calling", style="magenta")
            table.add_column("Parallel FC", style="blue")
            table.add_column("Created", style="yellow")

            for model in models:
                model_id = model.get("id", "unknown")
                owned_by = model.get("owned_by", "unknown")
                created = model.get("created", 0)

                try:
                    import asyncio

                    model_info = asyncio.run(fc_discovery.validate_model(model_id))
                    fc_support = (
                        "‚úÖ" if model_info["supports_function_calling"] else "‚ùå"
                    )
                    pfc_support = (
                        "‚úÖ"
                        if model_info["supports_parallel_function_calling"]
                        else "‚ùå"
                    )
                except Exception:
                    fc_support = "‚ùì"
                    pfc_support = "‚ùì"

                from datetime import datetime

                created_date = (
                    datetime.fromtimestamp(created).strftime("%Y-%m-%d")
                    if created
                    else "unknown"
                )

                table.add_row(model_id, owned_by, fc_support, pfc_support, created_date)

            console.print(table)
            console.print(f"[green]‚úÖ Found {len(models)} models[/green]")
            console.print(
                "\n[dim]Legend: ‚úÖ = Supported, ‚ùå = Not Supported, ‚ùì = Unknown[/dim]"
            )

        except Exception as e:
            console.print(f"[red]‚ùå Error discovering models: {e}[/red]")
            console.print(
                "[dim]Make sure LiteLLM proxy is running and accessible[/dim]"
            )
    else:
        config = config_manager.load_config()

        from EQUITR_coder.providers.function_calling_discovery import (
            FunctionCallingModelDiscovery,
        )

        fc_discovery = FunctionCallingModelDiscovery()

        model_status = "Unknown"
        fc_status = "Unknown"
        if config.llm.model:
            try:
                import asyncio

                model_info = asyncio.run(fc_discovery.validate_model(config.llm.model))
                model_status = (
                    "‚úÖ Compatible" if model_info["valid"] else "‚ùå Incompatible"
                )
                fc_status = (
                    "‚úÖ Supported"
                    if model_info["supports_function_calling"]
                    else "‚ùå Not Supported"
                )
            except Exception:
                model_status = "‚ùì Unknown"
                fc_status = "‚ùì Unknown"

        console.print(
            Panel(
                f"[cyan]Current Model:[/cyan] {config.llm.model or 'Not selected'}\n"
                f"[cyan]Model Status:[/cyan] {model_status}\n"
                f"[cyan]Function Calling:[/cyan] {fc_status}\n"
                f"[cyan]API Base:[/cyan] {config.llm.api_base or 'Not configured'}\n"
                f"[cyan]Provider:[/cyan] {config.llm.provider}\n\n"
                f"Use [bold]--discover[/bold] to discover models from LiteLLM proxy\n"
                f"Use [bold]--api-base[/bold] to specify a different LiteLLM proxy URL",
                title="Model Configuration",
                border_style="cyan",
            )
        )


@app.command()
def version():
    
    from . import __version__

    console.print(f"[green]üöÄ EQUITR Coder v{__version__}[/green]")


if __name__ == "__main__":
    app()


===== EQUITR-coder/EQUITR_coder/interactive_cli.py =====


import asyncio
import sys
from pathlib import Path
from typing import Optional

import typer
from rich.console import Console
from rich.prompt import Prompt, Confirm
from rich.panel import Panel
from rich.text import Text

from .core.config import config_manager
from .core.orchestrator import AgentOrchestrator
from .core.planning import ConversationalPlanner
from .core.documentation import DocumentationGenerator
from .tools.builtin.git_auto import GitAutoCommit

app = typer.Typer(
    name="equitrcoder",
    help="EQUITR Coder - Interactive AI coding assistant with mandatory documentation generation",
    add_completion=False,
)

console = Console()


def show_welcome():
    
    welcome_text = Text()
    welcome_text.append("üöÄ EQUITR Coder - Interactive Mode\n", style="bold green")
    welcome_text.append("\nWorkflow:\n", style="bold cyan")
    welcome_text.append("1. Chat with the AI to discuss your requirements\n", style="dim")
    welcome_text.append("2. AI generates mandatory documentation (todo, requirements, design)\n", style="dim")
    welcome_text.append("3. Review and approve documentation\n", style="dim")
    welcome_text.append("4. AI executes tasks using documentation as context\n", style="dim")
    welcome_text.append("\nCommands:\n", style="bold yellow")
    welcome_text.append("  /quit - Exit the session\n", style="dim")
    welcome_text.append("  /clear - Clear conversation history\n", style="dim")
    welcome_text.append("  /status - Show session status\n", style="dim")
    welcome_text.append("  /multi-agent - Toggle multi-agent mode\n", style="dim")
    welcome_text.append("  /help - Show this help\n", style="dim")
    
    console.print(Panel(welcome_text, title="EQUITR Coder", border_style="green"))


def show_session_status(orchestrator: AgentOrchestrator):
    
    messages = orchestrator.session_manager.get_messages()
    multi_agent_status = "Enabled" if orchestrator.config.orchestrator.use_multi_agent else "Disabled"
    
    status_text = Text()
    status_text.append(f"Messages: {len(messages)}\n", style="cyan")
    status_text.append(f"Total cost: ${orchestrator.total_cost:.4f}\n", style="cyan")
    status_text.append(f"Iterations: {orchestrator.iteration_count}\n", style="cyan")
    status_text.append(f"Multi-agent: {multi_agent_status}\n", style="cyan")
    status_text.append(f"Model: {orchestrator.config.llm.model}\n", style="cyan")
    
    console.print(Panel(status_text, title="Session Status", border_style="blue"))


async def conduct_planning_conversation(orchestrator: AgentOrchestrator, initial_request: str) -> Optional[dict]:
    
    console.print("\n[bold green]üéØ Starting Planning Conversation[/bold green]")
    console.print("[dim]The AI will ask questions to understand your requirements...[/dim]\n")
    
    conversation_history = []
    conversation_history.append({"role": "user", "content": initial_request})
    
    while True:
        planning_prompt = f
        
        response = await orchestrator.run(planning_prompt)
        ai_response = response.get("content", "")
        
        if "READY_TO_DOCUMENT" in ai_response:
            console.print("\n[green]‚úÖ Planning conversation complete![/green]")
            break
        
        console.print(Panel(ai_response, title="ü§ñ EQUITR Coder", border_style="blue"))
        
        user_response = Prompt.ask("\n[bold cyan]Your response[/bold cyan]")
        
        if user_response.lower() in ["/quit", "/exit"]:
            return None
        
        conversation_history.append({"role": "assistant", "content": ai_response})
        conversation_history.append({"role": "user", "content": user_response})
    
    return {"conversation": conversation_history}


async def generate_documentation(orchestrator: AgentOrchestrator, conversation_data: dict) -> Optional[dict]:
    
    console.print("\n[bold green]üìã Generating Documentation...[/bold green]")
    
    doc_generator = DocumentationGenerator(orchestrator.provider, str(Path.cwd()))
    
    docs = await doc_generator.generate_all_documents(conversation_data["conversation"])
    
    if not docs:
        console.print("[red]‚ùå Failed to generate documentation[/red]")
        return None
    
    return docs


async def review_and_approve_documentation(docs: dict) -> bool:
    
    console.print("\n[bold green]üìã Generated Documentation[/bold green]")
    
    console.print(Panel(docs["requirements"], title="üìÑ Requirements Document", border_style="green"))
    console.print(Panel(docs["design"], title="üèóÔ∏è Design Document", border_style="blue"))
    console.print(Panel(docs["todos"], title="‚úÖ Todo List", border_style="yellow"))
    
    while True:
        choice = Prompt.ask(
            "\n[bold cyan]Review documentation[/bold cyan]",
            choices=["approve", "revise", "quit"],
            default="approve"
        )
        
        if choice == "approve":
            console.print("[green]‚úÖ Documentation approved![/green]")
            return True
        elif choice == "revise":
            console.print("[yellow]üìù Documentation revision not yet implemented[/yellow]")
            console.print("[dim]Please restart the conversation with revised requirements[/dim]")
            return False
        elif choice == "quit":
            return False


async def execute_with_documentation(orchestrator: AgentOrchestrator, docs: dict) -> dict:
    
    console.print("\n[bold green]üöÄ Starting Implementation with MANDATORY Documentation Context[/bold green]")
    
    required_docs = ['requirements', 'design', 'todos']
    missing_docs = [doc for doc in required_docs if doc not in docs or not docs[doc].strip()]
    
    if missing_docs:
        error_msg = f"EXECUTION BLOCKED: Missing mandatory documentation: {', '.join(missing_docs)}"
        console.print(f"[red]‚ùå {error_msg}[/red]")
        return {
            "content": error_msg,
            "usage": {},
            "cost": 0.0,
            "error": "missing_mandatory_documentation"
        }
    
    execution_context = f
    
    response = await orchestrator.run(execution_context)
    return response


@app.command()
def main(
    repo: str = typer.Option(".", "--repo", "-r", help="Repository path to analyze"),
    profile: str = typer.Option("default", "--profile", "-p", help="Configuration profile to use"),
    model: Optional[str] = typer.Option(None, "--model", "-m", help="LLM model to use (overrides config)"),
    supervisor_model: Optional[str] = typer.Option(None, "--supervisor-model", help="Model for supervisor in multi-agent mode"),
    worker_model: Optional[str] = typer.Option(None, "--worker-model", help="Model for workers in multi-agent mode"),
    budget: Optional[float] = typer.Option(None, "--budget", "-b", help="Budget limit in USD (overrides config)"),
    multi_agent: bool = typer.Option(False, "--multi-agent", "-M", help="Enable multi-agent mode"),
    log_tool_calls: bool = typer.Option(False, "--log-tool-calls", help="Enable tool call logging"),
    tool_log_file: str = typer.Option("tool_calls.log", "--tool-log-file", help="Tool call log file path"),
    version: bool = typer.Option(False, "--version", "-v", help="Show version information"),
):
    
    
    if version:
        console.print("[green]EQUITR Coder v0.1.0[/green]")
        return
    
    try:
        config = config_manager.load_config(profile)
        
        if model:
            config.llm.model = model
        if budget:
            config.llm.budget = budget
        if multi_agent:
            config.orchestrator.use_multi_agent = True
        if supervisor_model:
            config.orchestrator.supervisor_model = supervisor_model
        if worker_model:
            config.orchestrator.worker_model = worker_model
        if log_tool_calls:
            config.orchestrator.log_tool_calls = True
            config.orchestrator.tool_log_file = tool_log_file
        
        repo_path = Path(repo).resolve()
        if not repo_path.exists():
            console.print(f"[red]‚ùå Repository path does not exist: {repo_path}[/red]")
            raise typer.Exit(1)
        
        show_welcome()
        
        config_text = Text()
        config_text.append(f"Model: {config.llm.model}\n", style="cyan")
        if config.orchestrator.use_multi_agent:
            if config.orchestrator.supervisor_model:
                config_text.append(f"Supervisor Model: {config.orchestrator.supervisor_model}\n", style="cyan")
            if config.orchestrator.worker_model:
                config_text.append(f"Worker Model: {config.orchestrator.worker_model}\n", style="cyan")
        config_text.append(f"Profile: {profile}\n", style="cyan")
        config_text.append(f"Repository: {repo_path}\n", style="cyan")
        config_text.append(f"Budget: ${config.llm.budget}\n", style="cyan")
        config_text.append(f"Multi-agent: {'Enabled' if config.orchestrator.use_multi_agent else 'Disabled'}\n", style="cyan")
        if config.orchestrator.log_tool_calls:
            config_text.append(f"Tool Logging: Enabled ({config.orchestrator.tool_log_file})\n", style="cyan")
        
        console.print(Panel(config_text, title="üõ†Ô∏è Configuration", border_style="green"))
        
        async def run_interactive():
            orchestrator = AgentOrchestrator(
                config, 
                str(repo_path),
                supervisor_model=supervisor_model,
                worker_model=worker_model,
            )
            git_auto = GitAutoCommit(str(repo_path))
            session_id = None
            
            git_auto.commit_planning_start()
            
            try:
                while True:
                    try:
                        user_input = Prompt.ask("\n[bold cyan]What would you like to build?[/bold cyan]")
                        
                        if user_input.lower() in ["/quit", "/exit", "/q"]:
                            console.print("[yellow]üëã Goodbye![/yellow]")
                            break
                        elif user_input.lower() == "/clear":
                            orchestrator.session_manager.clear_current_session()
                            console.print("[green]‚úÖ Conversation history cleared[/green]")
                            continue
                        elif user_input.lower() == "/status":
                            show_session_status(orchestrator)
                            continue
                        elif user_input.lower() == "/multi-agent":
                            config.orchestrator.use_multi_agent = not config.orchestrator.use_multi_agent
                            status = "enabled" if config.orchestrator.use_multi_agent else "disabled"
                            console.print(f"[green]‚úÖ Multi-agent mode {status}[/green]")
                            continue
                        elif user_input.lower() == "/help":
                            show_welcome()
                            continue
                        
                        if not user_input.strip():
                            continue
                        
                        conversation_data = await conduct_planning_conversation(orchestrator, user_input)
                        if not conversation_data:
                            console.print("[yellow]Planning cancelled[/yellow]")
                            continue
                        
                        docs = await generate_documentation(orchestrator, conversation_data)
                        if not docs:
                            console.print("[red]‚ùå CRITICAL: Failed to generate MANDATORY documentation[/red]")
                            continue
                        
                        missing_docs = []
                        for doc_type in ['requirements', 'design', 'todos']:
                            if doc_type not in docs or not docs[doc_type].strip():
                                missing_docs.append(doc_type)
                        
                        if missing_docs:
                            console.print(f"[red]‚ùå CRITICAL: Missing MANDATORY documentation: {', '.join(missing_docs)}[/red]")
                            console.print("[red]All three documents (requirements, design, todos) MUST be generated before proceeding[/red]")
                            continue
                        
                        approved = await review_and_approve_documentation(docs)
                        if not approved:
                            console.print("[yellow]Documentation not approved - starting over[/yellow]")
                            continue
                        
                        git_auto.commit_planning_complete()
                        
                        response = await execute_with_documentation(orchestrator, docs)
                        
                        content = response.get("content", "")
                        usage = response.get("usage", {})
                        cost = response.get("cost", 0.0)
                        
                        usage_text = Text()
                        usage_text.append(f"Total tokens: {usage.get('total_tokens', 0)}\n", style="cyan")
                        usage_text.append(f"Cost: ${cost:.4f}\n", style="cyan")
                        
                        console.print(Panel(content, title="ü§ñ Implementation Complete", border_style="green"))
                        console.print(Panel(usage_text, title="üìä Usage Stats", border_style="blue"))
                        
                        git_auto.commit_checkpoint("Implementation complete")
                        
                        if not Confirm.ask("\n[bold cyan]Start another project?[/bold cyan]"):
                            break
                        
                    except KeyboardInterrupt:
                        console.print("\n[yellow]Use /quit to exit properly[/yellow]")
                        continue
                    except Exception as e:
                        console.print(f"[red]‚ùå Error: {e}[/red]")
                        import traceback
                        traceback.print_exc()
                        continue
            
            finally:
                await orchestrator.close()
        
        asyncio.run(run_interactive())
        
    except KeyboardInterrupt:
        console.print("\n[yellow]üëã Goodbye![/yellow]")
        sys.exit(0)
    except Exception as e:
        console.print(f"[red]‚ùå Error: {e}[/red]")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    app()

===== EQUITR-coder/EQUITR_coder/simple_cli.py =====
import asyncio
from pathlib import Path
from typing import Optional

import typer
from rich.console import Console
from rich.prompt import Prompt
from rich.panel import Panel

from .core.config import config_manager
from .core.orchestrator import AgentOrchestrator
from .core.planning import ConversationalPlanner
from .tools.builtin.git_auto import GitAutoCommit

app = typer.Typer(
    name="equitrcoder",
    help="EQUITR Coder - An advanced AI coding assistant that starts interactive sessions automatically",
    add_completion=False,
)

console = Console()


def check_api_key():
    
    pass


@app.command()
def main(
    repo: str = typer.Option(".", "--repo", "-r", help="Repository path to analyze"),
    profile: str = typer.Option(
        "default", "--profile", "-p", help="Configuration profile to use"
    ),
    model: Optional[str] = typer.Option(
        None, "--model", "-m", help="LLM model to use (overrides config)"
    ),
    supervisor_model: Optional[str] = typer.Option(None, "--supervisor-model", help="Model for supervisor in multi-agent mode"),
    worker_model: Optional[str] = typer.Option(None, "--worker-model", help="Model for workers in multi-agent mode"),
    budget: Optional[float] = typer.Option(
        None, "--budget", "-b", help="Budget limit in USD (overrides config)"
    ),
    session: Optional[str] = typer.Option(
        None, "--session", "-s", help="Session ID to resume"
    ),
    multi_agent: bool = typer.Option(False, "--multi-agent", "-M", help="Enable multi-agent mode"),
    log_tool_calls: bool = typer.Option(False, "--log-tool-calls", help="Enable tool call logging"),
    tool_log_file: str = typer.Option("tool_calls.log", "--tool-log-file", help="Tool call log file path"),
    version: bool = typer.Option(
        False, "--version", "-v", help="Show version information"
    ),
):
    

    if version:
        from . import __version__

        console.print(f"[green]üöÄ EQUITR Coder v{__version__}[/green]")
        return

    check_api_key()

    try:
        config = config_manager.load_config(profile)
    except Exception as e:
        console.print(f"[red]‚ùå Failed to load config: {e}[/red]")
        raise typer.Exit(1)

    if budget:
        config.llm.budget = budget
    if multi_agent:
        config.orchestrator.use_multi_agent = True
    if supervisor_model:
        config.orchestrator.supervisor_model = supervisor_model
    if worker_model:
        config.orchestrator.worker_model = worker_model
    if log_tool_calls:
        config.orchestrator.log_tool_calls = True
        config.orchestrator.tool_log_file = tool_log_file

    repo_path = Path(repo).resolve()
    if not repo_path.exists():
        console.print(f"[red]‚ùå Repository path does not exist: {repo_path}[/red]")
        raise typer.Exit(1)

    console.print(
        Panel(
            f"[green]üöÄ EQUITR Coder - Interactive Mode[/green]\n\n"
            f"[cyan]Model:[/cyan] {model or config.llm.model}\n"
            f"[cyan]Profile:[/cyan] {profile}\n"
            f"[cyan]Repository:[/cyan] {repo_path}\n"
            f"[cyan]Budget:[/cyan] ${config.llm.budget}\n"
            f"[cyan]Session:[/cyan] {session or 'new'}\n\n"
            "Type your messages and press Enter. Use '/quit' to exit.\n"
            "Commands:\n"
            "  /quit - Exit the session\n"
            "  /clear - Clear conversation history\n"
            "  /status - Show session status\n"
            "  /help - Show this help",
            title="EQUITR Coder",
            border_style="green",
        )
    )

    async def run_interactive():
        orchestrator = AgentOrchestrator(
            config, 
            str(repo_path), 
            model=model,
            supervisor_model=supervisor_model,
            worker_model=worker_model,
        )
        git_auto = GitAutoCommit(str(repo_path))
        session_id = session

        git_auto.commit_planning_start()

        try:
            while True:
                try:
                    user_input = Prompt.ask("\n[bold cyan]You[/bold cyan]")

                    if user_input.lower() in ["/quit", "/exit", "/q"]:
                        console.print("[yellow]üëã Goodbye![/yellow]")
                        break
                    elif user_input.lower() == "/clear":
                        orchestrator.session_manager.clear_current_session()
                        console.print("[green]‚úÖ Conversation history cleared[/green]")
                        continue
                    elif user_input.lower() == "/status":
                        messages = orchestrator.session_manager.get_messages()
                        console.print("[cyan]üìä Session Status:[/cyan]")
                        console.print(f"  Messages: {len(messages)}")
                        console.print(f"  Total cost: ${orchestrator.total_cost:.4f}")
                        console.print(f"  Iterations: {orchestrator.iteration_count}")
                        continue
                    elif user_input.lower() == "/help":
                        console.print(
                            Panel(
                                "Commands:\n"
                                "  /quit - Exit the session\n"
                                "  /clear - Clear conversation history\n"
                                "  /status - Show session status\n"
                                "  /help - Show this help\n"
                                "  /skip - Skip planning conversation",
                                title="Help",
                                border_style="blue",
                            )
                        )
                        continue

                    if not user_input.strip():
                        continue

                    if not session_id and orchestrator.iteration_count == 0:
                        console.print(
                            "\n[green]üéØ Starting Conversational Planning Phase...[/green]"
                        )

                        planner = ConversationalPlanner(
                            orchestrator.provider, str(repo_path)
                        )

                        planning_success = await planner.start_planning_conversation(
                            user_input
                        )

                        if not planning_success:
                            console.print(
                                "[yellow]Planning cancelled. Exiting...[/yellow]"
                            )
                            break

                        documents = await planner.generate_planning_documents()

                        if not documents:
                            console.print(
                                "[red]Failed to generate planning documents[/red]"
                            )
                            continue

                        console.print(
                            "\n[green]üìã Planning Documents Generated:[/green]"
                        )
                        console.print(
                            Panel(
                                documents["requirements"],
                                title="Requirements Document",
                                border_style="green",
                            )
                        )
                        console.print(
                            Panel(
                                documents["design"],
                                title="Design Document",
                                border_style="blue",
                            )
                        )
                        console.print(
                            Panel(
                                documents["todos"],
                                title="Todo List",
                                border_style="yellow",
                            )
                        )

                        while True:
                            approval = Prompt.ask(
                                "\n[bold cyan]Approve planning documents?[/bold cyan]",
                                choices=["y", "n", "edit"],
                                default="y",
                            )

                            if approval == "y":
                                console.print(
                                    "[green]‚úÖ Planning approved - proceeding to implementation[/green]"
                                )
                                git_auto.commit_planning_complete()
                                break
                            elif approval == "n":
                                console.print(
                                    "[yellow]‚ùå Planning rejected - please provide new requirements[/yellow]"
                                )
                                continue
                            elif approval == "edit":
                                _edit_feedback = Prompt.ask(
                                    "[bold cyan]What changes would you like?[/bold cyan]"
                                )
                                # TODO: Implement document editing based on feedback
                                console.print(
                                    "[yellow]Document editing not yet implemented - please restart planning[/yellow]"
                                )
                                continue

                        planning_context = f

                        response = await orchestrator.run(planning_context, session_id)
                    else:
                        console.print("\n[dim]ü§î Thinking...[/dim]")
                        response = await orchestrator.run(user_input, session_id)

                    content = response.get("content", "")
                    usage = response.get("usage", {})
                    cost = response.get("cost", 0.0)

                    if "completed" in content.lower() or "‚úÖ" in content:
                        git_auto.commit_checkpoint("Task completion")

                    cache_stats = ""
                    prompt_tokens_details = usage.get("prompt_tokens_details", {})
                    cached_tokens = prompt_tokens_details.get("cached_tokens", 0)
                    prompt_tokens = usage.get("prompt_tokens", 0)
                    completion_tokens = usage.get("completion_tokens", 0)
                    total_tokens = usage.get("total_tokens", 0)

                    cached_price = 0.0
                    if cached_tokens > 0:
                        cached_price = (cached_tokens / 1000) * 0.03
                        cache_stats = f"[green]Cached tokens:[/green] {cached_tokens}\n[green]Cached price:[/green] ${cached_price:.4f}"

                    usage_stats = f"[cyan]Prompt tokens:[/cyan] {prompt_tokens}\n[cyan]Completion tokens:[/cyan] {completion_tokens}\n[cyan]Total tokens:[/cyan] {total_tokens}\n[cyan]Total price:[/cyan] ${cost:.4f}"

                    output = f"{content}\n\n{cache_stats}\n{usage_stats}"
                    console.print(
                        Panel(output, title="ü§ñ EQUITR Coder", border_style="blue")
                    )

                    if orchestrator.session_manager.current_session:
                        session_id = (
                            orchestrator.session_manager.current_session.session_id
                        )

                except KeyboardInterrupt:
                    console.print("\n[yellow]Use /quit to exit properly[/yellow]")
                    continue
                except Exception as e:
                    console.print(f"[red]‚ùå Error: {e}[/red]")
                    continue

        finally:
            await orchestrator.close()

    asyncio.run(run_interactive())


def run():
    
    app()


if __name__ == "__main__":
    run()


===== EQUITR-coder/EQUITR_coder/simplest_cli.py =====


import asyncio
import sys
from pathlib import Path

from rich.console import Console
from rich.prompt import Prompt
from rich.panel import Panel

from .core.config import config_manager
from .core.orchestrator import AgentOrchestrator
from .core.planning import ConversationalPlanner
from .tools.builtin.git_auto import GitAutoCommit

console = Console()


def main():
    
    try:
        config = config_manager.load_config("default")

        repo_path = Path.cwd().resolve()

        console.print(
            Panel(
                f"[green]üöÄ EQUITR Coder - Interactive Mode[/green]\n\n"
                f"[cyan]Model:[/cyan] {config.llm.model}\n"
                f"[cyan]Repository:[/cyan] {repo_path}\n"
                f"[cyan]Budget:[/cyan] ${config.llm.budget}\n\n"
                "Type your messages and press Enter. Use '/quit' to exit.\n"
                "Commands:\n"
                "  /quit - Exit the session\n"
                "  /clear - Clear conversation history\n"
                "  /status - Show session status\n"
                "  /help - Show this help",
                title="EQUITR Coder",
                border_style="green",
            )
        )

        async def run_interactive():
            orchestrator = AgentOrchestrator(config, str(repo_path))
            git_auto = GitAutoCommit(str(repo_path))
            session_id = None

            git_auto.commit_planning_start()

            try:
                while True:
                    try:
                        user_input = Prompt.ask("\n[bold cyan]You[/bold cyan]")

                        if user_input.lower() in ["/quit", "/exit", "/q"]:
                            console.print("[yellow]üëã Goodbye![/yellow]")
                            break
                        elif user_input.lower() == "/clear":
                            orchestrator.session_manager.clear_current_session()
                            console.print(
                                "[green]‚úÖ Conversation history cleared[/green]"
                            )
                            continue
                        elif user_input.lower() == "/status":
                            messages = orchestrator.session_manager.get_messages()
                            console.print("[cyan]üìä Session Status:[/cyan]")
                            console.print(f"  Messages: {len(messages)}")
                            console.print(
                                f"  Total cost: ${orchestrator.total_cost:.4f}"
                            )
                            console.print(
                                f"  Iterations: {orchestrator.iteration_count}"
                            )
                            continue
                        elif user_input.lower() == "/help":
                            console.print(
                                Panel(
                                    "Commands:\n"
                                    "  /quit - Exit the session\n"
                                    "  /clear - Clear conversation history\n"
                                    "  /status - Show session status\n"
                                    "  /help - Show this help\n"
                                    "  /skip - Skip planning conversation",
                                    title="Help",
                                    border_style="blue",
                                )
                            )
                            continue

                        if not user_input.strip():
                            continue

                        if not session_id and orchestrator.iteration_count == 0:
                            console.print(
                                "\n[green]üéØ Starting Conversational Planning Phase...[/green]"
                            )

                            planner = ConversationalPlanner(
                                orchestrator.provider, str(repo_path)
                            )

                            planning_success = (
                                await planner.start_planning_conversation(user_input)
                            )

                            if not planning_success:
                                console.print(
                                    "[yellow]Planning cancelled. Exiting...[/yellow]"
                                )
                                break

                            documents = await planner.generate_planning_documents()

                            if not documents:
                                console.print(
                                    "[red]Failed to generate planning documents[/red]"
                                )
                                continue

                            console.print(
                                "\n[green]üìã Planning Documents Generated:[/green]"
                            )
                            console.print(
                                Panel(
                                    documents["requirements"],
                                    title="Requirements Document",
                                    border_style="green",
                                )
                            )
                            console.print(
                                Panel(
                                    documents["design"],
                                    title="Design Document",
                                    border_style="blue",
                                )
                            )
                            console.print(
                                Panel(
                                    documents["todos"],
                                    title="Todo List",
                                    border_style="yellow",
                                )
                            )

                            while True:
                                approval = Prompt.ask(
                                    "\n[bold cyan]Approve planning documents?[/bold cyan]",
                                    choices=["y", "n", "edit"],
                                    default="y",
                                )

                                if approval == "y":
                                    console.print(
                                        "[green]‚úÖ Planning approved - proceeding to implementation[/green]"
                                    )
                                    git_auto.commit_planning_complete()
                                    break
                                elif approval == "n":
                                    console.print(
                                        "[yellow]‚ùå Planning rejected - please provide new requirements[/yellow]"
                                    )
                                    continue
                                elif approval == "edit":
                                    _edit_feedback = Prompt.ask(
                                        "[bold cyan]What changes would you like?[/bold cyan]"
                                    )
                                    console.print(
                                        "[yellow]Document editing not yet implemented - please restart planning[/yellow]"
                                    )
                                    continue

                            planning_context = f

                            response = await orchestrator.run(
                                planning_context, session_id
                            )
                        else:
                            console.print("\n[dim]ü§î Thinking...[/dim]")
                            response = await orchestrator.run(user_input, session_id)

                        content = response.get("content", "")
                        usage = response.get("usage", {})
                        cost = response.get("cost", 0.0)

                        if "completed" in content.lower() or "‚úÖ" in content:
                            git_auto.commit_checkpoint("Task completion")

                        cache_stats = ""
                        prompt_tokens_details = usage.get("prompt_tokens_details", {})
                        cached_tokens = prompt_tokens_details.get("cached_tokens", 0)
                        prompt_tokens = usage.get("prompt_tokens", 0)
                        completion_tokens = usage.get("completion_tokens", 0)
                        total_tokens = usage.get("total_tokens", 0)

                        cached_price = 0.0
                        if cached_tokens > 0:
                            cached_price = (cached_tokens / 1000) * 0.03
                            cache_stats = f"[green]Cached tokens:[/green] {cached_tokens}\n[green]Cached price:[/green] ${cached_price:.4f}"

                        usage_stats = f"[cyan]Prompt tokens:[/cyan] {prompt_tokens}\n[cyan]Completion tokens:[/cyan] {completion_tokens}\n[cyan]Total tokens:[/cyan] {total_tokens}\n[cyan]Total price:[/cyan] ${cost:.4f}"

                        output = f"{content}\n\n{cache_stats}\n{usage_stats}"
                        console.print(
                            Panel(output, title="ü§ñ EQUITR Coder", border_style="blue")
                        )

                        if orchestrator.session_manager.current_session:
                            session_id = (
                                orchestrator.session_manager.current_session.session_id
                            )

                    except KeyboardInterrupt:
                        console.print("\n[yellow]Use /quit to exit properly[/yellow]")
                        continue
                    except Exception as e:
                        console.print(f"[red]‚ùå Error: {e}[/red]")
                        continue

            finally:
                await orchestrator.close()

        asyncio.run(run_interactive())

    except KeyboardInterrupt:
        console.print("\n[yellow]üëã Goodbye![/yellow]")
        sys.exit(0)
    except Exception as e:
        console.print(f"[red]‚ùå Error: {e}[/red]")
        sys.exit(1)


if __name__ == "__main__":
    main()


===== EQUITR-coder/EQUITR_coder/ui/__init__.py =====


from .tui import EquitrTUI

__all__ = ["EquitrTUI"]


===== EQUITR-coder/EQUITR_coder/ui/tui.py =====


from datetime import datetime
from typing import Dict, List, Any, Optional

from textual.app import App, ComposeResult
from textual.containers import Container, Horizontal, Vertical, ScrollableContainer
from textual.widgets import (
    Button,
    DataTable,
    Footer,
    Header,
    Input,
    Label,
    Select,
    Static,
    TabbedContent,
    TabPane,
)
from textual.reactive import reactive
from textual.binding import Binding
from rich.console import RenderableType
from rich.table import Table
from rich.panel import Panel

from ..core.config import Config, config_manager
from ..core.orchestrator import AgentOrchestrator
from ..core.session import SessionManagerV2


class ChatMessage(Static):
    

    def __init__(self, role: str, content: str, timestamp: datetime, **kwargs):
        self.role = role
        self.content = content
        self.timestamp = timestamp
        super().__init__(**kwargs)

    def compose(self) -> ComposeResult:
        
        role_color = "blue" if self.role == "user" else "green"
        time_str = self.timestamp.strftime("%H:%M:%S")

        with Container(classes="message"):
            yield Label(
                f"[{role_color}]{self.role.upper()}[/] [{time_str}]",
                classes="message-header",
            )
            yield Static(self.content, classes="message-content")


class TaskProgress(Static):
    

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.progress_data = None

    def update_progress(self, progress_data: Dict[str, Any]):
        
        self.progress_data = progress_data
        self.refresh()

    def render(self) -> RenderableType:
        
        if not self.progress_data:
            return Panel("No active tasks", title="Task Progress")

        table = Table(show_header=True, header_style="bold magenta")
        table.add_column("Task ID", style="cyan")
        table.add_column("Status", style="green")
        table.add_column("Agent", style="yellow")
        table.add_column("Progress", style="blue")

        for task in self.progress_data.get("tasks", []):
            status_emoji = {
                "todo": "‚è≥",
                "in_progress": "üîÑ",
                "done": "‚úÖ",
                "failed": "‚ùå",
            }.get(task["status"], "‚ùì")

            table.add_row(
                task["id"],
                f"{status_emoji} {task['status']}",
                task.get("assigned_agent", "N/A"),
                f"{task.get('progress', 0):.1f}%",
            )

        summary = self.progress_data.get("summary", {})
        progress_text = f"Overall: {summary.get('progress', 0):.1f}% ({summary.get('completed', 0)}/{summary.get('total', 0)} tasks)"

        return Panel(
            table, title=f"Task Progress - {progress_text}", border_style="bright_blue"
        )


class ModelSelector(Static):
    

    def __init__(self, config: Config, **kwargs):
        super().__init__(**kwargs)
        self.config = config

    def compose(self) -> ComposeResult:
        
        with Vertical():
            yield Label("Model Selection", classes="panel-title")

            current_model = self.config.llm.active_model
            model_info = self.config.llm.models.get(current_model, {})
            current_display = f"{current_model}: {model_info.get('model', 'Unknown')}"
            yield Label(
                f"Current: {current_display}",
                id="current-model",
                classes="current-model",
            )

            model_options = [(name, name) for name in self.config.llm.models.keys()]
            yield Select(
                options=model_options,
                value=current_model,
                id="model-select",
                classes="model-select",
            )

            yield Label("Details:", classes="details-label")
            yield Static(
                self._format_model_details(current_model),
                id="model-details",
                classes="model-details",
            )

    def _format_model_details(self, model_name: str) -> str:
        
        if model_name not in self.config.llm.models:
            return "Model not found"

        model_config = self.config.llm.models[model_name]
        details = []
        details.append(f"Provider: {model_config.get('provider', 'Unknown')}")
        details.append(f"Model: {model_config.get('model', 'Unknown')}")
        details.append(f"Temperature: {model_config.get('temperature', 'N/A')}")
        details.append(f"Max Tokens: {model_config.get('max_tokens', 'N/A')}")

        return "\n".join(details)

    def update_model_info(self, model_name: str) -> None:
        
        if model_name in self.config.llm.models:
            model_info = self.config.llm.models[model_name]
            current_display = f"{model_name}: {model_info.get('model', 'Unknown')}"

            self.query_one("#current-model", Label).update(
                f"Current: {current_display}"
            )
            self.query_one("#model-details", Static).update(
                self._format_model_details(model_name)
            )


class SessionPanel(Static):
    

    def __init__(self, session_manager: SessionManagerV2, **kwargs):
        super().__init__(**kwargs)
        self.session_manager = session_manager

    def compose(self) -> ComposeResult:
        
        with Vertical():
            yield Label("Sessions", classes="panel-title")
            yield Button("New Session", id="new-session", classes="session-button")
            yield Button("Load Session", id="load-session", classes="session-button")
            yield Button(
                "Delete Session", id="delete-session", classes="session-button"
            )

            with ScrollableContainer(classes="session-list"):
                yield DataTable(id="session-table")

    def on_mount(self) -> None:
        
        table = self.query_one("#session-table", DataTable)
        table.add_columns("ID", "Created", "Tasks", "Cost")
        self.refresh_sessions()

    def refresh_sessions(self) -> None:
        
        table = self.query_one("#session-table", DataTable)
        table.clear()

        sessions = self.session_manager.list_sessions()
        for session in sessions:
            table.add_row(
                session["session_id"][:8],
                session["created_at"].strftime("%m/%d %H:%M"),
                str(session["task_count"]),
                f"${session['cost']:.2f}",
            )


class EquitrTUI(App):
    

    CSS = 

    BINDINGS = [
        Binding("ctrl+c", "quit", "Quit", show=True),
        Binding("ctrl+n", "new_session", "New Session", show=True),
        Binding("ctrl+l", "load_session", "Load Session", show=True),
        Binding("ctrl+s", "save_session", "Save Session", show=True),
        Binding("ctrl+m", "focus_model_selector", "Select Model", show=True),
        Binding("f1", "toggle_sidebar", "Toggle Sidebar", show=True),
    ]

    current_session_id: reactive[str] = reactive("default")
    is_processing: reactive[bool] = reactive(False)
    sidebar_visible: reactive[bool] = reactive(True)

    def __init__(self, config: Config, supervisor_model: Optional[str] = None, worker_model: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        self.config = config
        self.supervisor_model = supervisor_model
        self.worker_model = worker_model
        self.session_manager = SessionManagerV2(config.session.session_dir)
        self.orchestrator = AgentOrchestrator(
            config=config, 
            session_manager=self.session_manager,
            supervisor_model=supervisor_model,
            worker_model=worker_model
        )
        self.messages: List[Dict[str, Any]] = []

    def compose(self) -> ComposeResult:
        
        yield Header(show_clock=True)

        with Horizontal():
            with Container(classes="sidebar", id="sidebar"):
                yield SessionPanel(self.session_manager, id="session-panel")
                yield ModelSelector(
                    self.config, id="model-selector", classes="model-panel"
                )
                yield TaskProgress(id="task-progress", classes="progress-panel")

            with Vertical():
                with TabbedContent(id="main-tabs"):
                    with TabPane("Chat", id="chat-tab"):
                        with ScrollableContainer(
                            classes="chat-container", id="chat-log"
                        ):
                            yield Static(
                                "Welcome to EQUITR Coder! Type your message below.",
                                classes="welcome-message",
                            )

                    with TabPane("Session Info", id="session-tab"):
                        yield Static(
                            "Session information will appear here.", id="session-info"
                        )

                with Container(classes="input-container"):
                    with Horizontal():
                        yield Input(
                            placeholder="Type your message...", id="message-input"
                        )
                        yield Button("Send", id="send-button", variant="primary")
                        yield Button("Clear", id="clear-button", variant="error")

        with Container(classes="status-bar"):
            yield Label(f"Session: {self.current_session_id}", id="status-session")
            yield Label("Ready", id="status-message")

        yield Footer()

    def on_mount(self) -> None:
        
        self.query_one("#message-input", Input).focus()
        self.load_session_messages()

    def watch_current_session_id(self, session_id: str) -> None:
        
        self.query_one("#status-session", Label).update(f"Session: {session_id}")
        self.load_session_messages()

    def watch_is_processing(self, processing: bool) -> None:
        
        status_label = self.query_one("#status-message", Label)
        send_button = self.query_one("#send-button", Button)
        message_input = self.query_one("#message-input", Input)

        if processing:
            status_label.update("Processing...")
            send_button.disabled = True
            message_input.disabled = True
        else:
            status_label.update("Ready")
            send_button.disabled = False
            message_input.disabled = False

    def watch_sidebar_visible(self, visible: bool) -> None:
        
        sidebar = self.query_one("#sidebar")
        if visible:
            sidebar.styles.display = "block"
        else:
            sidebar.styles.display = "none"

    def load_session_messages(self) -> None:
        
        chat_log = self.query_one("#chat-log", ScrollableContainer)
        chat_log.remove_children()

        session_data = self.session_manager.get_session_data(self.current_session_id)
        if session_data and session_data.messages:
            for msg in session_data.messages:
                timestamp = datetime.fromisoformat(
                    msg.get("timestamp", datetime.now().isoformat())
                )
                chat_message = ChatMessage(
                    role=msg["role"], content=msg["content"], timestamp=timestamp
                )
                chat_log.mount(chat_message)
        else:
            chat_log.mount(
                Static("No messages in this session.", classes="welcome-message")
            )

        chat_log.scroll_end()

    async def on_button_pressed(self, event: Button.Pressed) -> None:
        
        if event.button.id == "send-button":
            await self.send_message()
        elif event.button.id == "clear-button":
            await self.clear_chat()
        elif event.button.id == "new-session":
            await self.action_new_session()
        elif event.button.id == "load-session":
            await self.action_load_session()
        elif event.button.id == "delete-session":
            await self.action_delete_session()

    async def on_input_submitted(self, event: Input.Submitted) -> None:
        
        if event.input.id == "message-input":
            await self.send_message()

    async def on_select_changed(self, event: Select.Changed) -> None:
        
        if event.select.id == "model-select":
            new_model = event.value
            if new_model and new_model in self.config.llm.models:
                self.config = config_manager.switch_model(self.config, new_model)

                model_selector = self.query_one("#model-selector", ModelSelector)
                model_selector.update_model_info(new_model)

                self.orchestrator = AgentOrchestrator(
                    config=self.config, 
                    session_manager=self.session_manager,
                    supervisor_model=self.supervisor_model,
                    worker_model=self.worker_model
                )

                self.query_one("#status-message", Label).update(
                    f"Switched to model: {new_model}"
                )

                config_manager.save_user_config(self.config)

    async def send_message(self) -> None:
        
        message_input = self.query_one("#message-input", Input)
        message = message_input.value.strip()

        if not message:
            return

        message_input.value = ""

        self.add_message("user", message)

        self.is_processing = True

        try:
            response = await self.orchestrator.run(message, self.current_session_id)

            self.add_message("assistant", response)

            if (
                hasattr(self.orchestrator, "supervisor")
                and self.orchestrator.supervisor
            ):
                progress = await self.orchestrator.supervisor.get_status()
                task_progress = self.query_one("#task-progress", TaskProgress)
                task_progress.update_progress(progress)

        except Exception as e:
            self.add_message("assistant", f"Error: {str(e)}")

        finally:
            self.is_processing = False

    def add_message(self, role: str, content: str) -> None:
        
        chat_log = self.query_one("#chat-log", ScrollableContainer)
        timestamp = datetime.now()

        chat_message = ChatMessage(role=role, content=content, timestamp=timestamp)
        chat_log.mount(chat_message)
        chat_log.scroll_end()

    async def clear_chat(self) -> None:
        
        chat_log = self.query_one("#chat-log", ScrollableContainer)
        chat_log.remove_children()
        chat_log.mount(Static("Chat cleared.", classes="welcome-message"))

    async def action_new_session(self) -> None:
        
        new_session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.session_manager.create_session(new_session_id)
        self.current_session_id = new_session_id

        session_panel = self.query_one("#session-panel", SessionPanel)
        session_panel.refresh_sessions()

    async def action_load_session(self) -> None:
        
        sessions = self.session_manager.list_sessions()
        if sessions:
            self.current_session_id = sessions[0]["session_id"]

            session_panel = self.query_one("#session-panel", SessionPanel)
            session_panel.refresh_sessions()

    async def action_delete_session(self) -> None:
        
        if self.current_session_id != "default":
            self.session_manager.delete_session(self.current_session_id)
            self.current_session_id = "default"

            session_panel = self.query_one("#session-panel", SessionPanel)
            session_panel.refresh_sessions()

    async def action_save_session(self) -> None:
        
        await self.session_manager.save_session(self.current_session_id)

    async def action_toggle_sidebar(self) -> None:
        
        self.sidebar_visible = not self.sidebar_visible

    async def action_focus_model_selector(self) -> None:
        
        model_select = self.query_one("#model-select", Select)
        model_select.focus()

    async def action_quit(self) -> None:
        
        await self.session_manager.save_session(self.current_session_id)
        self.exit()


async def run_tui(config: Config, supervisor_model: Optional[str] = None, worker_model: Optional[str] = None) -> None:
    
    app = EquitrTUI(config, supervisor_model=supervisor_model, worker_model=worker_model)
    await app.run_async()


===== EQUITR-coder/EQUITR_coder/repository/__init__.py =====
from .indexer import RepositoryIndexer
from .analyzer import RepositoryAnalyzer

__all__ = ["RepositoryIndexer", "RepositoryAnalyzer"]


===== EQUITR-coder/EQUITR_coder/repository/analyzer.py =====
import json
import os
from pathlib import Path
from typing import Dict, List, Set


class RepositoryAnalyzer:
    

    def __init__(self, repo_path: str = "."):
        self.repo_path = Path(repo_path).resolve()

    def analyze(self) -> Dict[str, any]:
        
        analysis = {
            "languages": self._detect_languages(),
            "frameworks": self._detect_frameworks(),
            "project_type": self._determine_project_type(),
            "structure": self._analyze_structure(),
            "dependencies": self._analyze_dependencies(),
            "config_files": self._find_config_files(),
            "entry_points": self._find_entry_points(),
        }

        return analysis

    def _detect_languages(self) -> Dict[str, int]:
        
        language_map = {
            ".py": "Python",
            ".js": "JavaScript",
            ".ts": "TypeScript",
            ".jsx": "React",
            ".tsx": "React TypeScript",
            ".java": "Java",
            ".cpp": "C++",
            ".c": "C",
            ".h": "C/C++ Header",
            ".hpp": "C++ Header",
            ".rs": "Rust",
            ".go": "Go",
            ".php": "PHP",
            ".rb": "Ruby",
            ".swift": "Swift",
            ".kt": "Kotlin",
            ".scala": "Scala",
            ".cs": "C#",
            ".fs": "F#",
            ".sh": "Shell",
            ".bash": "Bash",
            ".zsh": "Zsh",
            ".ps1": "PowerShell",
            ".html": "HTML",
            ".css": "CSS",
            ".scss": "SCSS",
            ".sass": "Sass",
            ".less": "Less",
            ".sql": "SQL",
            ".r": "R",
            ".m": "MATLAB",
            ".dart": "Dart",
            ".elm": "Elm",
            ".clj": "Clojure",
            ".ex": "Elixir",
            ".erl": "Erlang",
            ".hs": "Haskell",
            ".ml": "OCaml",
            ".lua": "Lua",
            ".pl": "Perl",
            ".jl": "Julia",
        }

        language_counts = {}

        for file_path in self.repo_path.rglob("*"):
            if file_path.is_file():
                ext = file_path.suffix.lower()
                if ext in language_map:
                    lang = language_map[ext]
                    language_counts[lang] = language_counts.get(lang, 0) + 1

        return dict(sorted(language_counts.items(), key=lambda x: x[1], reverse=True))

    def _detect_frameworks(self) -> List[str]:
        
        frameworks = set()

        package_indicators = {
            "package.json": self._analyze_package_json,
            "requirements.txt": self._analyze_requirements_txt,
            "Pipfile": self._analyze_pipfile,
            "pyproject.toml": self._analyze_pyproject_toml,
            "Cargo.toml": self._analyze_cargo_toml,
            "go.mod": self._analyze_go_mod,
            "pom.xml": self._analyze_pom_xml,
            "build.gradle": self._analyze_gradle,
            "composer.json": self._analyze_composer_json,
            "Gemfile": self._analyze_gemfile,
        }

        for filename, analyzer in package_indicators.items():
            file_path = self.repo_path / filename
            if file_path.exists():
                detected = analyzer(file_path)
                frameworks.update(detected)

        config_indicators = {
            "next.config.js": "Next.js",
            "nuxt.config.js": "Nuxt.js",
            "vue.config.js": "Vue.js",
            "angular.json": "Angular",
            "svelte.config.js": "Svelte",
            "gatsby-config.js": "Gatsby",
            "webpack.config.js": "Webpack",
            "vite.config.js": "Vite",
            "rollup.config.js": "Rollup",
            "docker-compose.yml": "Docker Compose",
            "Dockerfile": "Docker",
            "kubernetes.yaml": "Kubernetes",
            "terraform.tf": "Terraform",
            "ansible.yml": "Ansible",
        }

        for filename, framework in config_indicators.items():
            if (self.repo_path / filename).exists():
                frameworks.add(framework)

        return sorted(list(frameworks))

    def _analyze_package_json(self, file_path: Path) -> Set[str]:
        
        frameworks = set()

        try:
            with open(file_path) as f:
                data = json.load(f)

            dependencies = data.get("dependencies", {})
            dev_dependencies = data.get("devDependencies", {})
            all_deps = {**dependencies, **dev_dependencies}

            framework_indicators = {
                "react": "React",
                "vue": "Vue.js",
                "angular": "Angular",
                "@angular/core": "Angular",
                "svelte": "Svelte",
                "next": "Next.js",
                "nuxt": "Nuxt.js",
                "gatsby": "Gatsby",
                "express": "Express.js",
                "fastify": "Fastify",
                "koa": "Koa.js",
                "nestjs": "NestJS",
                "@nestjs/core": "NestJS",
                "electron": "Electron",
                "ionic": "Ionic",
                "jest": "Jest",
                "mocha": "Mocha",
                "cypress": "Cypress",
                "playwright": "Playwright",
                "webpack": "Webpack",
                "vite": "Vite",
                "rollup": "Rollup",
                "parcel": "Parcel",
            }

            for dep, framework in framework_indicators.items():
                if any(dep in dep_name for dep_name in all_deps.keys()):
                    frameworks.add(framework)

        except (json.JSONDecodeError, FileNotFoundError):
            pass

        return frameworks

    def _analyze_requirements_txt(self, file_path: Path) -> Set[str]:
        
        frameworks = set()

        try:
            with open(file_path) as f:
                content = f.read().lower()

            framework_indicators = {
                "django": "Django",
                "flask": "Flask",
                "fastapi": "FastAPI",
                "tornado": "Tornado",
                "pyramid": "Pyramid",
                "bottle": "Bottle",
                "streamlit": "Streamlit",
                "dash": "Dash",
                "jupyterlab": "JupyterLab",
                "notebook": "Jupyter",
                "tensorflow": "TensorFlow",
                "pytorch": "PyTorch",
                "torch": "PyTorch",
                "scikit-learn": "Scikit-learn",
                "pandas": "Pandas",
                "numpy": "NumPy",
                "matplotlib": "Matplotlib",
                "seaborn": "Seaborn",
                "plotly": "Plotly",
                "celery": "Celery",
                "redis": "Redis",
                "sqlalchemy": "SQLAlchemy",
                "alembic": "Alembic",
                "pytest": "pytest",
                "black": "Black",
                "flake8": "Flake8",
                "mypy": "MyPy",
            }

            for indicator, framework in framework_indicators.items():
                if indicator in content:
                    frameworks.add(framework)

        except FileNotFoundError:
            pass

        return frameworks

    def _analyze_pipfile(self, file_path: Path) -> Set[str]:
        
        return self._analyze_requirements_txt(file_path)  # Simplified for now

    def _analyze_pyproject_toml(self, file_path: Path) -> Set[str]:
        
        frameworks = set()

        try:
            with open(file_path) as f:
                content = f.read().lower()

            if "poetry" in content:
                frameworks.add("Poetry")
            if "setuptools" in content:
                frameworks.add("Setuptools")
            if "hatch" in content:
                frameworks.add("Hatch")

        except FileNotFoundError:
            pass

        return frameworks

    def _analyze_cargo_toml(self, file_path: Path) -> Set[str]:
        
        frameworks = {"Rust"}

        try:
            with open(file_path) as f:
                content = f.read().lower()

            if "tokio" in content:
                frameworks.add("Tokio")
            if "actix" in content:
                frameworks.add("Actix")
            if "rocket" in content:
                frameworks.add("Rocket")
            if "warp" in content:
                frameworks.add("Warp")

        except FileNotFoundError:
            pass

        return frameworks

    def _analyze_go_mod(self, file_path: Path) -> Set[str]:
        
        frameworks = {"Go"}

        try:
            with open(file_path) as f:
                content = f.read().lower()

            if "gin" in content:
                frameworks.add("Gin")
            if "echo" in content:
                frameworks.add("Echo")
            if "fiber" in content:
                frameworks.add("Fiber")

        except FileNotFoundError:
            pass

        return frameworks

    def _analyze_pom_xml(self, file_path: Path) -> Set[str]:
        
        frameworks = {"Maven", "Java"}

        try:
            with open(file_path) as f:
                content = f.read().lower()

            if "spring" in content:
                frameworks.add("Spring")
            if "hibernate" in content:
                frameworks.add("Hibernate")
            if "junit" in content:
                frameworks.add("JUnit")

        except FileNotFoundError:
            pass

        return frameworks

    def _analyze_gradle(self, file_path: Path) -> Set[str]:
        
        frameworks = {"Gradle"}
        return frameworks

    def _analyze_composer_json(self, file_path: Path) -> Set[str]:
        
        frameworks = {"Composer", "PHP"}

        try:
            with open(file_path) as f:
                data = json.load(f)

            dependencies = data.get("require", {})

            if "laravel/framework" in dependencies:
                frameworks.add("Laravel")
            if "symfony/symfony" in dependencies:
                frameworks.add("Symfony")

        except (json.JSONDecodeError, FileNotFoundError):
            pass

        return frameworks

    def _analyze_gemfile(self, file_path: Path) -> Set[str]:
        
        frameworks = {"Ruby", "Bundler"}

        try:
            with open(file_path) as f:
                content = f.read().lower()

            if "rails" in content:
                frameworks.add("Ruby on Rails")
            if "sinatra" in content:
                frameworks.add("Sinatra")

        except FileNotFoundError:
            pass

        return frameworks

    def _determine_project_type(self) -> str:
        

        if (self.repo_path / "package.json").exists():
            return "Node.js/JavaScript"
        elif (self.repo_path / "requirements.txt").exists() or (
            self.repo_path / "pyproject.toml"
        ).exists():
            return "Python"
        elif (self.repo_path / "Cargo.toml").exists():
            return "Rust"
        elif (self.repo_path / "go.mod").exists():
            return "Go"
        elif (self.repo_path / "pom.xml").exists() or (
            self.repo_path / "build.gradle"
        ).exists():
            return "Java"
        elif (self.repo_path / "composer.json").exists():
            return "PHP"
        elif (self.repo_path / "Gemfile").exists():
            return "Ruby"
        elif (self.repo_path / "CMakeLists.txt").exists():
            return "C/C++"
        elif any((self.repo_path / f).exists() for f in ["Makefile", "makefile"]):
            return "C/C++/Generic"
        else:
            return "Unknown"

    def _analyze_structure(self) -> Dict[str, any]:
        
        structure = {
            "total_files": 0,
            "total_directories": 0,
            "max_depth": 0,
            "common_directories": [],
        }

        common_dirs = set()
        max_depth = 0

        for root, dirs, files in os.walk(self.repo_path):
            depth = root.replace(str(self.repo_path), "").count(os.sep)
            max_depth = max(max_depth, depth)
            structure["total_files"] += len(files)
            structure["total_directories"] += len(dirs)

            for d in dirs:
                if not d.startswith("."):
                    common_dirs.add(d)

        structure["max_depth"] = max_depth
        structure["common_directories"] = sorted(list(common_dirs))

        return structure

    def _analyze_dependencies(self) -> Dict[str, List[str]]:
        
        dependencies = {}

        dep_files = {
            "npm": "package.json",
            "pip": "requirements.txt",
            "poetry": "pyproject.toml",
            "cargo": "Cargo.toml",
            "go": "go.mod",
            "maven": "pom.xml",
            "gradle": "build.gradle",
            "composer": "composer.json",
            "bundler": "Gemfile",
        }

        for manager, filename in dep_files.items():
            file_path = self.repo_path / filename
            if file_path.exists():
                dependencies[manager] = [filename]

        return dependencies

    def _find_config_files(self) -> List[str]:
        
        config_patterns = [
            "*.json",
            "*.yaml",
            "*.yml",
            "*.toml",
            "*.ini",
            "*.cfg",
            "*.conf",
            "*.config",
            "Dockerfile",
            "Makefile",
            ".env*",
        ]

        config_files = []

        for pattern in config_patterns:
            for file_path in self.repo_path.glob(pattern):
                if file_path.is_file():
                    config_files.append(file_path.name)

        return sorted(config_files)

    def _find_entry_points(self) -> List[str]:
        
        entry_points = []

        common_entry_files = [
            "main.py",
            "app.py",
            "server.py",
            "index.js",
            "app.js",
            "main.js",
            "server.js",
            "index.html",
            "main.go",
            "main.rs",
            "Main.java",
            "index.php",
            "app.rb",
        ]

        for filename in common_entry_files:
            if (self.repo_path / filename).exists():
                entry_points.append(filename)

        return entry_points


===== EQUITR-coder/EQUITR_coder/repository/indexer.py =====
import os
from pathlib import Path
from typing import Dict, List
import pathspec
from .analyzer import RepositoryAnalyzer


class RepositoryIndexer:
    

    def __init__(self, repo_path: str = ".", ignore_patterns: List[str] = None):
        self.repo_path = Path(repo_path).resolve()
        self.ignore_patterns = ignore_patterns or []
        self.analyzer = RepositoryAnalyzer(repo_path)

        default_ignores = [
            ".git/**",
            "node_modules/**",
            "__pycache__/**",
            "*.pyc",
            ".venv/**",
            "venv/**",
            "env/**",
            ".env/**",
            "dist/**",
            "build/**",
            "target/**",
            "*.log",
            "*.tmp",
            "*.cache",
            ".DS_Store",
            "Thumbs.db",
        ]

        self.spec = pathspec.PathSpec.from_lines(
            "gitwildmatch", default_ignores + self.ignore_patterns
        )

    def should_ignore(self, path: Path) -> bool:
        
        rel_path = path.relative_to(self.repo_path)
        return self.spec.match_file(str(rel_path))

    def get_file_tree(self) -> Dict:
        
        tree = {}

        for root, dirs, files in os.walk(self.repo_path):
            root_path = Path(root)

            dirs[:] = [d for d in dirs if not self.should_ignore(root_path / d)]

            rel_root = root_path.relative_to(self.repo_path)

            if rel_root == Path("."):
                current_level = tree
            else:
                current_level = tree
                for part in rel_root.parts:
                    current_level = current_level.setdefault(part, {})

            for file in files:
                file_path = root_path / file
                if not self.should_ignore(file_path):
                    current_level[file] = None  # None indicates it's a file

        return tree

    def get_important_files(self) -> List[str]:
        
        important_patterns = [
            "README*",
            "readme*",
            "package.json",
            "requirements.txt",
            "pyproject.toml",
            "Cargo.toml",
            "go.mod",
            "pom.xml",
            "build.gradle",
            "Dockerfile",
            "docker-compose*",
            "Makefile",
            "makefile",
            "*.config.js",
            "*.config.ts",
            ".env*",
            "*.env",
            "main.*",
            "index.*",
            "app.*",
            "setup.py",
            "setup.cfg",
            "tox.ini",
            "pytest.ini",
            "jest.config.*",
            "webpack.config.*",
            "tsconfig.json",
            "jsconfig.json",
        ]

        important_files = []

        for pattern in important_patterns:
            for file_path in self.repo_path.glob(pattern):
                if file_path.is_file() and not self.should_ignore(file_path):
                    rel_path = file_path.relative_to(self.repo_path)
                    important_files.append(str(rel_path))

        return sorted(important_files)

    def get_file_summary(self, max_files: int = 50) -> List[Dict]:
        
        files_info = []
        count = 0

        for root, dirs, files in os.walk(self.repo_path):
            if count >= max_files:
                break

            root_path = Path(root)
            dirs[:] = [d for d in dirs if not self.should_ignore(root_path / d)]

            for file in files:
                if count >= max_files:
                    break

                file_path = root_path / file
                if not self.should_ignore(file_path):
                    rel_path = file_path.relative_to(self.repo_path)

                    try:
                        stat = file_path.stat()
                        files_info.append(
                            {
                                "path": str(rel_path),
                                "size": stat.st_size,
                                "extension": file_path.suffix,
                                "is_text": self._is_text_file(file_path),
                            }
                        )
                        count += 1
                    except (OSError, PermissionError):
                        continue

        return files_info

    def _is_text_file(self, file_path: Path) -> bool:
        
        text_extensions = {
            ".py",
            ".js",
            ".ts",
            ".jsx",
            ".tsx",
            ".html",
            ".css",
            ".scss",
            ".sass",
            ".less",
            ".json",
            ".yaml",
            ".yml",
            ".toml",
            ".ini",
            ".cfg",
            ".conf",
            ".txt",
            ".md",
            ".rst",
            ".tex",
            ".sh",
            ".bash",
            ".zsh",
            ".fish",
            ".ps1",
            ".bat",
            ".cmd",
            ".java",
            ".cpp",
            ".c",
            ".h",
            ".hpp",
            ".rs",
            ".go",
            ".php",
            ".rb",
            ".swift",
            ".kt",
            ".scala",
            ".cs",
            ".fs",
            ".hs",
            ".elm",
            ".clj",
            ".ex",
            ".erl",
            ".jl",
            ".r",
            ".m",
            ".sql",
            ".xml",
            ".svg",
            ".gitignore",
            ".dockerignore",
            ".env",
        }

        if file_path.suffix.lower() in text_extensions:
            return True

        if not file_path.suffix and file_path.name.lower() in {
            "readme",
            "license",
            "changelog",
            "makefile",
            "dockerfile",
            "vagrantfile",
            "rakefile",
            "gemfile",
            "procfile",
        }:
            return True

        try:
            with open(file_path, "rb") as f:
                chunk = f.read(1024)
                if b"\x00" in chunk:  # Null bytes suggest binary
                    return False
                try:
                    chunk.decode("utf-8")
                    return True
                except UnicodeDecodeError:
                    return False
        except (OSError, PermissionError):
            return False

    async def get_context(self, query: str = None) -> str:
        
        return await self.get_repository_context()

    async def get_repository_context(self) -> str:
        

        analysis = self.analyzer.analyze()

        file_tree = self.get_file_tree()
        important_files = self.get_important_files()
        self.get_file_summary()

        context_parts = []

        context_parts.append("# Repository Analysis")
        context_parts.append(f"Project Type: {analysis['project_type']}")

        if analysis["languages"]:
            languages = [
                f"{lang} ({count} files)"
                for lang, count in analysis["languages"].items()
            ]
            context_parts.append(f"Languages: {', '.join(languages[:5])}")  # Top 5

        if analysis["frameworks"]:
            context_parts.append(
                f"Frameworks: {', '.join(analysis['frameworks'][:10])}"
            )  # Top 10

        structure = analysis["structure"]
        context_parts.append(
            f"Structure: {structure['total_files']} files, {structure['total_directories']} directories"
        )

        if important_files:
            context_parts.append("\n## Important Files")
            for file in important_files[:20]:  # Top 20 important files
                context_parts.append(f"- {file}")

        context_parts.append("\n## File Tree")
        tree_str = self._format_tree(file_tree, max_depth=3)
        context_parts.append(tree_str)

        if analysis["entry_points"]:
            context_parts.append("\n## Entry Points")
            for entry in analysis["entry_points"]:
                context_parts.append(f"- {entry}")

        if analysis["config_files"]:
            config_files = analysis["config_files"][:10]  # Top 10 config files
            context_parts.append("\n## Configuration Files")
            context_parts.append(f"{', '.join(config_files)}")

        return "\n".join(context_parts)

    def _format_tree(
        self, tree: Dict, prefix: str = "", max_depth: int = 3, current_depth: int = 0
    ) -> str:
        
        if current_depth >= max_depth:
            return ""

        lines = []
        items = sorted(tree.items())

        for i, (name, subtree) in enumerate(items):
            is_last = i == len(items) - 1
            current_prefix = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
            lines.append(f"{prefix}{current_prefix}{name}")

            if subtree is not None:  # It's a directory
                extension = "    " if is_last else "‚îÇ   "
                sublines = self._format_tree(
                    subtree, prefix + extension, max_depth, current_depth + 1
                )
                if sublines:
                    lines.append(sublines)

        return "\n".join(lines)


===== EQUITR-coder/EQUITR_coder/tools/__init__.py =====
from .base import Tool, ToolResult, registry
from .discovery import discovery

__all__ = ["Tool", "ToolResult", "registry", "discovery"]


===== EQUITR-coder/EQUITR_coder/tools/base.py =====
from abc import ABC, abstractmethod
from typing import Any, Dict, Type, Optional
from pydantic import BaseModel, Field


class ToolResult(BaseModel):
    success: bool = True
    data: Any = None
    error: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)


class Tool(ABC):
    

    def __init__(self):
        self.name = self.get_name()
        self.description = self.get_description()
        self.args_schema = self.get_args_schema()

    @abstractmethod
    def get_name(self) -> str:
        
        pass

    @abstractmethod
    def get_description(self) -> str:
        
        pass

    @abstractmethod
    def get_args_schema(self) -> Type[BaseModel]:
        
        pass

    @abstractmethod
    async def run(self, **kwargs) -> ToolResult:
        
        pass

    def get_json_schema(self) -> Dict[str, Any]:
        
        schema = self.args_schema.model_json_schema()
        return {
            "name": self.name,
            "description": self.description,
            "parameters": schema,
        }

    def validate_args(self, args: Dict[str, Any]) -> BaseModel:
        
        return self.args_schema(**args)


class ToolRegistry:
    

    def __init__(self):
        self._tools: Dict[str, Tool] = {}

    def register(self, tool: Tool):
        
        self._tools[tool.name] = tool

    def get(self, name: str) -> Optional[Tool]:
        
        return self._tools.get(name)

    def get_all(self) -> Dict[str, Tool]:
        
        return self._tools.copy()

    def get_enabled_tools(self, enabled_names: list[str]) -> Dict[str, Tool]:
        
        return {
            name: tool for name, tool in self._tools.items() if name in enabled_names
        }

    def get_schemas(self, enabled_names: list[str] = None) -> list[Dict[str, Any]]:
        
        if enabled_names is None:
            tools = self._tools.values()
        else:
            tools = [self._tools[name] for name in enabled_names if name in self._tools]

        return [tool.get_json_schema() for tool in tools]


registry = ToolRegistry()


===== EQUITR-coder/EQUITR_coder/tools/discovery.py =====
import importlib
import inspect
import pkgutil
from pathlib import Path
from typing import List, Type
from .base import Tool, registry
import logging

logger = logging.getLogger(__name__)


class ToolDiscovery:
    

    def __init__(self):
        self.loaded_modules = set()

    def discover_builtin_tools(self):
        
        builtin_path = Path(__file__).parent / "builtin"
        self._discover_tools_in_package("EQUITR_coder.tools.builtin", builtin_path)

    def discover_custom_tools(self):
        
        custom_path = Path(__file__).parent / "custom"
        if custom_path.exists():
            self._discover_tools_in_package("EQUITR_coder.tools.custom", custom_path)

    def discover_mcp_tools(self):
        
        mcp_path = Path(__file__).parent / "mcp"
        if mcp_path.exists():
            self._discover_tools_in_package("EQUITR_coder.tools.mcp", mcp_path)

    def _discover_tools_in_package(self, package_name: str, package_path: Path):
        
        if not package_path.exists():
            return

        try:
            package = importlib.import_module(package_name)

            for importer, modname, ispkg in pkgutil.iter_modules(
                package.__path__, package_name + "."
            ):
                if modname in self.loaded_modules:
                    continue

                try:
                    module = importlib.import_module(modname)
                    self.loaded_modules.add(modname)

                    tools = self._extract_tools_from_module(module)
                    for tool_class in tools:
                        if self._tool_requires_parameters(tool_class):
                            logger.info(f"Skipping tool {tool_class.__name__} (requires parameters)")
                            continue
                        
                        tool_instance = tool_class()
                        registry.register(tool_instance)
                        logger.info(f"Registered tool: {tool_instance.name}")

                except Exception as e:
                    logger.warning(f"Failed to load tool module {modname}: {e}")

        except ImportError as e:
            logger.warning(f"Failed to import package {package_name}: {e}")

    def _extract_tools_from_module(self, module) -> List[Type[Tool]]:
        
        tools = []

        for name, obj in inspect.getmembers(module):
            if (
                inspect.isclass(obj)
                and issubclass(obj, Tool)
                and obj is not Tool
                and not inspect.isabstract(obj)
            ):
                tools.append(obj)

        return tools

    def _tool_requires_parameters(self, tool_class: Type[Tool]) -> bool:
        
        try:
            init_signature = inspect.signature(tool_class.__init__)
            
            for param_name, param in init_signature.parameters.items():
                if param_name != 'self' and param.default == inspect.Parameter.empty:
                    return True
                    
            return False
        except Exception:
            return True

    def reload_tools(self):
        
        registry._tools.clear()
        self.loaded_modules.clear()

        self.discover_builtin_tools()
        self.discover_custom_tools()
        self.discover_mcp_tools()


discovery = ToolDiscovery()


===== EQUITR-coder/EQUITR_coder/tools/builtin/__init__.py =====

from .agent_communication import *
from .ask_supervisor import *
from .fs import *
from .git import *
from .git_auto import *
from .search import *
from .shell import *
from .todo import *


===== EQUITR-coder/EQUITR_coder/tools/builtin/agent_communication.py =====


from typing import Type, List, Dict, Any, Optional
from pydantic import BaseModel, Field
from ..base import Tool, ToolResult
from ...core.message_pool import message_pool, MessageType


class SendMessageArgs(BaseModel):
    content: str = Field(..., description="The message content to send")
    message_type: str = Field(
        default="info",
        description="Type of message: info, request, response, status_update, coordination, error",
    )
    recipient_agent: Optional[str] = Field(
        default=None,
        description="Specific agent to send to (None for broadcast to all agents)",
    )
    task_id: Optional[str] = Field(
        default=None, description="Task ID this message relates to"
    )
    thread_id: Optional[str] = Field(
        default=None, description="Thread ID for message grouping"
    )
    priority: int = Field(
        default=5, description="Message priority (1-10, higher is more urgent)"
    )
    metadata: Optional[Dict[str, Any]] = Field(
        default=None, description="Additional metadata for the message"
    )


class ReceiveMessagesArgs(BaseModel):
    timeout: float = Field(
        default=0.1, description="Timeout in seconds to wait for messages"
    )
    message_type_filter: Optional[str] = Field(
        default=None, description="Filter messages by type"
    )


class GetMessageHistoryArgs(BaseModel):
    task_id: Optional[str] = Field(default=None, description="Filter by task ID")
    thread_id: Optional[str] = Field(default=None, description="Filter by thread ID")
    message_type: Optional[str] = Field(
        default=None, description="Filter by message type"
    )
    limit: int = Field(default=50, description="Maximum number of messages to return")


class GetActiveAgentsArgs(BaseModel):
    pass


class SendMessage(Tool):
    

    def __init__(self, agent_name: str):
        self.agent_name = agent_name
        super().__init__()

    def get_name(self) -> str:
        return "send_agent_message"

    def get_description(self) -> str:
        return "Send a message to other agents in the multi-agent system. For complex coordination, strategic planning, or when messages require deep analysis and synthesis, use a stronger reasoning model to craft comprehensive and insightful communications."

    def get_args_schema(self) -> Type[BaseModel]:
        return SendMessageArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            try:
                msg_type = MessageType(args.message_type)
            except ValueError:
                return ToolResult(
                    success=False,
                    error=f"Invalid message type: {args.message_type}. Valid types: {[t.value for t in MessageType]}",
                )

            message_id = await message_pool.send_message(
                sender_agent=self.agent_name,
                content=args.content,
                message_type=msg_type,
                recipient_agent=args.recipient_agent,
                task_id=args.task_id,
                thread_id=args.thread_id,
                metadata=args.metadata or {},
                priority=args.priority,
            )

            return ToolResult(
                success=True,
                data={
                    "message_id": message_id,
                    "sent_to": args.recipient_agent or "all_agents",
                    "message_type": args.message_type,
                    "content": args.content,
                },
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


class ReceiveMessages(Tool):
    

    def __init__(self, agent_name: str):
        self.agent_name = agent_name
        super().__init__()

    def get_name(self) -> str:
        return "receive_agent_messages"

    def get_description(self) -> str:
        return "Receive pending messages from other agents"

    def get_args_schema(self) -> Type[BaseModel]:
        return ReceiveMessagesArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            messages = await message_pool.get_messages_for_agent(
                self.agent_name, timeout=args.timeout
            )

            if args.message_type_filter:
                try:
                    filter_type = MessageType(args.message_type_filter)
                    messages = [m for m in messages if m.message_type == filter_type]
                except ValueError:
                    return ToolResult(
                        success=False,
                        error=f"Invalid message type filter: {args.message_type_filter}",
                    )

            message_data = []
            for msg in messages:
                message_data.append(
                    {
                        "id": msg.id,
                        "sender_agent": msg.sender_agent,
                        "message_type": msg.message_type.value,
                        "content": msg.content,
                        "timestamp": msg.timestamp.isoformat(),
                        "task_id": msg.task_id,
                        "thread_id": msg.thread_id,
                        "priority": msg.priority,
                        "metadata": msg.metadata,
                    }
                )

            return ToolResult(
                success=True,
                data={
                    "messages": message_data,
                    "count": len(message_data),
                    "agent": self.agent_name,
                },
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


class GetMessageHistory(Tool):
    

    def __init__(self, agent_name: str):
        self.agent_name = agent_name
        super().__init__()

    def get_name(self) -> str:
        return "get_message_history"

    def get_description(self) -> str:
        return "Get message history with optional filters. For complex analysis of agent communications, strategic insights, or when synthesizing patterns across multiple conversations, use a stronger reasoning model to provide deep understanding and actionable insights."

    def get_args_schema(self) -> Type[BaseModel]:
        return GetMessageHistoryArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            message_type_enum = None
            if args.message_type:
                try:
                    message_type_enum = MessageType(args.message_type)
                except ValueError:
                    return ToolResult(
                        success=False,
                        error=f"Invalid message type: {args.message_type}",
                    )

            messages = await message_pool.get_message_history(
                agent_name=self.agent_name,
                task_id=args.task_id,
                thread_id=args.thread_id,
                message_type=message_type_enum,
                limit=args.limit,
            )

            message_data = []
            for msg in messages:
                message_data.append(
                    {
                        "id": msg.id,
                        "sender_agent": msg.sender_agent,
                        "recipient_agent": msg.recipient_agent,
                        "message_type": msg.message_type.value,
                        "content": msg.content,
                        "timestamp": msg.timestamp.isoformat(),
                        "task_id": msg.task_id,
                        "thread_id": msg.thread_id,
                        "priority": msg.priority,
                        "metadata": msg.metadata,
                    }
                )

            return ToolResult(
                success=True,
                data={
                    "messages": message_data,
                    "count": len(message_data),
                    "filters": {
                        "agent_name": self.agent_name,
                        "task_id": args.task_id,
                        "thread_id": args.thread_id,
                        "message_type": args.message_type,
                        "limit": args.limit,
                    },
                },
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


class GetActiveAgents(Tool):
    

    def get_name(self) -> str:
        return "get_active_agents"

    def get_description(self) -> str:
        return "Get list of currently active agents in the system"

    def get_args_schema(self) -> Type[BaseModel]:
        return GetActiveAgentsArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            active_agents = await message_pool.get_active_agents()
            pool_status = await message_pool.get_pool_status()

            return ToolResult(
                success=True,
                data={
                    "active_agents": active_agents,
                    "agent_count": len(active_agents),
                    "pool_status": pool_status,
                },
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


def create_agent_communication_tools(agent_name: str) -> List[Tool]:
    
    return [
        SendMessage(agent_name),
        ReceiveMessages(agent_name),
        GetMessageHistory(agent_name),
        GetActiveAgents(),
    ]


===== EQUITR-coder/EQUITR_coder/tools/builtin/ask_supervisor.py =====


from typing import Type, Optional, List
from pydantic import BaseModel, Field
from ..base import Tool, ToolResult
from ...repository.indexer import RepositoryIndexer


class AskSupervisorArgs(BaseModel):
    question: str = Field(
        ..., description="The question or problem to ask the supervisor"
    )
    context_files: Optional[List[str]] = Field(
        default=None, description="Optional list of file paths to include as context"
    )
    include_repo_tree: bool = Field(
        default=True, description="Include repository tree structure in context"
    )
    include_git_status: bool = Field(
        default=True, description="Include current git status in context"
    )


class AskSupervisor(Tool):
    

    def __init__(self, provider):
        self.provider = provider
        super().__init__()

    def get_name(self) -> str:
        return "ask_supervisor"

    def get_description(self) -> str:
        return 

    def get_args_schema(self) -> Type[BaseModel]:
        return AskSupervisorArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            context_parts = []

            if args.include_repo_tree:
                try:

                    repo_path = "."
                    indexer = RepositoryIndexer(repo_path=repo_path)
                    tree = indexer.get_directory_tree()
                    if tree:
                        context_parts.append(f"Repository structure:\n{tree}")
                except Exception:
                    pass

            if args.include_git_status:
                try:
                    from .git import GitStatus

                    git_tool = GitStatus()
                    git_result = await git_tool.run()
                    if git_result.success:
                        context_parts.append(f"Git status:\n{git_result.data}")
                except Exception:
                    pass

            if args.context_files:
                from .fs import ReadFile

                read_tool = ReadFile()

                for file_path in args.context_files:
                    try:
                        file_result = await read_tool.run(path=file_path)
                        if file_result.success:
                            context_parts.append(
                                f"File: {file_path}\n```\n{file_result.data}\n```"
                            )
                    except Exception:
                        pass

            full_context = "\n\n".join(context_parts) if context_parts else ""

            supervisor_prompt = f

            response = await self.provider.chat(
                messages=[{"role": "user", "content": supervisor_prompt}],
                temperature=0.1,
                max_tokens=2000,
            )

            return ToolResult(
                success=True,
                data={
                    "question": args.question,
                    "response": response.content,
                    "context_provided": {
                        "repo_tree": args.include_repo_tree,
                        "git_status": args.include_git_status,
                        "files": args.context_files or [],
                    },
                },
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


def create_ask_supervisor_tool(provider) -> AskSupervisor:
    
    return AskSupervisor(provider)


===== EQUITR-coder/EQUITR_coder/tools/builtin/audit.py =====


import json
import os
from typing import Dict, List, Optional, Any
from pathlib import Path

from .todo import TodoManager


class AutoAuditManager:
    
    
    def __init__(self):
        self.todo_manager = TodoManager()
    
    def should_trigger_audit(self) -> bool:
        
        todos = self.todo_manager.list_todos()
        if not todos:
            return False
        
        incomplete_todos = [todo for todo in todos if todo.status not in ["completed", "cancelled"]]
        return len(incomplete_todos) == 0
    
    def get_audit_context(self) -> Optional[str]:
        
        if not self.should_trigger_audit():
            return None
        
        todos = self.todo_manager.list_todos()
        return self._prepare_audit_context(todos)
    
    def _prepare_audit_context(self, todos: List[Any]) -> str:
        
        context_parts = []
        
        completed_todos = [todo for todo in todos if todo.status == "completed"]
        context_parts.append(f"TODOS COMPLETED: {len(completed_todos)}/{len(todos)}")
        context_parts.append("=" * 50)
        
        for todo in completed_todos:
            context_parts.append(f"‚úÖ {todo.title}")
        
        context_parts.append("\nAUDIT TOOLS AVAILABLE:")
        context_parts.append("- read_file: Read any file in the codebase")
        context_parts.append("- list_files: List files in directories") 
        context_parts.append("- grep_search: Search for patterns in code")
        context_parts.append("- git_status: Check git status")
        context_parts.append("- git_diff: See changes made")
        
        context_parts.append("\nAUDIT INSTRUCTIONS:")
        context_parts.append("1. Use list_files to examine project structure")
        context_parts.append("2. Use read_file to examine design and requirements documents")
        context_parts.append("3. Use grep_search to verify implementation matches requirements")
        context_parts.append("4. Check code quality, completeness, and adherence to design")
        context_parts.append("5. If everything is complete and faithful: respond with 'AUDIT PASSED'")
        context_parts.append("6. If issues found: respond with 'AUDIT FAILED' and create new todos for fixes")
        
        return "\n".join(context_parts)


audit_manager = AutoAuditManager()

===== EQUITR-coder/EQUITR_coder/tools/builtin/fs.py =====
from pathlib import Path
from typing import Type
from pydantic import BaseModel, Field
from ..base import Tool, ToolResult


class CreateFileArgs(BaseModel):
    path: str = Field(..., description="Relative file path to create")
    content: str = Field(..., description="Content to write to the file")


class CreateFile(Tool):
    def get_name(self) -> str:
        return "create_file"

    def get_description(self) -> str:
        return "Create a new file with given content"

    def get_args_schema(self) -> Type[BaseModel]:
        return CreateFileArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            file_path = Path(args.path)

            if ".." in str(file_path) or str(file_path).startswith("/"):
                return ToolResult(
                    success=False,
                    error="Path traversal not allowed. Use relative paths only.",
                )

            file_path.parent.mkdir(parents=True, exist_ok=True)

            file_path.write_text(args.content, encoding="utf-8")

            return ToolResult(
                success=True,
                data={"path": str(file_path), "bytes_written": len(args.content)},
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


class ReadFileArgs(BaseModel):
    path: str = Field(..., description="Relative file path to read")


class ReadFile(Tool):
    def get_name(self) -> str:
        return "read_file"

    def get_description(self) -> str:
        return "Read the contents of a file"

    def get_args_schema(self) -> Type[BaseModel]:
        return ReadFileArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            file_path = Path(args.path)

            if ".." in str(file_path) or str(file_path).startswith("/"):
                return ToolResult(
                    success=False,
                    error="Path traversal not allowed. Use relative paths only.",
                )

            if not file_path.exists():
                return ToolResult(
                    success=False, error=f"File {file_path} does not exist"
                )

            content = file_path.read_text(encoding="utf-8")

            return ToolResult(
                success=True,
                data={"path": str(file_path), "content": content, "size": len(content)},
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


class EditFileArgs(BaseModel):
    path: str = Field(..., description="Relative file path to edit")
    old_content: str = Field(..., description="Content to replace")
    new_content: str = Field(..., description="New content to insert")


class EditFile(Tool):
    def get_name(self) -> str:
        return "edit_file"

    def get_description(self) -> str:
        return "Edit a file by replacing old content with new content"

    def get_args_schema(self) -> Type[BaseModel]:
        return EditFileArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            file_path = Path(args.path)

            if ".." in str(file_path) or str(file_path).startswith("/"):
                return ToolResult(
                    success=False,
                    error="Path traversal not allowed. Use relative paths only.",
                )

            if not file_path.exists():
                return ToolResult(
                    success=False, error=f"File {file_path} does not exist"
                )

            content = file_path.read_text(encoding="utf-8")

            if args.old_content not in content:
                return ToolResult(success=False, error="Old content not found in file")

            new_content = content.replace(args.old_content, args.new_content)
            file_path.write_text(new_content, encoding="utf-8")

            return ToolResult(
                success=True,
                data={
                    "path": str(file_path),
                    "changes": 1,
                    "new_size": len(new_content),
                },
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


class ListFilesArgs(BaseModel):
    path: str = Field(default=".", description="Directory path to list")


class ListFiles(Tool):
    def get_name(self) -> str:
        return "list_files"

    def get_description(self) -> str:
        return "List files and directories in a given path"

    def get_args_schema(self) -> Type[BaseModel]:
        return ListFilesArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            dir_path = Path(args.path)

            if ".." in str(dir_path) or str(dir_path).startswith("/"):
                return ToolResult(
                    success=False,
                    error="Path traversal not allowed. Use relative paths only.",
                )

            if not dir_path.exists():
                return ToolResult(
                    success=False, error=f"Directory {dir_path} does not exist"
                )

            if not dir_path.is_dir():
                return ToolResult(success=False, error=f"{dir_path} is not a directory")

            files = []
            directories = []

            for item in dir_path.iterdir():
                if item.is_file():
                    files.append(
                        {"name": item.name, "size": item.stat().st_size, "type": "file"}
                    )
                elif item.is_dir():
                    directories.append({"name": item.name, "type": "directory"})

            return ToolResult(
                success=True,
                data={
                    "path": str(dir_path),
                    "files": files,
                    "directories": directories,
                    "total_items": len(files) + len(directories),
                },
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


===== EQUITR-coder/EQUITR_coder/tools/builtin/git.py =====
import git
import os
from typing import Type
from pydantic import BaseModel, Field
from ..base import Tool, ToolResult


class GitCommitArgs(BaseModel):
    message: str = Field(..., description="Commit message")
    add_all: bool = Field(
        default=True, description="Whether to add all changes before committing"
    )


class GitCommit(Tool):
    def get_name(self) -> str:
        return "git_commit"

    def get_description(self) -> str:
        return "Stage changes and create a git commit"

    def get_args_schema(self) -> Type[BaseModel]:
        return GitCommitArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            try:
                repo = git.Repo(os.getcwd())
            except git.InvalidGitRepositoryError:
                return ToolResult(success=False, error="Not in a git repository")

            if args.add_all:
                repo.git.add(all=True)

            if not repo.index.diff("HEAD"):
                return ToolResult(success=False, error="No changes to commit")

            commit = repo.index.commit(args.message)

            return ToolResult(
                success=True,
                data={
                    "commit_hash": commit.hexsha,
                    "message": args.message,
                    "author": str(commit.author),
                    "files_changed": len(commit.stats.files),
                },
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


class GitStatusArgs(BaseModel):
    pass


class GitStatus(Tool):
    def get_name(self) -> str:
        return "git_status"

    def get_description(self) -> str:
        return "Get the current git repository status"

    def get_args_schema(self) -> Type[BaseModel]:
        return GitStatusArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            try:
                repo = git.Repo(os.getcwd())
            except git.InvalidGitRepositoryError:
                return ToolResult(success=False, error="Not in a git repository")

            untracked_files = repo.untracked_files
            modified_files = [item.a_path for item in repo.index.diff(None)]
            staged_files = [item.a_path for item in repo.index.diff("HEAD")]

            current_branch = repo.active_branch.name if repo.active_branch else "HEAD"

            return ToolResult(
                success=True,
                data={
                    "current_branch": current_branch,
                    "untracked_files": untracked_files,
                    "modified_files": modified_files,
                    "staged_files": staged_files,
                    "clean": len(untracked_files) == 0
                    and len(modified_files) == 0
                    and len(staged_files) == 0,
                },
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


class GitDiffArgs(BaseModel):
    file_path: str = Field(default="", description="Specific file to diff (optional)")
    staged: bool = Field(
        default=False,
        description="Show staged changes instead of working directory changes",
    )


class GitDiff(Tool):
    def get_name(self) -> str:
        return "git_diff"

    def get_description(self) -> str:
        return "Show git diff for changes"

    def get_args_schema(self) -> Type[BaseModel]:
        return GitDiffArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            try:
                repo = git.Repo(os.getcwd())
            except git.InvalidGitRepositoryError:
                return ToolResult(success=False, error="Not in a git repository")

            if args.staged:
                diff = repo.index.diff("HEAD")
            else:
                diff = repo.index.diff(None)

            diff_text = ""
            files_changed = []

            for item in diff:
                file_path = item.a_path or item.b_path
                if args.file_path and file_path != args.file_path:
                    continue

                files_changed.append(file_path)

                if hasattr(item, "diff") and item.diff:
                    diff_text += f"\n--- a/{file_path}\n+++ b/{file_path}\n"
                    diff_text += item.diff.decode("utf-8", errors="replace")

            return ToolResult(
                success=True,
                data={
                    "diff": diff_text,
                    "files_changed": files_changed,
                    "staged": args.staged,
                },
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


===== EQUITR-coder/EQUITR_coder/tools/builtin/git_auto.py =====


import subprocess
from datetime import datetime
from pathlib import Path


class GitAutoCommit:
    

    def __init__(self, repo_path: str):
        self.repo_path = Path(repo_path)
        self.enabled = self._check_git_repo()

    def _check_git_repo(self) -> bool:
        
        try:
            _result = subprocess.run(
                ["git", "rev-parse", "--git-dir"],
                cwd=self.repo_path,
                capture_output=True,
                text=True,
                check=True,
            )
            return True
        except subprocess.CalledProcessError:
            return False

    def commit_all(self, message: str, allow_empty: bool = False) -> bool:
        
        if not self.enabled:
            print("‚ö†Ô∏è  Not in a git repository, skipping commit")
            return False

        try:
            subprocess.run(
                ["git", "add", "."], cwd=self.repo_path, check=True, capture_output=True
            )

            if not allow_empty:
                result = subprocess.run(
                    ["git", "diff", "--cached", "--quiet"],
                    cwd=self.repo_path,
                    capture_output=True,
                )
                if result.returncode == 0:
                    print("‚ÑπÔ∏è  No changes to commit")
                    return True

            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            full_message = f"{message}\n\nAuto-commit at {timestamp}"

            subprocess.run(
                ["git", "commit", "-m", full_message],
                cwd=self.repo_path,
                check=True,
                capture_output=True,
            )

            print(f"‚úÖ Committed: {message}")
            return True

        except subprocess.CalledProcessError as e:
            print(f"‚ùå Git commit failed: {e}")
            return False

    def commit_planning_start(self) -> bool:
        
        return self.commit_all("üéØ Start planning phase")

    def commit_planning_complete(self) -> bool:
        
        return self.commit_all("üìã Planning phase complete - documents generated")

    def commit_checkpoint(self, task_title: str) -> bool:
        
        safe_title = task_title.replace('"', "").replace("'", "")[:50]
        return self.commit_all(f"‚úÖ Checkpoint: {safe_title}")

    def commit_task_start(self, task_title: str) -> bool:
        
        safe_title = task_title.replace('"', "").replace("'", "")[:50]
        return self.commit_all(f"üöÄ Starting: {safe_title}")

    def get_status(self) -> dict:
        
        if not self.enabled:
            return {"enabled": False, "message": "Not a git repository"}

        try:
            branch_result = subprocess.run(
                ["git", "rev-parse", "--abbrev-ref", "HEAD"],
                cwd=self.repo_path,
                capture_output=True,
                text=True,
                check=True,
            )

            commit_result = subprocess.run(
                ["git", "log", "-1", "--oneline"],
                cwd=self.repo_path,
                capture_output=True,
                text=True,
                check=True,
            )

            status_result = subprocess.run(
                ["git", "status", "--porcelain"],
                cwd=self.repo_path,
                capture_output=True,
                text=True,
                check=True,
            )

            return {
                "enabled": True,
                "branch": branch_result.stdout.strip(),
                "last_commit": commit_result.stdout.strip(),
                "changes": len(status_result.stdout.strip().split("\n"))
                if status_result.stdout.strip()
                else 0,
            }

        except subprocess.CalledProcessError as e:
            return {"enabled": False, "message": f"Git error: {e}"}


===== EQUITR-coder/EQUITR_coder/tools/builtin/search.py =====
from typing import Type
from pydantic import BaseModel, Field
from ddgs import DDGS
from ..base import Tool, ToolResult


class SearchArgs(BaseModel):
    query: str = Field(..., description="Search query")
    max_results: int = Field(
        default=5, description="Maximum number of results to return"
    )


class WebSearch(Tool):
    def get_name(self) -> str:
        return "web_search"

    def get_description(self) -> str:
        return "Search the web using DuckDuckGo"

    def get_args_schema(self) -> Type[BaseModel]:
        return SearchArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            with DDGS() as ddgs:
                results = list(
                    ddgs.text(
                        args.query,
                        max_results=min(args.max_results, 10),  # Limit to 10 max
                    )
                )

            formatted_results = []
            for result in results:
                formatted_results.append(
                    {
                        "title": result.get("title", ""),
                        "url": result.get("href", ""),
                        "snippet": result.get("body", ""),
                    }
                )

            return ToolResult(
                success=True,
                data={
                    "query": args.query,
                    "results": formatted_results,
                    "total_results": len(formatted_results),
                },
            )

        except Exception as e:
            return ToolResult(success=False, error=str(e))


===== EQUITR-coder/EQUITR_coder/tools/builtin/shell.py =====
import asyncio
import os
import tempfile
import venv
from pathlib import Path
from typing import Type
from pydantic import BaseModel, Field
from ..base import Tool, ToolResult


class RunCommandArgs(BaseModel):
    command: str = Field(..., description="Shell command to execute")
    timeout: int = Field(default=30, description="Command timeout in seconds")
    use_venv: bool = Field(
        default=True, description="Run command in virtual environment"
    )


class RunCommand(Tool):
    def get_name(self) -> str:
        return "run_command"

    def get_description(self) -> str:
        return "Execute shell commands in a sandboxed environment. For complex system analysis, debugging intricate issues, or when understanding command outputs requires deep technical insight, use a stronger reasoning model to interpret results and suggest optimal solutions."

    def get_args_schema(self) -> Type[BaseModel]:
        return RunCommandArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            dangerous_commands = [
                "rm -rf",
                "sudo",
                "su",
                "chmod +x",
                "dd if=",
                "format",
                "del /",
                "rmdir /s",
                ":(){ :|:& };:",
                "fork()",
                "while true",
            ]

            for dangerous in dangerous_commands:
                if dangerous.lower() in args.command.lower():
                    return ToolResult(
                        success=False,
                        error=f"Command contains potentially dangerous pattern: {dangerous}",
                    )

            if args.use_venv:
                return await self._run_in_venv(args.command, args.timeout)
            else:
                return await self._run_direct(args.command, args.timeout)

        except Exception as e:
            return ToolResult(success=False, error=str(e))

    async def _run_in_venv(self, command: str, timeout: int) -> ToolResult:
        
        with tempfile.TemporaryDirectory() as temp_dir:
            venv_path = Path(temp_dir) / "sandbox_venv"

            venv.create(venv_path, with_pip=True, clear=True)

            if os.name == "nt":  # Windows
                activate_script = venv_path / "Scripts" / "activate.bat"
                shell_cmd = f'"{activate_script}" && {command}'
                shell = True
            else:  # Unix/Linux/macOS
                activate_script = venv_path / "bin" / "activate"
                shell_cmd = f'source "{activate_script}" && {command}'
                shell = ["/bin/bash", "-c", shell_cmd]

            try:
                process = await asyncio.create_subprocess_exec(
                    *shell if isinstance(shell, list) else shell_cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE,
                    cwd=os.getcwd(),
                    shell=isinstance(shell, bool) and shell,
                )

                stdout, stderr = await asyncio.wait_for(
                    process.communicate(), timeout=timeout
                )

                return ToolResult(
                    success=process.returncode == 0,
                    data={
                        "exit_code": process.returncode,
                        "stdout": stdout.decode("utf-8", errors="replace")[
                            -4000:
                        ],  # Limit output
                        "stderr": stderr.decode("utf-8", errors="replace")[-4000:],
                        "command": command,
                        "sandboxed": True,
                    },
                )

            except asyncio.TimeoutError:
                try:
                    process.kill()
                    await process.wait()
                except Exception:
                    pass
                return ToolResult(
                    success=False, error=f"Command timed out after {timeout} seconds"
                )

    async def _run_direct(self, command: str, timeout: int) -> ToolResult:
        
        try:
            process = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=os.getcwd(),
            )

            stdout, stderr = await asyncio.wait_for(
                process.communicate(), timeout=timeout
            )

            return ToolResult(
                success=process.returncode == 0,
                data={
                    "exit_code": process.returncode,
                    "stdout": stdout.decode("utf-8", errors="replace")[-4000:],
                    "stderr": stderr.decode("utf-8", errors="replace")[-4000:],
                    "command": command,
                    "sandboxed": False,
                },
            )

        except asyncio.TimeoutError:
            try:
                process.kill()
                await process.wait()
            except Exception:
                pass
            return ToolResult(
                success=False, error=f"Command timed out after {timeout} seconds"
            )


===== EQUITR-coder/EQUITR_coder/tools/builtin/todo.py =====
import json
from datetime import datetime
from pathlib import Path
from typing import Type, List, Dict, Any, Optional
from pydantic import BaseModel, Field
from ..base import Tool, ToolResult


class TodoItem(BaseModel):
    id: str
    title: str
    description: str = ""
    status: str = "pending"  # pending, in_progress, completed, cancelled
    priority: str = "medium"  # low, medium, high, urgent
    created_at: datetime
    updated_at: datetime
    due_date: Optional[datetime] = None
    tags: List[str] = Field(default_factory=list)
    assignee: Optional[str] = None


class TodoList(BaseModel):
    todos: List[TodoItem] = Field(default_factory=list)
    metadata: Dict[str, Any] = Field(default_factory=dict)


class CreateTodoArgs(BaseModel):
    title: str = Field(..., description="Title of the todo item")
    description: str = Field(default="", description="Detailed description of the todo")
    priority: str = Field(
        default="medium", description="Priority: low, medium, high, urgent"
    )
    due_date: Optional[str] = Field(
        default=None, description="Due date in ISO format (YYYY-MM-DD)"
    )
    tags: List[str] = Field(default_factory=list, description="Tags for categorization")
    assignee: Optional[str] = Field(
        default=None, description="Person assigned to this todo"
    )


class UpdateTodoArgs(BaseModel):
    todo_id: str = Field(..., description="ID of the todo to update")
    title: Optional[str] = Field(default=None, description="New title")
    description: Optional[str] = Field(default=None, description="New description")
    status: Optional[str] = Field(
        default=None,
        description="New status: pending, in_progress, completed, cancelled",
    )
    priority: Optional[str] = Field(
        default=None, description="New priority: low, medium, high, urgent"
    )
    due_date: Optional[str] = Field(
        default=None, description="New due date in ISO format"
    )
    tags: Optional[List[str]] = Field(default=None, description="New tags")
    assignee: Optional[str] = Field(default=None, description="New assignee")


class DeleteTodoArgs(BaseModel):
    todo_id: str = Field(..., description="ID of the todo to delete")


class ListTodosArgs(BaseModel):
    status: Optional[str] = Field(default=None, description="Filter by status")
    priority: Optional[str] = Field(default=None, description="Filter by priority")
    assignee: Optional[str] = Field(default=None, description="Filter by assignee")
    tag: Optional[str] = Field(default=None, description="Filter by tag")


class TodoManager:
    

    def __init__(self, todo_file: str = ".EQUITR_todos.json"):
        self.todo_file = Path(todo_file)
        self._load_todos()

    def _load_todos(self):
        
        if self.todo_file.exists():
            try:
                with open(self.todo_file, "r") as f:
                    data = json.load(f)
                    for todo_data in data.get("todos", []):
                        todo_data["created_at"] = datetime.fromisoformat(
                            todo_data["created_at"]
                        )
                        todo_data["updated_at"] = datetime.fromisoformat(
                            todo_data["updated_at"]
                        )
                        if todo_data.get("due_date"):
                            todo_data["due_date"] = datetime.fromisoformat(
                                todo_data["due_date"]
                            )
                    self.todo_list = TodoList(**data)
            except Exception as e:
                print(f"Warning: Could not load todos: {e}")
                self.todo_list = TodoList()
        else:
            self.todo_list = TodoList()

    def _save_todos(self):
        
        try:
            data = self.todo_list.model_dump()
            for todo_data in data["todos"]:
                todo_data["created_at"] = todo_data["created_at"].isoformat()
                todo_data["updated_at"] = todo_data["updated_at"].isoformat()
                if todo_data.get("due_date"):
                    todo_data["due_date"] = todo_data["due_date"].isoformat()

            with open(self.todo_file, "w") as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            print(f"Warning: Could not save todos: {e}")

    def create_todo(self, **kwargs) -> TodoItem:
        
        now = datetime.now()

        todo_id = f"todo_{now.strftime('%Y%m%d_%H%M%S')}_{len(self.todo_list.todos)}"

        due_date = None
        if kwargs.get("due_date"):
            try:
                due_date = datetime.fromisoformat(kwargs["due_date"])
            except ValueError:
                pass

        todo = TodoItem(
            id=todo_id,
            title=kwargs["title"],
            description=kwargs.get("description", ""),
            priority=kwargs.get("priority", "medium"),
            created_at=now,
            updated_at=now,
            due_date=due_date,
            tags=kwargs.get("tags", []),
            assignee=kwargs.get("assignee"),
        )

        self.todo_list.todos.append(todo)
        self._save_todos()
        return todo

    def update_todo(self, todo_id: str, **kwargs) -> Optional[TodoItem]:
        
        todo = self.get_todo(todo_id)
        if not todo:
            return None

        now = datetime.now()

        for field, value in kwargs.items():
            if value is not None:
                if field == "due_date" and isinstance(value, str):
                    try:
                        value = datetime.fromisoformat(value)
                    except ValueError:
                        continue
                setattr(todo, field, value)

        todo.updated_at = now
        self._save_todos()
        return todo

    def delete_todo(self, todo_id: str) -> bool:
        
        for i, todo in enumerate(self.todo_list.todos):
            if todo.id == todo_id:
                del self.todo_list.todos[i]
                self._save_todos()
                return True
        return False

    def get_todo(self, todo_id: str) -> Optional[TodoItem]:
        
        for todo in self.todo_list.todos:
            if todo.id == todo_id:
                return todo
        return None

    def list_todos(self, **filters) -> List[TodoItem]:
        
        todos = self.todo_list.todos

        if filters.get("status"):
            todos = [t for t in todos if t.status == filters["status"]]
        if filters.get("priority"):
            todos = [t for t in todos if t.priority == filters["priority"]]
        if filters.get("assignee"):
            todos = [t for t in todos if t.assignee == filters["assignee"]]
        if filters.get("tag"):
            todos = [t for t in todos if filters["tag"] in t.tags]

        return todos


todo_manager = TodoManager()


class CreateTodo(Tool):
    def get_name(self) -> str:
        return "create_todo"

    def get_description(self) -> str:
        return "Create a new todo item"

    def get_args_schema(self) -> Type[BaseModel]:
        return CreateTodoArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)
            todo = todo_manager.create_todo(**args.model_dump())

            return ToolResult(
                success=True,
                data={
                    "todo": {
                        "id": todo.id,
                        "title": todo.title,
                        "description": todo.description,
                        "status": todo.status,
                        "priority": todo.priority,
                        "created_at": todo.created_at.isoformat(),
                        "due_date": todo.due_date.isoformat()
                        if todo.due_date
                        else None,
                        "tags": todo.tags,
                        "assignee": todo.assignee,
                    }
                },
            )
        except Exception as e:
            return ToolResult(success=False, error=str(e))


class UpdateTodo(Tool):
    def get_name(self) -> str:
        return "update_todo"

    def get_description(self) -> str:
        return "Update an existing todo item"

    def get_args_schema(self) -> Type[BaseModel]:
        return UpdateTodoArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)

            todo_id = args.todo_id
            update_data = {
                k: v
                for k, v in args.model_dump().items()
                if k != "todo_id" and v is not None
            }

            todo = todo_manager.update_todo(todo_id, **update_data)

            if not todo:
                return ToolResult(
                    success=False, error=f"Todo with ID '{todo_id}' not found"
                )

            return ToolResult(
                success=True,
                data={
                    "todo": {
                        "id": todo.id,
                        "title": todo.title,
                        "description": todo.description,
                        "status": todo.status,
                        "priority": todo.priority,
                        "updated_at": todo.updated_at.isoformat(),
                        "due_date": todo.due_date.isoformat()
                        if todo.due_date
                        else None,
                        "tags": todo.tags,
                        "assignee": todo.assignee,
                    }
                },
            )
        except Exception as e:
            return ToolResult(success=False, error=str(e))


class DeleteTodo(Tool):
    def get_name(self) -> str:
        return "delete_todo"

    def get_description(self) -> str:
        return "Delete a todo item"

    def get_args_schema(self) -> Type[BaseModel]:
        return DeleteTodoArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)
            success = todo_manager.delete_todo(args.todo_id)

            if not success:
                return ToolResult(
                    success=False, error=f"Todo with ID '{args.todo_id}' not found"
                )

            return ToolResult(
                success=True,
                data={"message": f"Todo '{args.todo_id}' deleted successfully"},
            )
        except Exception as e:
            return ToolResult(success=False, error=str(e))


class ListTodos(Tool):
    def get_name(self) -> str:
        return "list_todos"

    def get_description(self) -> str:
        return "List todos with optional filters"

    def get_args_schema(self) -> Type[BaseModel]:
        return ListTodosArgs

    async def run(self, **kwargs) -> ToolResult:
        try:
            args = self.validate_args(kwargs)
            filters = {k: v for k, v in args.model_dump().items() if v is not None}
            todos = todo_manager.list_todos(**filters)

            todo_list = []
            for todo in todos:
                todo_list.append(
                    {
                        "id": todo.id,
                        "title": todo.title,
                        "description": todo.description,
                        "status": todo.status,
                        "priority": todo.priority,
                        "created_at": todo.created_at.isoformat(),
                        "updated_at": todo.updated_at.isoformat(),
                        "due_date": todo.due_date.isoformat()
                        if todo.due_date
                        else None,
                        "tags": todo.tags,
                        "assignee": todo.assignee,
                    }
                )

            return ToolResult(
                success=True,
                data={
                    "todos": todo_list,
                    "count": len(todo_list),
                    "filters_applied": filters,
                },
            )
        except Exception as e:
            return ToolResult(success=False, error=str(e))


===== EQUITR-coder/EQUITR_coder/core/__init__.py =====
from .orchestrator import AgentOrchestrator
from .config import Config, ConfigManager

__all__ = ["AgentOrchestrator", "Config", "ConfigManager"]


===== EQUITR-coder/EQUITR_coder/core/config.py =====
import os
import yaml
from pathlib import Path
from typing import Dict, Any, List
from pydantic import BaseModel, Field


class LLMConfig(BaseModel):
    provider: str = "litellm"  # Use LiteLLM as default
    model: str = ""  # No default model - users must select one
    api_base: str = ""
    api_key: str = ""
    budget: float = 1.0
    temperature: float = 0.1
    max_tokens: int = 4000

    models: Dict[str, Dict[str, Any]] = Field(default_factory=dict)

    active_model: str = ""

    provider_settings: Dict[str, Dict[str, Any]] = Field(default_factory=dict)


class ToolsConfig(BaseModel):
    enabled: list[str] = Field(default_factory=lambda: ["fs", "git", "shell", "search"])
    disabled: list[str] = Field(default_factory=list)


class SandboxConfig(BaseModel):
    type: str = "venv"
    timeout: int = 30
    max_memory: int = 512
    allow_network: bool = False


class SessionConfig(BaseModel):
    persist: bool = True
    max_context: int = 100000
    session_dir: str = "~/.EQUITR-coder/sessions"


class RepositoryConfig(BaseModel):
    index_on_start: bool = True
    ignore_patterns: list[str] = Field(
        default_factory=lambda: [
            "*.pyc",
            "__pycache__",
            ".git",
            "node_modules",
            ".venv",
            "venv",
            "*.log",
        ]
    )


class OrchestratorConfig(BaseModel):
    max_iterations: int = 20
    error_retry_limit: int = 3
    error_retry_delay: float = 1.0
    use_multi_agent: bool = False  # Enable strong/weak agent paradigm


class ProfilesConfig(BaseModel):
    default: str = "default"
    available: list[str] = Field(
        default_factory=lambda: ["ml_researcher", "app_developer"]
    )


class Config(BaseModel):
    llm: LLMConfig = Field(default_factory=LLMConfig)
    tools: ToolsConfig = Field(default_factory=ToolsConfig)
    sandbox: SandboxConfig = Field(default_factory=SandboxConfig)
    session: SessionConfig = Field(default_factory=SessionConfig)
    repository: RepositoryConfig = Field(default_factory=RepositoryConfig)
    orchestrator: OrchestratorConfig = Field(default_factory=OrchestratorConfig)
    profiles: ProfilesConfig = Field(default_factory=ProfilesConfig)


class ConfigManager:
    def __init__(self):
        self.config_dir = Path(__file__).parent.parent / "config"
        self.user_config_dir = Path.home() / ".EQUITR-coder"
        self.user_config_dir.mkdir(exist_ok=True)

    def load_config(self, profile: str = "default") -> Config:
        config_data = self._load_yaml_file(self.config_dir / "default.yaml")

        if profile != "default":
            profile_file = self.config_dir / f"{profile}.yaml"
            if profile_file.exists():
                profile_data = self._load_yaml_file(profile_file)
                config_data = self._merge_configs(config_data, profile_data)

        user_config_file = self.user_config_dir / "config.yaml"
        if user_config_file.exists():
            user_data = self._load_yaml_file(user_config_file)
            config_data = self._merge_configs(config_data, user_data)

        config_data = self._apply_env_overrides(config_data)

        return Config(**config_data)

    def _load_yaml_file(self, file_path: Path) -> Dict[str, Any]:
        with open(file_path, "r") as f:
            return yaml.safe_load(f) or {}

    def _merge_configs(
        self, base: Dict[str, Any], override: Dict[str, Any]
    ) -> Dict[str, Any]:
        
        result = base.copy()
        for key, value in override.items():
            if (
                key in result
                and isinstance(result[key], dict)
                and isinstance(value, dict)
            ):
                result[key] = self._merge_configs(result[key], value)
            else:
                result[key] = value
        return result

    def _apply_env_overrides(self, config_data: Dict[str, Any]) -> Dict[str, Any]:
        
        env_mappings = {
            "OPENROUTER_API_KEY": ("llm", "api_key"),
            "CLAUDE_AGENT_MODEL": ("llm", "model"),
            "CLAUDE_AGENT_BUDGET": ("llm", "budget"),
            "CLAUDE_AGENT_PROFILE": ("profiles", "default"),
        }

        for env_var, (section, key) in env_mappings.items():
            if env_var in os.environ:
                if section not in config_data:
                    config_data[section] = {}
                value = os.environ[env_var]
                if key in ["budget"]:
                    value = float(value)
                config_data[section][key] = value

        return config_data

    def save_user_config(self, config: Config):
        
        config_file = self.user_config_dir / "config.yaml"
        with open(config_file, "w") as f:
            yaml.dump(config.model_dump(), f, default_flow_style=False)

    def get_active_model_config(self, config: Config) -> Dict[str, Any]:
        
        active_model = config.llm.active_model
        if active_model in config.llm.models:
            model_config = config.llm.models[active_model].copy()

            if config.llm.api_key:
                model_config["api_key"] = config.llm.api_key
            if config.llm.api_base:
                model_config["api_base"] = config.llm.api_base
            if config.llm.budget:
                model_config["budget"] = config.llm.budget

            return model_config
        else:
            return {
                "provider": config.llm.provider,
                "model": config.llm.model,
                "api_key": config.llm.api_key,
                "api_base": config.llm.api_base,
                "temperature": config.llm.temperature,
                "max_tokens": config.llm.max_tokens,
                "budget": config.llm.budget,
            }

    def switch_model(self, config: Config, model_name: str) -> Config:
        
        if model_name in config.llm.models:
            config.llm.active_model = model_name
            return config
        else:
            raise ValueError(f"Model '{model_name}' not found in configuration")

    def add_model_config(
        self, config: Config, name: str, model_config: Dict[str, Any]
    ) -> Config:
        
        config.llm.models[name] = model_config
        return config

    def remove_model_config(self, config: Config, name: str) -> Config:
        
        if name in config.llm.models:
            del config.llm.models[name]
            if config.llm.active_model == name:
                config.llm.active_model = "default"
        return config

    def get_available_models(self, config: Config) -> List[str]:
        
        return list(config.llm.models.keys())

    def discover_lite_llm_models(
        self, api_base: str = "http://localhost:4000"
    ) -> List[str]:
        
        from EQUITR_coder.providers.model_discovery import LiteLLMModelDiscovery

        discovery = LiteLLMModelDiscovery(api_base)
        return discovery.get_model_names(sync=True)


config_manager = ConfigManager()


===== EQUITR-coder/EQUITR_coder/core/context_compressor.py =====


from __future__ import annotations

import asyncio
from typing import List

from .context_manager import ContextManager
from ..providers.openrouter import Message  # shared pydantic model


class ContextCompressor:
    

    def __init__(self, provider, max_summary_tokens: int = 1024):
        self.provider = provider
        self.counter = ContextManager(max_tokens=100000)
        self.max_summary_tokens = max_summary_tokens

    async def compress(self, messages: List[Message]) -> Message:
        
        if not messages:
            return Message(role="system", content="(empty summary)")

        conversation_text = "\n\n".join(
            [f"{m.role.upper()}: {m.content}" for m in messages]
        )

        summarise_prompt = (
            "You are a context-compression assistant.  Summarise the following "
            "conversation into a concise, bullet-point brief capturing all key "
            "technical decisions, file names, todos and reasoning required to "
            "continue the task.  Keep it under 800 words.  Do **not** lose any "
            "important detail needed for future work.\n\nCONVERSATION:\n" + conversation_text
        )

        response = await self.provider.chat(
            messages=[Message(role="user", content=summarise_prompt)],
            temperature=0.2,
            max_tokens=self.max_summary_tokens,
        )

        return Message(role="system", content="COMPRESSED CONTEXT SUMMARY:\n" + response.content) 

===== EQUITR-coder/EQUITR_coder/core/context_manager.py =====
import tiktoken
from typing import List
from ..providers.openrouter import Message


class ContextManager:
    

    def __init__(self, max_tokens: int = 100000, model: str = "gpt-3.5-turbo"):
        self.max_tokens = max_tokens
        self.encoding = tiktoken.encoding_for_model(
            "gpt-3.5-turbo"
        )  # Use default encoding

    def count_tokens(self, text: str) -> int:
        
        try:
            return len(self.encoding.encode(text))
        except Exception:
            return len(text) // 4

    def count_message_tokens(self, message: Message) -> int:
        
        return self.count_tokens(message.content) + 4  # +4 for message overhead

    def truncate_context(
        self, messages: List[Message], system_prompt: str = ""
    ) -> List[Message]:
        
        if not messages:
            return messages

        result = []
        total_tokens = self.count_tokens(system_prompt)

        if messages:
            last_msg = messages[-1]
            result.insert(0, last_msg)
            total_tokens += self.count_message_tokens(last_msg)

        for i in range(len(messages) - 2, -1, -1):
            msg = messages[i]
            msg_tokens = self.count_message_tokens(msg)

            if total_tokens + msg_tokens > self.max_tokens:
                break

            result.insert(0, msg)
            total_tokens += msg_tokens

        return result

    def should_truncate(self, messages: List[Message], system_prompt: str = "") -> bool:
        
        total_tokens = self.count_tokens(system_prompt)
        total_tokens += sum(self.count_message_tokens(msg) for msg in messages)
        return total_tokens > self.max_tokens

    def get_context_summary(self, messages: List[Message]) -> str:
        
        if not messages:
            return "Empty conversation"

        total_messages = len(messages)
        total_tokens = sum(self.count_message_tokens(msg) for msg in messages)

        return f"Context: {total_messages} messages, ~{total_tokens} tokens"


===== EQUITR-coder/EQUITR_coder/core/documentation.py =====


import json
from typing import Dict, List, Optional, Any
from pathlib import Path

from ..providers.openrouter import Message


class DocumentationGenerator:
    
    
    def __init__(self, provider, repo_path: str):
        self.provider = provider
        self.repo_path = Path(repo_path)
    
    async def generate_all_documents(self, conversation: List[Dict[str, str]]) -> Optional[Dict[str, str]]:
        
        try:
            conversation_text = self._format_conversation(conversation)
            
            requirements = await self._generate_requirements(conversation_text)
            if not requirements or not requirements.strip():
                raise Exception("CRITICAL: Requirements document generation failed - this is MANDATORY")
            
            design = await self._generate_design(conversation_text, requirements)
            if not design or not design.strip():
                raise Exception("CRITICAL: Design document generation failed - this is MANDATORY")
            
            todos = await self._generate_todos(conversation_text, requirements, design)
            if not todos or not todos.strip():
                raise Exception("CRITICAL: Todo list generation failed - this is MANDATORY")
            
            min_length = 100  # Minimum characters for a valid document
            if len(requirements.strip()) < min_length:
                raise Exception(f"CRITICAL: Requirements document too short ({len(requirements)} chars) - must be comprehensive")
            if len(design.strip()) < min_length:
                raise Exception(f"CRITICAL: Design document too short ({len(design)} chars) - must be comprehensive")
            if len(todos.strip()) < min_length:
                raise Exception(f"CRITICAL: Todo list too short ({len(todos)} chars) - must be comprehensive")
            
            await self._save_documents(requirements, design, todos)
            
            docs_result = {
                "requirements": requirements,
                "design": design,
                "todos": todos
            }
            
            for doc_type, content in docs_result.items():
                if not content or not content.strip():
                    raise Exception(f"CRITICAL: {doc_type} document is empty - ALL THREE DOCUMENTS ARE MANDATORY")
            
            print("‚úÖ Successfully generated ALL THREE MANDATORY documents")
            return docs_result
            
        except Exception as e:
            print(f"‚ùå CRITICAL ERROR generating MANDATORY documentation: {e}")
            return None
    
    def _format_conversation(self, conversation: List[Dict[str, str]]) -> str:
        
        formatted = []
        for msg in conversation:
            role = msg["role"].upper()
            content = msg["content"]
            formatted.append(f"{role}: {content}")
        return "\n\n".join(formatted)
    
    async def _generate_requirements(self, conversation_text: str) -> Optional[str]:
        
        prompt = f
        
        try:
            response = await self.provider.chat(
                messages=[Message(role="user", content=prompt)],
                temperature=0.3,
                max_tokens=2000
            )
            return response.content
        except Exception as e:
            print(f"Error generating requirements: {e}")
            return None
    
    async def _generate_design(self, conversation_text: str, requirements: str) -> Optional[str]:
        
        prompt = f
        
        try:
            response = await self.provider.chat(
                messages=[Message(role="user", content=prompt)],
                temperature=0.3,
                max_tokens=2500
            )
            return response.content
        except Exception as e:
            print(f"Error generating design: {e}")
            return None
    
    async def _generate_todos(self, conversation_text: str, requirements: str, design: str) -> Optional[str]:
        
        prompt = f
        
        try:
            response = await self.provider.chat(
                messages=[Message(role="user", content=prompt)],
                temperature=0.3,
                max_tokens=2000
            )
            return response.content
        except Exception as e:
            print(f"Error generating todos: {e}")
            return None
    
    async def _save_documents(self, requirements: str, design: str, todos: str) -> None:
        
        try:
            docs_dir = self.repo_path / "docs"
            docs_dir.mkdir(exist_ok=True)
            
            (docs_dir / "requirements.md").write_text(requirements, encoding="utf-8")
            
            (docs_dir / "design.md").write_text(design, encoding="utf-8")
            
            (docs_dir / "todos.md").write_text(todos, encoding="utf-8")
            
            print(f"üìÅ Documents saved to {docs_dir}")
            
        except Exception as e:
            print(f"Error saving documents: {e}")
    
    def get_existing_documents(self) -> Optional[Dict[str, str]]:
        
        try:
            docs_dir = self.repo_path / "docs"
            if not docs_dir.exists():
                print("‚ùå CRITICAL: No docs directory found - ALL THREE DOCUMENTS ARE MANDATORY")
                return None
            
            docs = {}
            required_files = {
                "requirements": "requirements.md",
                "design": "design.md", 
                "todos": "todos.md"
            }
            
            missing_files = []
            empty_files = []
            
            for doc_type, filename in required_files.items():
                file_path = docs_dir / filename
                if not file_path.exists():
                    missing_files.append(filename)
                else:
                    content = file_path.read_text(encoding="utf-8")
                    if not content.strip():
                        empty_files.append(filename)
                    else:
                        docs[doc_type] = content
            
            if missing_files:
                print(f"‚ùå CRITICAL: Missing MANDATORY documentation files: {', '.join(missing_files)}")
                return None
            
            if empty_files:
                print(f"‚ùå CRITICAL: Empty MANDATORY documentation files: {', '.join(empty_files)}")
                return None
            
            if len(docs) != 3:
                print(f"‚ùå CRITICAL: Expected 3 documents, found {len(docs)}. ALL THREE ARE MANDATORY.")
                return None
            
            min_length = 50  # Minimum characters for a valid document
            for doc_type, content in docs.items():
                if len(content.strip()) < min_length:
                    print(f"‚ùå CRITICAL: {doc_type} document too short ({len(content)} chars) - must be comprehensive")
                    return None
            
            print("‚úÖ All three MANDATORY documents loaded successfully")
            return docs
            
        except Exception as e:
            print(f"‚ùå CRITICAL ERROR loading MANDATORY documents: {e}")
            return None

===== EQUITR-coder/EQUITR_coder/core/message_pool.py =====


import asyncio
from datetime import datetime
from typing import Dict, List, Optional, Any, Set
from dataclasses import dataclass, asdict
from enum import Enum


class MessageType(Enum):
    

    INFO = "info"
    REQUEST = "request"
    RESPONSE = "response"
    STATUS_UPDATE = "status_update"
    COORDINATION = "coordination"
    ERROR = "error"


@dataclass
class AgentMessage:
    

    id: str
    sender_agent: str
    recipient_agent: Optional[str]  # None for broadcast messages
    message_type: MessageType
    content: str
    metadata: Dict[str, Any]
    timestamp: datetime
    task_id: Optional[str] = None
    thread_id: Optional[str] = None
    priority: int = 5  # 1-10, higher is more urgent

    def to_dict(self) -> Dict[str, Any]:
        
        data = asdict(self)
        data["message_type"] = self.message_type.value
        data["timestamp"] = self.timestamp.isoformat()
        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "AgentMessage":
        
        data["message_type"] = MessageType(data["message_type"])
        data["timestamp"] = datetime.fromisoformat(data["timestamp"])
        return cls(**data)


class MessagePool:
    

    def __init__(self, max_messages: int = 1000):
        self.max_messages = max_messages
        self.messages: List[AgentMessage] = []
        self.message_index: Dict[str, AgentMessage] = {}
        self.agent_subscriptions: Dict[
            str, Set[str]
        ] = {}  # agent -> set of message types
        self.message_queues: Dict[str, asyncio.Queue] = {}  # agent -> message queue
        self.lock = asyncio.Lock()
        self._message_counter = 0

    async def register_agent(
        self, agent_name: str, subscriptions: Optional[List[str]] = None
    ):
        
        async with self.lock:
            if subscriptions is None:
                subscriptions = [msg_type.value for msg_type in MessageType]

            self.agent_subscriptions[agent_name] = set(subscriptions)
            self.message_queues[agent_name] = asyncio.Queue()

    async def unregister_agent(self, agent_name: str):
        
        async with self.lock:
            self.agent_subscriptions.pop(agent_name, None)
            self.message_queues.pop(agent_name, None)

    async def send_message(
        self,
        sender_agent: str,
        content: str,
        message_type: MessageType = MessageType.INFO,
        recipient_agent: Optional[str] = None,
        task_id: Optional[str] = None,
        thread_id: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
        priority: int = 5,
    ) -> str:
        
        async with self.lock:
            self._message_counter += 1
            message_id = f"msg_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{self._message_counter}"

            message = AgentMessage(
                id=message_id,
                sender_agent=sender_agent,
                recipient_agent=recipient_agent,
                message_type=message_type,
                content=content,
                metadata=metadata or {},
                timestamp=datetime.now(),
                task_id=task_id,
                thread_id=thread_id,
                priority=priority,
            )

            self.messages.append(message)
            self.message_index[message_id] = message

            if len(self.messages) > self.max_messages:
                old_message = self.messages.pop(0)
                self.message_index.pop(old_message.id, None)

            await self._route_message(message)

            return message_id

    async def _route_message(self, message: AgentMessage):
        
        target_agents = []

        if message.recipient_agent:
            if message.recipient_agent in self.message_queues:
                target_agents.append(message.recipient_agent)
        else:
            for agent_name, subscriptions in self.agent_subscriptions.items():
                if (
                    message.message_type.value in subscriptions
                    and agent_name != message.sender_agent
                ):  # Don't send to sender
                    target_agents.append(agent_name)

        for agent_name in target_agents:
            if agent_name in self.message_queues:
                try:
                    await self.message_queues[agent_name].put(message)
                except asyncio.QueueFull:
                    try:
                        self.message_queues[agent_name].get_nowait()
                        await self.message_queues[agent_name].put(message)
                    except asyncio.QueueEmpty:
                        pass

    async def get_messages_for_agent(
        self, agent_name: str, timeout: float = 0.1
    ) -> List[AgentMessage]:
        
        if agent_name not in self.message_queues:
            return []

        messages = []
        queue = self.message_queues[agent_name]

        try:
            while True:
                try:
                    message = queue.get_nowait()
                    messages.append(message)
                except asyncio.QueueEmpty:
                    break
        except Exception:
            pass

        messages.sort(key=lambda m: (-m.priority, m.timestamp))
        return messages

    async def wait_for_message(
        self, agent_name: str, timeout: Optional[float] = None
    ) -> Optional[AgentMessage]:
        
        if agent_name not in self.message_queues:
            return None

        try:
            message = await asyncio.wait_for(
                self.message_queues[agent_name].get(), timeout=timeout
            )
            return message
        except asyncio.TimeoutError:
            return None

    async def get_message_history(
        self,
        agent_name: Optional[str] = None,
        task_id: Optional[str] = None,
        thread_id: Optional[str] = None,
        message_type: Optional[MessageType] = None,
        limit: int = 100,
    ) -> List[AgentMessage]:
        
        async with self.lock:
            filtered_messages = self.messages

            if agent_name:
                filtered_messages = [
                    m
                    for m in filtered_messages
                    if m.sender_agent == agent_name or m.recipient_agent == agent_name
                ]

            if task_id:
                filtered_messages = [
                    m for m in filtered_messages if m.task_id == task_id
                ]

            if thread_id:
                filtered_messages = [
                    m for m in filtered_messages if m.thread_id == thread_id
                ]

            if message_type:
                filtered_messages = [
                    m for m in filtered_messages if m.message_type == message_type
                ]

            return filtered_messages[-limit:][::-1]

    async def get_active_agents(self) -> List[str]:
        
        async with self.lock:
            return list(self.agent_subscriptions.keys())

    async def get_pool_status(self) -> Dict[str, Any]:
        
        async with self.lock:
            return {
                "total_messages": len(self.messages),
                "active_agents": list(self.agent_subscriptions.keys()),
                "queue_sizes": {
                    agent: queue.qsize() for agent, queue in self.message_queues.items()
                },
                "message_types_count": {
                    msg_type.value: sum(
                        1 for m in self.messages if m.message_type == msg_type
                    )
                    for msg_type in MessageType
                },
            }

    async def clear_messages(self, older_than_hours: Optional[int] = None):
        
        async with self.lock:
            if older_than_hours is None:
                self.messages.clear()
                self.message_index.clear()
            else:
                cutoff_time = datetime.now().timestamp() - (older_than_hours * 3600)
                self.messages = [
                    m for m in self.messages if m.timestamp.timestamp() > cutoff_time
                ]
                self.message_index = {m.id: m for m in self.messages}


message_pool = MessagePool()


===== EQUITR-coder/EQUITR_coder/core/orchestrator.py =====
import asyncio
import json
import time
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional
from tenacity import retry, stop_after_attempt, wait_exponential

from ..providers.openrouter import OpenRouterProvider, Message, ToolCall
from ..providers.litellm import LiteLLMProvider
from ..tools import registry, discovery
from ..repository.indexer import RepositoryIndexer
from .context_manager import ContextManager
from .session import SessionManagerV2
from .config import Config, config_manager
from .supervisor import SupervisorAgent
from .documentation import DocumentationGenerator
from ..tools.builtin.git_auto import GitAutoCommit
from ..utils.tool_logger import get_tool_logger, configure_tool_logger


class AgentOrchestrator:
    

    def __init__(
        self,
        config: Config,
        repo_path: str = ".",
        provider: Optional[OpenRouterProvider] = None,
        session_manager: Optional[SessionManagerV2] = None,
        available_tools: Optional[List[str]] = None,
        max_iterations: Optional[int] = None,
        model: Optional[str] = None,
        supervisor_model: Optional[str] = None,
        worker_model: Optional[str] = None,
    ):
        self.config = config
        self.repo_path = repo_path
        self._model_override = model
        self._supervisor_model_override = supervisor_model
        self._worker_model_override = worker_model

        configure_tool_logger(
            log_file=config.orchestrator.tool_log_file,
            enabled=config.orchestrator.log_tool_calls
        )
        self.tool_logger = get_tool_logger()

        self.provider = provider or self._create_provider(config)
        self.context_manager = ContextManager(
            max_tokens=config.session.max_context,
            model=getattr(self.provider, "model", config.llm.model),
        )
        self.session_manager = session_manager or SessionManagerV2(
            config.session.session_dir
        )
        self.repo_indexer = RepositoryIndexer(
            repo_path=repo_path, ignore_patterns=config.repository.ignore_patterns
        )
        self.git_auto = GitAutoCommit(repo_path)

        discovery.discover_builtin_tools()
        discovery.discover_custom_tools()

        if self.config.orchestrator.use_multi_agent:
            from EQUITR_coder.tools.builtin.ask_supervisor import (
                create_ask_supervisor_tool,
            )

            registry.register(create_ask_supervisor_tool(self.provider))

        self.available_tools = available_tools

        self.max_iterations = max_iterations or config.orchestrator.max_iterations

        self.total_cost = 0.0
        self.iteration_count = 0

        self._check_model_compatibility()

        supervisor_provider = self._create_supervisor_provider(config) if config.orchestrator.use_multi_agent else self.provider
        worker_provider = self._create_worker_provider(config) if config.orchestrator.use_multi_agent else self.provider
        
        self.supervisor = SupervisorAgent(
            supervisor_provider,
            self.session_manager,
            self.repo_path,
            use_multi_agent=config.orchestrator.use_multi_agent,
            worker_provider=worker_provider,
        )
        
        self.doc_generator = DocumentationGenerator(self.provider, self.repo_path)

        from .context_compressor import ContextCompressor
        self.context_compressor = ContextCompressor(self.provider)

    def _create_provider(self, config: Config):
        
        model_config = self._parse_model_override() or config_manager.get_active_model_config(
            config
        )
        provider_type = model_config.get("provider", "litellm")

        model_name = model_config.get("model", "")
        if not model_name:
            raise ValueError(
                "No model specified. Please select a model using:\n"
                "1. Run 'EQUITR-coder models --discover' to see available models\n"
                "2. Use --model parameter with your chosen model\n"
                "3. Set model in configuration"
            )

        if provider_type == "litellm":
            return LiteLLMProvider.from_config(model_config)
        elif provider_type == "openrouter":
            return OpenRouterProvider.from_env(model=model_name)
        else:
            return LiteLLMProvider.from_config(model_config)

    def _create_supervisor_provider(self, config: Config):
        
        model_override = (
            self._supervisor_model_override or 
            config.orchestrator.supervisor_model or 
            self._model_override
        )
        
        if model_override:
            temp_config = config.model_copy()
            temp_config.llm.model = model_override
            model_config = self._parse_model_override(model_override) or config_manager.get_active_model_config(temp_config)
        else:
            model_config = config_manager.get_active_model_config(config)
            
        provider_type = model_config.get("provider", "litellm")
        model_name = model_config.get("model", "")
        
        if not model_name:
            raise ValueError("No supervisor model specified")
            
        if provider_type == "litellm":
            return LiteLLMProvider.from_config(model_config)
        elif provider_type == "openrouter":
            return OpenRouterProvider.from_env(model=model_name)
        else:
            return LiteLLMProvider.from_config(model_config)

    def _create_worker_provider(self, config: Config):
        
        model_override = (
            self._worker_model_override or 
            config.orchestrator.worker_model or 
            self._model_override
        )
        
        if model_override:
            temp_config = config.model_copy()
            temp_config.llm.model = model_override
            model_config = self._parse_model_override(model_override) or config_manager.get_active_model_config(temp_config)
        else:
            model_config = config_manager.get_active_model_config(config)
            
        provider_type = model_config.get("provider", "litellm")
        model_name = model_config.get("model", "")
        
        if not model_name:
            raise ValueError("No worker model specified")
            
        if provider_type == "litellm":
            return LiteLLMProvider.from_config(model_config)
        elif provider_type == "openrouter":
            return OpenRouterProvider.from_env(model=model_name)
        else:
            return LiteLLMProvider.from_config(model_config)

    def _check_model_compatibility(self):
        
        from ..utils.litellm_utils import get_model_compatibility, get_compatible_tools

        model_name = getattr(self.provider, "model", self.config.llm.model)
        validation = get_model_compatibility(model_name)

        if not validation["function_calling"]:
            if validation["warnings"]:
                print(f"‚ö†Ô∏è  Warning: {validation['warnings'][0]}")
            print("   EQUITR Coder will continue without tool execution capabilities.")

        self.model_compatibility = validation

    def _parse_model_override(self, model_override: Optional[str] = None) -> Optional[Dict[str, Any]]:
        
        override = model_override or self._model_override
        if not override:
            return None

        if override in self.config.llm.models:
            return self.config.llm.models[override]

        if "/" in override:
            _provider_type, _model_name = override.split("/", 1)
        else:
            _provider_type, _model_name = "openai", override

        return {
            "provider": "litellm",
            "model": override,
            "temperature": self.config.llm.temperature,
            "max_tokens": self.config.llm.max_tokens,
            "api_key": self.config.llm.api_key,
            "api_base": self.config.llm.api_base,
        }

    async def run(self, user_input: str, session_id: Optional[str] = None, force_documentation: bool = True) -> dict:
        

        if session_id:
            session = self.session_manager.load_session(session_id)
            if not session:
                print(f"Session {session_id} not found, creating new session")
                session = self.session_manager.create_session(session_id)
        else:
            session = self.session_manager.create_session()

        docs = self.doc_generator.get_existing_documents()
        
        if not docs or not all(key in docs for key in ['requirements', 'design', 'todos']):
            print("üìã Generating mandatory documentation from user input...")
            
            planning_conversation = [
                {"role": "user", "content": user_input}
            ]
            
            docs = await self.doc_generator.generate_all_documents(planning_conversation)
            
            if not docs:
                error_msg = "CRITICAL: Failed to generate mandatory documentation. Please provide a clearer description of what you want to build."
            return {
                "content": error_msg,
                "usage": {},
                "cost": 0.0,
                    "error": "documentation_generation_failed"
            }
            
            print("‚úÖ Documentation generated successfully!")

        doc_context = f
        
        contextualized_input = doc_context

        if self.supervisor.should_use_multiagent(contextualized_input):
            return {
                "content": await self._run_multiagent(contextualized_input, session),
                "usage": {},
                "cost": self.total_cost,
            }
        else:
            return await self._run_single_agent(contextualized_input, session)

    async def _run_multiagent(self, user_input: str, session) -> str:
        

        if "MANDATORY PROJECT DOCUMENTATION CONTEXT" not in user_input:
            return "EXECUTION BLOCKED: No mandatory documentation context found in user input. All multi-agent execution must include requirements, design, and todos."

        print(f"ü§ñ Using multi-agent mode with MANDATORY documentation context")

        user_message = Message(role="user", content=user_input)
        self.session_manager.add_message(user_message)

        try:
            task_list = await self.supervisor.break_into_tasks(user_input)

            print(f"üìã Created {len(task_list.tasks)} tasks for multi-agent execution")

            results = await self.supervisor.spawn_workers(task_list)

            response_parts = []
            response_parts.append("‚úÖ Multi-agent execution completed!")
            response_parts.append(f"üìä Summary: {results['summary']}")

            if results["task_results"]:
                response_parts.append("\nüîç Task Results:")
                for task_id, result in results["task_results"].items():
                    if result["success"]:
                        response_parts.append(f"  ‚úì Task {task_id}: {result['result']}")
                    else:
                        response_parts.append(f"  ‚ùå Task {task_id}: {result['error']}")

            pool_status = await self.supervisor.get_status()
            if pool_status["recent_messages"]:
                response_parts.append("\nüí¨ Agent Communication Summary:")
                response_parts.append(
                    f"  - {len(pool_status['recent_messages'])} messages exchanged"
                )
                response_parts.append(
                    f"  - Active agents: {', '.join(pool_status['active_workers'])}"
                )

            response = "\n".join(response_parts)

            assistant_message = Message(role="assistant", content=response)
            self.session_manager.add_message(assistant_message)

            await self._check_and_trigger_multiagent_audit()

            return response

        except Exception as e:
            error_message = f"‚ùå Error in multi-agent execution: {str(e)}"
            print(error_message)

            error_msg = Message(role="assistant", content=error_message)
            self.session_manager.add_message(error_msg)

            return error_message

    @retry(
        stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=1, max=10)
    )
    async def _call_llm_with_retry(
        self, messages: List[Message], tool_schemas: List[Dict[str, Any]]
    ):
        
        tools_to_use = (
            tool_schemas
            if tool_schemas and self.model_compatibility["supported"]
            else None
        )

        print(f"DEBUG: Model compatibility: {self.model_compatibility}")
        print(f"DEBUG: Tool schemas provided: {len(tool_schemas) if tool_schemas else 0}")
        print(f"DEBUG: Tools to use: {len(tools_to_use) if tools_to_use else 0}")
        if tools_to_use:
            print(f"DEBUG: Tool names: {[tool.get('name', 'unknown') for tool in tools_to_use]}")

        if self.context_manager.should_truncate(messages, system_prompt="") and not any(
            m.content.startswith("COMPRESSED CONTEXT SUMMARY") for m in messages
        ):
            older_messages = messages[:-8] if len(messages) > 8 else []
            if older_messages:
                summary_msg = await self.context_compressor.compress(older_messages)
                messages = [summary_msg] + messages[-8:]

        response = await self.provider.chat(
            messages=messages,
            tools=tools_to_use,
            temperature=self.config.llm.temperature,
            max_tokens=self.config.llm.max_tokens,
        )
        
        print(f"DEBUG: Response has tool calls: {bool(response.tool_calls)}")
        if response.tool_calls:
            print(f"DEBUG: Tool calls: {[tc.function['name'] for tc in response.tool_calls]}")
            
        if self.config.orchestrator.debug:
            print(f"\nü§ñ LLM Response:")
            print(f"   Content: {response.content}")
            if response.tool_calls:
                print(f"   Tool calls ({len(response.tool_calls)}):")
                for i, tc in enumerate(response.tool_calls, 1):
                    print(f"     {i}. {tc.function['name']}: {tc.function.get('arguments', {})}")
            print()
            
        return response

    async def _execute_tools(
        self, tool_calls: List[ToolCall], enabled_tools: Dict[str, Any], session_id: Optional[str] = None
    ) -> List[Any]:
        
        tasks = []
        start_times = []

        for tool_call in tool_calls:
            tool_name = tool_call.function["name"]
            tool_args = tool_call.function.get("arguments", {})

            if isinstance(tool_args, str):
                try:
                    tool_args = json.loads(tool_args)
                except json.JSONDecodeError:
                    tool_args = {}

            if self.config.orchestrator.debug:
                print(f"üîß Executing tool: {tool_name}")
                print(f"   Args: {tool_args}")

            start_time = time.time()
            start_times.append(start_time)

            def _path_safe(p: str) -> bool:
                try:
                    root = Path(self.repo_path).resolve()
                    return Path(p).resolve().is_relative_to(root)
                except Exception:
                    return False

            dangerous = False
            for key in ("path", "target_file", "file", "filename"):
                if key in tool_args and isinstance(tool_args[key], str):
                    if not _path_safe(tool_args[key]):
                        dangerous = True
                        break

            if dangerous:
                from ..tools.base import ToolResult

                async def error_result():
                    return ToolResult(success=False, error="Path outside workspace is not allowed")

                tasks.append(error_result())
            else:
                if tool_name in enabled_tools:
                    tool = enabled_tools[tool_name]
                    tasks.append(tool.run(**tool_args))
                else:
                    async def error_result():
                        from ..tools.base import ToolResult
                        return ToolResult(success=False, error=f"Tool '{tool_name}' not found or not enabled")

                    tasks.append(error_result())

        results = await asyncio.gather(*tasks, return_exceptions=True)

        final_results = []
        for i, (tool_call, result) in enumerate(zip(tool_calls, results)):
            duration_ms = (time.time() - start_times[i]) * 1000
            tool_name = tool_call.function["name"]
            
            if isinstance(result, Exception):
                from ..tools.base import ToolResult
                tool_result = ToolResult(success=False, error=str(result))
                final_results.append(tool_result)
            else:
                tool_result = result
                final_results.append(result)
            
            if self.config.orchestrator.debug:
                status = "‚úÖ" if tool_result.success else "‚ùå"
                print(f"   Result: {status} ({duration_ms:.1f}ms)")
                if tool_result.success:
                    result_str = str(tool_result)
                    print(f"   Output: {result_str[:100]}...")
                else:
                    print(f"   Error: {tool_result.error}")
                print()
            
            if self.tool_logger.enabled:
                self.tool_logger.log_tool_call(
                    tool_call=tool_call,
                    result=tool_result,
                    duration_ms=duration_ms,
                    session_id=session_id
                )

        return final_results

    def _build_system_prompt(self, repo_context: str) -> str:
        

        if self.model_compatibility["supported"]:
            prompt = .format(
                self.repo_path,
                self.config.llm.model,
                ", ".join(self.config.tools.enabled),
            )
        else:
            prompt = .format(
                self.config.llm.model, self.repo_path, self.config.llm.model
            )

        if repo_context:
            prompt += f"\n\nRepository context:\n{repo_context}"

        return prompt

    async def _run_single_agent(self, user_input: str, session) -> dict:
        

        if "MANDATORY PROJECT DOCUMENTATION CONTEXT" not in user_input:
            return {
                "content": "EXECUTION BLOCKED: No mandatory documentation context found in user input. All execution must include requirements, design, and todos.",
                "usage": {},
                "cost": 0.0,
                "error": "missing_documentation_context"
            }

        user_message = Message(role="user", content=user_input)
        self.session_manager.add_message(user_message)

        repo_context = await self.repo_indexer.get_context(user_input)

        system_prompt = self._build_system_prompt(repo_context)

        messages = self.session_manager.get_messages()

        if len(messages) == 1:  # Only user message exists
            messages.insert(0, Message(role="system", content=system_prompt))

        enabled_tools = {
            name: tool
            for name, tool in registry.get_all().items()
            if name in self.config.tools.enabled
            and name not in self.config.tools.disabled
        }

        if self.available_tools:
            enabled_tools = {
                name: tool
                for name, tool in enabled_tools.items()
                if name in self.available_tools
            }

        tool_schemas = [tool.get_json_schema() for tool in enabled_tools.values()]

        iteration = 0
        
        while True:
            iteration += 1
            
            response = await self._call_llm_with_retry(messages, tool_schemas)
            
            self.total_cost += response.cost or 0

            assistant_message = Message(role="assistant", content=response.content)

            if response.tool_calls:
                assistant_message.tool_calls = response.tool_calls
                messages.append(assistant_message)
                
                tool_results = await self._execute_tools(response.tool_calls, enabled_tools, session.session_id if session else None)

                for tool_call, result in zip(response.tool_calls, tool_results):
                    tool_message = Message(
                        role="tool", content=str(result), tool_call_id=tool_call.id
                    )
                    messages.append(tool_message)

                continue
            else:
                break

        self.session_manager.add_message(assistant_message)

        audit_triggered = await self._check_and_trigger_audit(messages, tool_schemas)
        
        response_data = {
            "content": assistant_message.content,
            "usage": response.usage or {},
            "cost": self.total_cost,
        }

        if audit_triggered:
            response_data["audit_triggered"] = True

        return response_data

    async def _check_and_trigger_audit(self, messages: List[Message], tool_schemas: List[Dict[str, Any]]) -> bool:
        
        try:
            from ..tools.builtin.audit import audit_manager
            
            if not audit_manager.should_trigger_audit():
                return False
            
            print("üîç All todos completed! Triggering automatic audit...")
            
            audit_context = audit_manager.get_audit_context()
            
            audit_message = Message(
                role="user", 
                content=f
            )
            
            messages.append(audit_message)
            
            audit_iteration = 0
            max_audit_iterations = 50  # Allow more thorough audits
            while audit_iteration < max_audit_iterations:
                audit_iteration += 1
                
                response = await self._call_llm_with_retry(messages, tool_schemas)
                
                self.total_cost += response.cost or 0
                
                audit_response = Message(role="assistant", content=response.content)

                if response.tool_calls:
                    audit_response.tool_calls = response.tool_calls
                    messages.append(audit_response)

                    enabled_tools = {
                        name: tool
                        for name, tool in registry.get_all().items()
                        if name in self.config.tools.enabled and name not in self.config.tools.disabled
                    }

                    await self._execute_tools(response.tool_calls, enabled_tools, None)
                    return True

                messages.append(audit_response)
            
            print("‚ö†Ô∏è Audit reached maximum iterations without producing a tool call")
            return False
            
        except Exception as e:
            print(f"‚ö†Ô∏è Audit trigger error: {e}")
            return False

    async def _check_and_trigger_multiagent_audit(self):
        
        try:
            from ..tools.builtin.audit import audit_manager
            
            if not audit_manager.should_trigger_audit():
                return False
            
            print("üîç All todos completed! Triggering automatic audit via supervisor...")
            
            if hasattr(self, 'supervisor') and self.supervisor:
                await self.supervisor.trigger_audit()
            
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è Multi-agent audit trigger error: {e}")
            return False

    async def close(self):
        
        await self.provider.close()


===== EQUITR-coder/EQUITR_coder/core/planning.py =====


import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List

from ..providers.litellm import LiteLLMProvider
from ..providers.openrouter import Message


class ConversationalPlanner:
    

    def __init__(self, provider: LiteLLMProvider, repo_path: str):
        self.provider = provider
        self.repo_path = Path(repo_path)
        self.conversation_history: List[Dict[str, str]] = []
        self.planning_complete = False

    async def start_planning_conversation(self, initial_prompt: str) -> bool:
        
        print("\nüéØ CONVERSATIONAL PLANNING PHASE")
        print("=" * 50)
        print("Strong AI will discuss requirements with you.")
        print("Type '/done' when satisfied, '/exit' to quit planning.")
        print("-" * 50)

        system_prompt = .format(initial_prompt=initial_prompt)

        self.conversation_history = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": initial_prompt},
        ]

        exchange_count = 0

        while (
            not self.planning_complete and exchange_count < 20
        ):  # Limit to prevent infinite loops
            try:
                ai_response = await self._get_ai_response()
                print(f"\nü§ñ AI: {ai_response}")

                user_input = input("\nüë§ You: ").strip()

                if user_input.lower() in ["/exit", "/quit", "/q"]:
                    print("\n‚ùå Planning session cancelled by user")
                    return False
                elif user_input.lower() in ["/done", "/complete", "/finish"]:
                    print("\n‚úÖ Planning session completed by user")
                    self.planning_complete = True
                    break
                elif user_input.lower() == "/skip":
                    print("\n‚è≠Ô∏è  Skipping planning conversation")
                    return True

                self.conversation_history.append(
                    {"role": "user", "content": user_input}
                )
                exchange_count += 1

            except KeyboardInterrupt:
                print("\n\n‚ùå Planning session interrupted")
                return False

        if exchange_count >= 20:
            print(
                "\n‚ö†Ô∏è  Maximum exchanges reached. Proceeding with available information."
            )

        return True

    async def _get_ai_response(self) -> str:
        
        try:
            messages = [
                Message(role=msg["role"], content=msg["content"])
                for msg in self.conversation_history
            ]

            response = await self.provider.chat(
                messages=messages, temperature=0.7, max_tokens=400
            )

            ai_content = response.content.strip()
            self.conversation_history.append(
                {"role": "assistant", "content": ai_content}
            )
            return ai_content

        except Exception as e:
            return f"Error getting AI response: {str(e)}. Please provide your input."

    async def generate_planning_documents(self) -> Dict[str, str]:
        
        if not self.conversation_complete():
            return {}

        print("\nüìã Generating Planning Documents...")

        conversation_context = "\n".join(
            [
                f"{msg['role'].upper()}: {msg['content']}"
                for msg in self.conversation_history
                if msg["role"] != "system"
            ]
        )

        requirements = await self._generate_requirements_doc(conversation_context)

        design = await self._generate_design_doc(conversation_context, requirements)

        todos = await self._generate_todo_list(
            conversation_context, requirements, design
        )

        docs_dir = self.repo_path / "planning_docs"
        docs_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        files = {
            "requirements": docs_dir / f"requirements_{timestamp}.md",
            "design": docs_dir / f"design_{timestamp}.md",
            "todos": docs_dir / f"todos_{timestamp}.json",
        }

        files["requirements"].write_text(requirements)
        files["design"].write_text(design)
        files["todos"].write_text(json.dumps(todos, indent=2))

        print(f"‚úÖ Planning documents saved to {docs_dir}")

        return {
            "requirements": requirements,
            "design": design,
            "todos": json.dumps(todos, indent=2),
            "files": {k: str(v) for k, v in files.items()},
        }

    async def _generate_requirements_doc(self, context: str) -> str:
        
        prompt = f

        messages = [Message(role="user", content=prompt)]
        response = await self.provider.chat(messages=messages, max_tokens=1000)
        return response.content

    async def _generate_design_doc(self, context: str, requirements: str) -> str:
        
        prompt = f

        messages = [Message(role="user", content=prompt)]
        response = await self.provider.chat(messages=messages, max_tokens=1500)
        return response.content

    async def _generate_todo_list(
        self, context: str, requirements: str, design: str
    ) -> List[Dict[str, Any]]:
        
        prompt = f

        messages = [Message(role="user", content=prompt)]
        response = await self.provider.chat(messages=messages, max_tokens=1000)

        try:
            content = response.content.strip()
            if content.startswith("```json"):
                content = content[7:-3]
            elif content.startswith("```"):
                content = content[3:-3]

            todos = json.loads(content)
            return todos if isinstance(todos, list) else []
        except Exception:
            return [
                {
                    "id": "1",
                    "title": "Implement basic structure",
                    "description": "Start implementation",
                    "priority": "high",
                    "type": "create",
                }
            ]

    def conversation_complete(self) -> bool:
        
        return self.planning_complete or len(self.conversation_history) > 2

    def get_conversation_summary(self) -> str:
        
        return "\n".join(
            [
                f"{msg['role']}: {msg['content'][:100]}..."
                for msg in self.conversation_history[-6:]
                if msg["role"] != "system"
            ]
        )


===== EQUITR-coder/EQUITR_coder/core/session.py =====
import json
import asyncio
import uuid
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional, Set
from pydantic import BaseModel
from ..providers.openrouter import Message


class TaskItem(BaseModel):
    

    id: str
    description: str
    status: str = "todo"  # todo, in_progress, done, failed
    files: List[str] = []
    created_at: datetime
    updated_at: datetime


class SessionData(BaseModel):
    

    session_id: str
    created_at: datetime
    updated_at: datetime
    messages: List[Message] = []
    metadata: Dict[str, Any] = {}

    checklist: List[TaskItem] = []
    cost: float = 0.0
    total_tokens: int = 0
    iteration_count: int = 0


class SessionManagerV2:
    

    def __init__(self, session_dir: str = "~/.EQUITR-coder/sessions"):
        self.session_dir = Path(session_dir).expanduser()
        self.session_dir.mkdir(parents=True, exist_ok=True)
        self.current_session: Optional[SessionData] = None

        self._session_cache: Dict[str, SessionData] = {}
        self._dirty_sessions: Set[str] = set()

        self._save_task: Optional[asyncio.Task] = None
        self._start_periodic_save()

    def _start_periodic_save(self):
        
        try:
            if self._save_task is None or self._save_task.done():
                self._save_task = asyncio.create_task(self._periodic_save_loop())
        except RuntimeError:
            pass

    async def _periodic_save_loop(self):
        
        while True:
            try:
                await asyncio.sleep(30)  # Save every 30 seconds
                await self._flush_dirty_sessions()
            except asyncio.CancelledError:
                break
            except Exception as e:
                print(f"Error in periodic save: {e}")

    async def _flush_dirty_sessions(self):
        
        for session_id in list(self._dirty_sessions):
            if session_id in self._session_cache:
                session = self._session_cache[session_id]
                await self._save_session_to_disk(session)
                self._dirty_sessions.discard(session_id)

    def create_session(self, session_id: Optional[str] = None) -> SessionData:
        
        if session_id is None:
            session_id = str(uuid.uuid4())[:8]  # Short UUID for readability

        now = datetime.now()
        session = SessionData(session_id=session_id, created_at=now, updated_at=now)

        self.current_session = session
        self._session_cache[session_id] = session
        self._dirty_sessions.add(session_id)
        return session

    def load_session(self, session_id: str) -> Optional[SessionData]:
        
        if session_id in self._session_cache:
            session = self._session_cache[session_id]
            self.current_session = session
            return session

        session_file = self.session_dir / f"{session_id}.json"
        if not session_file.exists():
            return None

        try:
            with open(session_file, "r") as f:
                data = json.load(f)

            messages = [Message(**msg) for msg in data.get("messages", [])]
            data["messages"] = messages

            checklist = [TaskItem(**item) for item in data.get("checklist", [])]
            data["checklist"] = checklist

            data["created_at"] = datetime.fromisoformat(data["created_at"])
            data["updated_at"] = datetime.fromisoformat(data["updated_at"])

            session = SessionData(**data)

            self._session_cache[session_id] = session
            self.current_session = session
            return session

        except Exception as e:
            print(f"Failed to load session {session_id}: {e}")
            return None

    def switch_session(self, session_id: str) -> bool:
        
        session = self.load_session(session_id)
        if session:
            self.current_session = session
            return True
        return False

    async def _save_session_to_disk(self, session: SessionData):
        
        session.updated_at = datetime.now()
        session_file = self.session_dir / f"{session.session_id}.json"

        try:
            data = session.model_dump()

            data["created_at"] = session.created_at.isoformat()
            data["updated_at"] = session.updated_at.isoformat()

            checklist_data = []
            for item in session.checklist:
                item_dict = item.model_dump()
                item_dict["created_at"] = item.created_at.isoformat()
                item_dict["updated_at"] = item.updated_at.isoformat()
                checklist_data.append(item_dict)
            data["checklist"] = checklist_data

            import aiofiles

            async with aiofiles.open(session_file, "w") as f:
                await f.write(json.dumps(data, indent=2))

        except Exception as e:
            print(f"Failed to save session {session.session_id}: {e}")

    def save_session(self, session: SessionData):
        
        session.updated_at = datetime.now()
        self._session_cache[session.session_id] = session
        self._dirty_sessions.add(session.session_id)

        if self._save_task is None:
            self._save_session_sync(session)

    def _save_session_sync(self, session: SessionData):
        
        session_file = self.session_dir / f"{session.session_id}.json"

        try:
            data = session.model_dump()

            data["created_at"] = session.created_at.isoformat()
            data["updated_at"] = session.updated_at.isoformat()

            checklist_data = []
            for item in session.checklist:
                item_dict = item.model_dump()
                item_dict["created_at"] = item.created_at.isoformat()
                item_dict["updated_at"] = item.updated_at.isoformat()
                checklist_data.append(item_dict)
            data["checklist"] = checklist_data

            with open(session_file, "w") as f:
                json.dump(data, f, indent=2)

        except Exception as e:
            print(f"Failed to save session {session.session_id}: {e}")

    def add_message(self, message: Message):
        
        if self.current_session is None:
            self.create_session()

        self.current_session.messages.append(message)
        self.save_session(self.current_session)

    def get_messages(self) -> List[Message]:
        
        if self.current_session is None:
            return []
        return self.current_session.messages.copy()

    def list_sessions(self) -> List[Dict[str, Any]]:
        
        sessions = []

        for session_id, session in self._session_cache.items():
            sessions.append(
                {
                    "session_id": session_id,
                    "created_at": session.created_at,
                    "updated_at": session.updated_at,
                    "message_count": len(session.messages),
                    "cost": session.cost,
                    "task_count": len(session.checklist),
                    "status": "cached",
                }
            )

        for file in self.session_dir.glob("*.json"):
            session_id = file.stem
            if session_id not in self._session_cache:
                try:
                    with open(file, "r") as f:
                        data = json.load(f)

                    sessions.append(
                        {
                            "session_id": session_id,
                            "created_at": datetime.fromisoformat(
                                data.get("created_at", "")
                            ),
                            "updated_at": datetime.fromisoformat(
                                data.get("updated_at", "")
                            ),
                            "message_count": len(data.get("messages", [])),
                            "cost": data.get("cost", 0.0),
                            "task_count": len(data.get("checklist", [])),
                            "status": "on_disk",
                        }
                    )
                except Exception as e:
                    print(f"Error reading session {session_id}: {e}")

        return sorted(sessions, key=lambda x: x["updated_at"], reverse=True)

    def delete_session(self, session_id: str) -> bool:
        
        if session_id in self._session_cache:
            del self._session_cache[session_id]

        if session_id in self._dirty_sessions:
            self._dirty_sessions.remove(session_id)

        session_file = self.session_dir / f"{session_id}.json"
        try:
            if session_file.exists():
                session_file.unlink()
            return True
        except Exception as e:
            print(f"Failed to delete session {session_id}: {e}")
            return False

    def clear_current_session(self):
        
        if self.current_session:
            self.current_session.messages.clear()
            self.save_session(self.current_session)

    def add_task(self, description: str, files: List[str] = None) -> str:
        
        if self.current_session is None:
            self.create_session()

        task_id = str(uuid.uuid4())[:8]
        now = datetime.now()

        task = TaskItem(
            id=task_id,
            description=description,
            files=files or [],
            created_at=now,
            updated_at=now,
        )

        self.current_session.checklist.append(task)
        self.save_session(self.current_session)
        return task_id

    def update_task_status(self, task_id: str, status: str) -> bool:
        
        if self.current_session is None:
            return False

        for task in self.current_session.checklist:
            if task.id == task_id:
                task.status = status
                task.updated_at = datetime.now()
                self.save_session(self.current_session)
                return True
        return False

    def get_checklist(self) -> List[TaskItem]:
        
        if self.current_session is None:
            return []
        return self.current_session.checklist.copy()

    def update_cost(self, additional_cost: float, additional_tokens: int = 0):
        
        if self.current_session is None:
            self.create_session()

        self.current_session.cost += additional_cost
        self.current_session.total_tokens += additional_tokens
        self.save_session(self.current_session)

    def increment_iteration(self):
        
        if self.current_session is None:
            self.create_session()

        self.current_session.iteration_count += 1
        self.save_session(self.current_session)

    async def cleanup(self):
        
        if self._save_task:
            self._save_task.cancel()
            try:
                await self._save_task
            except asyncio.CancelledError:
                pass

        await self._flush_dirty_sessions()


SessionManager = SessionManagerV2


===== EQUITR-coder/EQUITR_coder/core/supervisor.py =====


import json
import asyncio
from typing import List, Dict, Any, Optional, Set
from datetime import datetime

from .task import Task, TaskList
from .session import SessionManagerV2
from .message_pool import message_pool, MessageType
from ..providers.openrouter import OpenRouterProvider, Message
from ..tools.builtin.agent_communication import create_agent_communication_tools
from ..tools.builtin.git_auto import GitAutoCommit


class WorkerAgent:
    

    def __init__(self, name: str, tools: List[str], provider: OpenRouterProvider, 
                 session_manager: SessionManagerV2, repo_path: str):
        self.name = name
        self.tools = tools
        self.provider = provider
        self.session_manager = session_manager
        self.repo_path = repo_path
        self.current_task: Optional[Task] = None
        self.is_busy = False
        self.communication_tools = create_agent_communication_tools(name)

    async def execute_task(self, task: Task) -> Dict[str, Any]:
        
        if self.is_busy:
            return {"success": False, "error": "Agent is busy"}

        self.is_busy = True
        self.current_task = task

        try:
            await message_pool.register_agent(self.name)

            await message_pool.send_message(
                sender_agent=self.name,
                content=f"Starting task: {task.description}",
                message_type=MessageType.STATUS_UPDATE,
                task_id=task.id,
                metadata={"task_status": "started"},
            )

            messages = await message_pool.get_messages_for_agent(self.name)
            coordination_info = ""
            if messages:
                coordination_info = "\n\nRECENT MESSAGES FROM OTHER AGENTS:\n"
                for msg in messages[-3:]:  # Show last 3 messages
                    coordination_info += f"- {msg.sender_agent}: {msg.content}\n"

            task_prompt = self._create_task_prompt(task) + coordination_info
            
            if "MANDATORY PROJECT DOCUMENTATION CONTEXT" not in task_prompt:
                task_prompt = f

            result = await self._execute_task_with_orchestrator(task_prompt, task)

            await message_pool.send_message(
                sender_agent=self.name,
                content=f"Completed task: {task.description}. Result: {result[:100]}",
                message_type=MessageType.STATUS_UPDATE,
                task_id=task.id,
                metadata={"task_status": "completed", "result": result},
            )

            return {
                "success": True,
                "result": result,
                "agent": self.name,
                "task_id": task.id,
            }

        except Exception as e:
            await message_pool.send_message(
                sender_agent=self.name,
                content=f"Error in task: {task.description}. Error: {str(e)}",
                message_type=MessageType.ERROR,
                task_id=task.id,
                metadata={"task_status": "failed", "error": str(e)},
            )

            return {
                "success": False,
                "error": str(e),
                "agent": self.name,
                "task_id": task.id,
            }
        finally:
            self.is_busy = False
            self.current_task = None

    def _create_task_prompt(self, task: Task) -> str:
        
        prompt = f

        return prompt

    async def _execute_task_with_orchestrator(self, task_prompt: str, task: Task) -> str:
        
        import asyncio
        import json
        from ..providers.openrouter import Message, ToolCall
        from ..tools import registry, discovery
        from ..repository.indexer import RepositoryIndexer
        from .context_manager import ContextManager
        from ..tools.base import ToolResult

        try:
            discovery.discover_builtin_tools()
            discovery.discover_custom_tools()
            temp_session = self.session_manager.create_session()
            
            user_message = Message(role="user", content=task_prompt)
            temp_session.messages.append(user_message)
            
            repo_indexer = RepositoryIndexer(repo_path=self.repo_path)
            repo_context = await repo_indexer.get_context(task_prompt)
            
            system_prompt = f

            if repo_context:
                system_prompt += f"\n\nRepository context:\n{repo_context}"

            messages = temp_session.messages.copy()
            
            messages.insert(0, Message(role="system", content=system_prompt))
            
            all_tools = registry.get_all()
            enabled_tools = {
                name: tool
                for name, tool in all_tools.items()
                if name in self.tools
            }
            
            tool_schemas = [tool.get_json_schema() for tool in enabled_tools.values()]
            
            iteration = 0
            
            while True:
                iteration += 1
                
                tools_to_use = tool_schemas if tool_schemas else None
                
                response = await self.provider.chat(
                    messages=messages,
                    tools=tools_to_use,
                    temperature=0.7,
                    max_tokens=4096,
                )
                
                assistant_message = Message(role="assistant", content=response.content)
                
                if response.tool_calls:
                    assistant_message.tool_calls = response.tool_calls
                    messages.append(assistant_message)
                    
                    tool_results = await self._execute_tools(response.tool_calls, enabled_tools)
                    
                    for tool_call, result in zip(response.tool_calls, tool_results):
                        tool_message = Message(
                            role="tool", content=str(result), tool_call_id=tool_call.id
                        )
                        messages.append(tool_message)
                    
                    continue
                else:
                    break
            
            return response.content or f"Task '{task.description}' completed by {self.name}"
            
        except Exception as e:
            return f"Error executing task '{task.description}': {str(e)}"

    async def _execute_tools(self, tool_calls: list, enabled_tools: dict) -> list:
        
        tasks = []

        for tool_call in tool_calls:
            tool_name = tool_call.function["name"]
            tool_args = tool_call.function.get("arguments", {})

            if isinstance(tool_args, str):
                try:
                    tool_args = json.loads(tool_args)
                except json.JSONDecodeError:
                    tool_args = {}

            if tool_name in enabled_tools:
                tool = enabled_tools[tool_name]
                tasks.append(tool.run(**tool_args))
            else:
                async def error_result():
                    from ..tools.base import ToolResult
                    return ToolResult(
                        success=False,
                        error=f"Tool '{tool_name}' not found or not enabled",
                    )
                tasks.append(error_result())

        results = await asyncio.gather(*tasks, return_exceptions=True)

        final_results = []
        for result in results:
            if isinstance(result, Exception):
                from ..tools.base import ToolResult
                final_results.append(ToolResult(success=False, error=str(result)))
            else:
                final_results.append(result)

        return final_results


class SupervisorAgent:
    

    def __init__(
        self,
        provider: OpenRouterProvider,
        session_manager: SessionManagerV2,
        repo_path: str = ".",
        use_multi_agent: bool = False,
        worker_provider: Optional[OpenRouterProvider] = None,
    ):
        self.provider = provider
        self.worker_provider = worker_provider or provider  # Use separate provider for workers if provided
        self.session_manager = session_manager
        self.repo_path = repo_path
        self.use_multi_agent = use_multi_agent
        self.worker_agents: Dict[str, WorkerAgent] = {}
        self.task_queue = asyncio.Queue()
        self.worker_semaphore = asyncio.Semaphore(3)  # Max 3 concurrent workers
        self.active_tasks: Set[str] = set()
        self.git_auto = GitAutoCommit(repo_path)

        self._initialize_workers()

        asyncio.create_task(self._register_supervisor())

    def _initialize_workers(self):
        
        self.worker_agents = {
            "file_worker": WorkerAgent(
                name="file_worker",
                tools=["read_file", "write_file", "list_files", "create_file"],
                provider=self.worker_provider,
                session_manager=self.session_manager,
                repo_path=self.repo_path,
            ),
            "search_worker": WorkerAgent(
                name="search_worker",
                tools=["search_files", "grep_search", "web_search"],
                provider=self.worker_provider,
                session_manager=self.session_manager,
                repo_path=self.repo_path,
            ),
            "code_worker": WorkerAgent(
                name="code_worker",
                tools=["read_file", "write_file", "run_shell", "git_commit"],
                provider=self.worker_provider,
                session_manager=self.session_manager,
                repo_path=self.repo_path,
            ),
            "analysis_worker": WorkerAgent(
                name="analysis_worker",
                tools=["read_file", "search_files", "analyze_code"],
                provider=self.worker_provider,
                session_manager=self.session_manager,
                repo_path=self.repo_path,
            ),
        }

    async def _register_supervisor(self):
        
        await message_pool.register_agent("supervisor")

    async def break_into_tasks(self, user_input: str) -> TaskList:
        

        if "MANDATORY PROJECT DOCUMENTATION CONTEXT" not in user_input:
            raise Exception("CRITICAL: Task decomposition requires MANDATORY documentation context (requirements, design, todos)")

        decomposition_prompt = f

        try:
            messages = [Message(role="user", content=decomposition_prompt)]
            response = await self.provider.chat(messages)

            response_text = response.content.strip()
            if response_text.startswith("```json"):
                response_text = response_text[7:-3]
            elif response_text.startswith("```"):
                response_text = response_text[3:-3]

            task_data = json.loads(response_text)

            task_list = TaskList()

            for task_info in task_data.get("tasks", []):
                task = Task(
                    id=task_info.get("id", str(len(task_list.tasks) + 1)),
                    description=task_info["description"],
                    files=task_info.get("files", []),
                    dependencies=task_info.get("dependencies", []),
                    assigned_agent=task_info.get("assigned_agent"),
                    priority=task_info.get("priority", 5),
                    estimated_duration=task_info.get("estimated_duration"),
                )
                task_list.add_task(task)

            return task_list

        except Exception as e:
            print(f"Failed to decompose tasks: {e}")
            task_list = TaskList()
            task = Task(
                id="1", description=user_input, assigned_agent="code_worker", priority=5
            )
            task_list.add_task(task)
            return task_list

    async def spawn_workers(self, task_list: TaskList) -> Dict[str, Any]:
        

        results = {}
        completed_tasks = []

        await message_pool.send_message(
            sender_agent="supervisor",
            content=f"Starting multi-agent task execution with {len(task_list.tasks)} tasks",
            message_type=MessageType.COORDINATION,
            metadata={"total_tasks": len(task_list.tasks)},
        )

        while not task_list.is_complete():
            ready_tasks = task_list.get_ready_tasks()

            if not ready_tasks:
                await asyncio.sleep(1)
                continue

            worker_coroutines = []

            for task in ready_tasks:
                if task.id not in self.active_tasks:
                    task_list.update_task_status(task.id, "in_progress")
                    self.active_tasks.add(task.id)

                    agent_name = task.assigned_agent or "code_worker"
                    if agent_name not in self.worker_agents:
                        agent_name = "code_worker"  # fallback

                    worker_agent = self.worker_agents[agent_name]

                    await message_pool.send_message(
                        sender_agent="supervisor",
                        content=f"Assigning task to {agent_name}: {task.description}",
                        message_type=MessageType.COORDINATION,
                        recipient_agent=agent_name,
                        task_id=task.id,
                        metadata={"task_assignment": True},
                    )

                    worker_coroutine = self._execute_task_with_semaphore(
                        worker_agent, task, task_list
                    )
                    worker_coroutines.append(worker_coroutine)

            if worker_coroutines:
                task_results = await asyncio.gather(
                    *worker_coroutines, return_exceptions=True
                )

                for result in task_results:
                    if isinstance(result, Exception):
                        print(f"Worker error: {result}")
                        await message_pool.send_message(
                            sender_agent="supervisor",
                            content=f"Worker error occurred: {str(result)}",
                            message_type=MessageType.ERROR,
                            metadata={"error": str(result)},
                        )
                    elif isinstance(result, dict) and "task_id" in result:
                        results[result["task_id"]] = result
                        completed_tasks.append(result["task_id"])
                    else:
                        print(f"Unexpected result format: {result}")
                        await message_pool.send_message(
                            sender_agent="supervisor",
                            content=f"Unexpected result format: {str(result)}",
                            message_type=MessageType.ERROR,
                            metadata={"error": f"Unexpected result format: {str(result)}"},
                        )

        await message_pool.send_message(
            sender_agent="supervisor",
            content=f"All tasks completed. {len(completed_tasks)} tasks finished successfully.",
            message_type=MessageType.COORDINATION,
            metadata={"completion": True, "completed_tasks": len(completed_tasks)},
        )

        return {
            "task_results": results,
            "summary": task_list.get_progress_summary(),
            "completed_tasks": completed_tasks,
        }

    async def _execute_task_with_semaphore(
        self, worker_agent: WorkerAgent, task: Task, task_list: TaskList
    ) -> Dict[str, Any]:
        
        async with self.worker_semaphore:
            try:
                self.git_auto.commit_task_start(task.description)

                result = await worker_agent.execute_task(task)

                if result["success"]:
                    task_list.update_task_status(
                        task.id, "done", result=result["result"]
                    )
                    self.git_auto.commit_checkpoint(task.description)
                else:
                    task_list.update_task_status(
                        task.id, "failed", error=result["error"]
                    )

                self.active_tasks.discard(task.id)

                return result

            except Exception as e:
                task_list.update_task_status(task.id, "failed", error=str(e))
                self.active_tasks.discard(task.id)
                return {
                    "success": False,
                    "error": str(e),
                    "agent": worker_agent.name,
                    "task_id": task.id,
                }

    async def monitor_progress(self, task_list: TaskList) -> Dict[str, Any]:
        

        summary = task_list.get_progress_summary()

        task_details = []
        for task in task_list.tasks:
            task_details.append(
                {
                    "id": task.id,
                    "description": task.description,
                    "status": task.status,
                    "assigned_agent": task.assigned_agent,
                    "priority": task.priority,
                    "duration": task.duration_minutes(),
                    "result": task.result[:100] + "..."
                    if task.result and len(task.result) > 100
                    else task.result,
                    "error": task.error,
                }
            )

        pool_status = await message_pool.get_pool_status()

        return {
            "summary": summary,
            "tasks": task_details,
            "active_workers": [
                agent.name for agent in self.worker_agents.values() if agent.is_busy
            ],
            "message_pool": pool_status,
            "timestamp": datetime.now().isoformat(),
        }

    def should_use_multiagent(self, user_input: str) -> bool:
        

        if self.use_multi_agent:
            return True
        
        return False

        multiagent_indicators = [
            "build complete",
            "create project",
            "implement system",
            "develop application",
            "multiple files",
            "full stack",
            "frontend and backend",
            "database and api",
            "comprehensive",
            "end-to-end",
        ]

        input_lower = user_input.lower()

        complexity_score = 0
        for indicator in multiagent_indicators:
            if indicator in input_lower:
                complexity_score += 2  # Higher weight for explicit multi-component requests

        if "create" in input_lower and any(ext in input_lower for ext in [".py", ".js", ".html", ".css"]):
            complexity_score += 1

        if len(user_input.split()) > 30:
            complexity_score += 1

        return complexity_score >= 3

    async def get_status(self) -> Dict[str, Any]:
        
        pool_status = await message_pool.get_pool_status()
        recent_messages = await message_pool.get_message_history(limit=10)

        return {
            "active_workers": [
                agent.name for agent in self.worker_agents.values() if agent.is_busy
            ],
            "message_pool": pool_status,
            "recent_messages": [
                {
                    "sender": msg.sender_agent,
                    "recipient": msg.recipient_agent,
                    "type": msg.message_type.value,
                    "content": msg.content[:100] + "..."
                    if len(msg.content) > 100
                    else msg.content,
                    "timestamp": msg.timestamp.isoformat(),
                }
                for msg in recent_messages
            ],
            "timestamp": datetime.now().isoformat(),
        }

    async def trigger_audit(self):
        
        try:
            print("üîç Starting multi-agent audit...")
            
            from EQUITR_coder.tools.builtin.audit import audit_manager
            
            audit_context = audit_manager.get_audit_context()
            
            from EQUITR_coder.core.task import Task
            audit_task = Task(
                id="audit_task",
                description=f,
                assignee="analysis_worker",
                priority="high"
            )
            
            if "analysis_worker" in self.workers:
                audit_result = await self.workers["analysis_worker"].execute_task(audit_task)
                
                if audit_result.get("success", False):
                    result_content = audit_result.get("result", "")
                    
                    if "AUDIT PASSED" in result_content:
                        print("‚úÖ Multi-agent audit completed successfully!")
                    elif "AUDIT FAILED" in result_content:
                        print("‚ùå Multi-agent audit failed - issues found")
                    else:
                        print("‚ö†Ô∏è Multi-agent audit completed with unclear result")
                else:
                    print("‚ùå Multi-agent audit execution failed")
            else:
                print("‚ùå Analysis worker not available for audit")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Multi-agent audit error: {e}")


===== EQUITR-coder/EQUITR_coder/core/task.py =====


from datetime import datetime
from typing import List, Optional, Dict, Any, Literal
from pydantic import BaseModel, Field
import uuid


class Task(BaseModel):
    

    id: str = Field(default_factory=lambda: str(uuid.uuid4())[:8])
    description: str = Field(..., description="What needs to be done")
    status: Literal["todo", "in_progress", "done", "failed"] = "todo"
    files: List[str] = Field(
        default_factory=list, description="Files this task should focus on"
    )
    dependencies: List[str] = Field(
        default_factory=list, description="Task IDs this task depends on"
    )
    assigned_agent: Optional[str] = None
    priority: int = Field(
        default=5, description="Priority 1-10, higher is more important"
    )
    estimated_duration: Optional[int] = None  # minutes
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    result: Optional[str] = None
    error: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)

    def update_status(
        self, new_status: str, result: Optional[str] = None, error: Optional[str] = None
    ):
        
        self.status = new_status
        self.updated_at = datetime.now()

        if new_status == "in_progress" and self.started_at is None:
            self.started_at = datetime.now()
        elif new_status in ["done", "failed"]:
            self.completed_at = datetime.now()

        if result:
            self.result = result
        if error:
            self.error = error

    def is_ready(self, completed_tasks: List[str]) -> bool:
        
        if self.status != "todo":
            return False
        return all(dep_id in completed_tasks for dep_id in self.dependencies)

    def duration_minutes(self) -> Optional[int]:
        
        if self.started_at and self.completed_at:
            return int((self.completed_at - self.started_at).total_seconds() / 60)
        return None


class TaskList(BaseModel):
    

    tasks: List[Task] = Field(default_factory=list)
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)

    def add_task(self, task: Task) -> str:
        
        self.tasks.append(task)
        self.updated_at = datetime.now()
        return task.id

    def get_task(self, task_id: str) -> Optional[Task]:
        
        for task in self.tasks:
            if task.id == task_id:
                return task
        return None

    def update_task_status(
        self,
        task_id: str,
        status: str,
        result: Optional[str] = None,
        error: Optional[str] = None,
    ) -> bool:
        
        task = self.get_task(task_id)
        if task:
            task.update_status(status, result, error)
            self.updated_at = datetime.now()
            return True
        return False

    def get_ready_tasks(self) -> List[Task]:
        
        completed_task_ids = [t.id for t in self.tasks if t.status == "done"]
        return [task for task in self.tasks if task.is_ready(completed_task_ids)]

    def get_tasks_by_status(self, status: str) -> List[Task]:
        
        return [task for task in self.tasks if task.status == status]

    def get_tasks_by_agent(self, agent_name: str) -> List[Task]:
        
        return [task for task in self.tasks if task.assigned_agent == agent_name]

    def is_complete(self) -> bool:
        
        return all(task.status in ["done", "failed"] for task in self.tasks)

    def get_progress_summary(self) -> Dict[str, Any]:
        
        total = len(self.tasks)
        if total == 0:
            return {
                "total": 0,
                "completed": 0,
                "in_progress": 0,
                "todo": 0,
                "failed": 0,
                "progress": 0.0,
            }

        status_counts = {}
        for status in ["todo", "in_progress", "done", "failed"]:
            status_counts[status] = len(self.get_tasks_by_status(status))

        return {
            "total": total,
            "completed": status_counts["done"],
            "in_progress": status_counts["in_progress"],
            "todo": status_counts["todo"],
            "failed": status_counts["failed"],
            "progress": status_counts["done"] / total * 100,
        }

    def get_next_task(self, agent_name: Optional[str] = None) -> Optional[Task]:
        
        ready_tasks = self.get_ready_tasks()

        if agent_name:
            ready_tasks = [
                t
                for t in ready_tasks
                if t.assigned_agent == agent_name or t.assigned_agent is None
            ]

        if not ready_tasks:
            return None

        ready_tasks.sort(key=lambda t: (-t.priority, t.created_at))
        return ready_tasks[0]

    def to_dict(self) -> Dict[str, Any]:
        
        return {
            "tasks": [task.model_dump() for task in self.tasks],
            "created_at": self.created_at.isoformat(),
            "updated_at": self.updated_at.isoformat(),
            "summary": self.get_progress_summary(),
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "TaskList":
        
        tasks = [Task(**task_data) for task_data in data.get("tasks", [])]
        return cls(
            tasks=tasks,
            created_at=datetime.fromisoformat(
                data.get("created_at", datetime.now().isoformat())
            ),
            updated_at=datetime.fromisoformat(
                data.get("updated_at", datetime.now().isoformat())
            ),
        )


===== EQUITR-coder/EQUITR_coder/config/app_developer.yaml =====
llm:
  provider: openrouter
  model: anthropic/claude-3-haiku
  api_base: https://openrouter.ai/api/v1
  budget: 1.5
  temperature: 0.1
  max_tokens: 4000

tools:
  enabled:
    - fs
    - git
    - shell
    - search
    - npm
    - docker
    - testing
    - linting
  disabled: []

sandbox:
  type: venv
  timeout: 45
  max_memory: 1024  # MB
  allow_network: true  # For package installs

session:
  persist: true
  max_context: 120000
  session_dir: ~/.EQUITR-coder/sessions

repository:
  index_on_start: true
  ignore_patterns:
    - "*.pyc"
    - "__pycache__"
    - ".git"
    - "node_modules"
    - ".venv"
    - "venv"
    - "*.log"
    - "dist/"
    - "build/"
    - ".next/"

orchestrator:
  max_iterations: 25
  error_retry_limit: 4
  error_retry_delay: 1.5


===== EQUITR-coder/EQUITR_coder/config/default.yaml =====
llm:
  provider: litellm
  model: ""  # No default model - users must select one
  api_base: ""
  budget: 1.0
  temperature: 0.1
  max_tokens: 4000

tools:
  enabled:
    - create_file
    - edit_file
    - list_files
    - read_file
    - git_commit
    - git_diff
    - git_status
    - web_search
    - run_command
    - create_todo
    - update_todo
    - delete_todo
    - list_todos
  disabled: []

sandbox:
  type: venv
  timeout: 30
  max_memory: 512  # MB
  allow_network: false

session:
  persist: true
  max_context: 100000
  session_dir: ~/.EQUITR-coder/sessions

repository:
  index_on_start: true
  ignore_patterns:
    - "*.pyc"
    - "__pycache__"
    - ".git"
    - "node_modules"
    - ".venv"
    - "venv"
    - "*.log"

orchestrator:
  max_iterations: 20
  error_retry_limit: 3
  error_retry_delay: 1.0

profiles:
  default: default
  available:
    - ml_researcher
    - app_developer


===== EQUITR-coder/EQUITR_coder/config/ml_researcher.yaml =====
llm:
  provider: openrouter
  model: anthropic/claude-3-haiku
  api_base: https://openrouter.ai/api/v1
  budget: 2.0
  temperature: 0.2
  max_tokens: 4000

tools:
  enabled:
    - fs
    - git
    - shell
    - search
    - arxiv_search
    - jupyter
    - data_analysis
  disabled: []

sandbox:
  type: venv
  timeout: 60
  max_memory: 2048  # MB
  allow_network: true  # For downloading papers/datasets

session:
  persist: true
  max_context: 150000
  session_dir: ~/.EQUITR-coder/sessions

repository:
  index_on_start: true
  ignore_patterns:
    - "*.pyc"
    - "__pycache__"
    - ".git"
    - "node_modules"
    - ".venv"
    - "venv"
    - "*.log"
    - "data/"
    - "logs/"
    - "wandb/"

orchestrator:
  max_iterations: 30
  error_retry_limit: 5
  error_retry_delay: 2.0


===== EQUITR-coder/EQUITR_coder/providers/__init__.py =====
from .openrouter import OpenRouterProvider

__all__ = ["OpenRouterProvider"]


===== EQUITR-coder/EQUITR_coder/providers/function_calling_discovery.py =====


import litellm
from typing import List, Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)


class FunctionCallingModelDiscovery:
    

    def __init__(self):
        self._cache = {}
        self._cache_timeout = 3600  # 1 hour cache

    async def discover_models(self, provider: str = None) -> List[Dict[str, Any]]:
        
        try:
            all_models = litellm.model_list

            supported_models = []

            for model in all_models:
                model_info = await self._get_model_info(model)
                if model_info and model_info["supports_function_calling"]:
                    if provider is None or model_info["provider"] == provider:
                        supported_models.append(model_info)

            return supported_models

        except Exception as e:
            logger.error(f"Error discovering models: {e}")
            return await self._get_fallback_models(provider)

    async def _get_model_info(self, model: str) -> Optional[Dict[str, Any]]:
        
        try:
            provider = None
            model_name = model

            if "/" in model:
                provider, model_name = model.split("/", 1)
            else:
                provider = self._infer_provider(model)

            supports_fc = litellm.supports_function_calling(model)
            supports_pfc = litellm.supports_parallel_function_calling(model)

            return {
                "name": model,
                "model_name": model_name,
                "provider": provider,
                "supports_function_calling": supports_fc,
                "supports_parallel_function_calling": supports_pfc,
                "full_name": model,
            }

        except Exception as e:
            logger.warning(f"Error checking model {model}: {e}")
            return None

    def _infer_provider(self, model: str) -> str:
        
        model_lower = model.lower()

        if "gpt" in model_lower or "openai" in model_lower:
            return "openai"
        elif "claude" in model_lower or "anthropic" in model_lower:
            return "anthropic"
        elif "gemini" in model_lower:
            return "google"
        elif "mistral" in model_lower:
            return "mistral"
        elif "cohere" in model_lower:
            return "cohere"
        else:
            return "unknown"

    async def _get_fallback_models(self, provider: str = None) -> List[Dict[str, Any]]:
        
        fallback_models = {
            "openai": [
                {
                    "name": "gpt-4-turbo-preview",
                    "provider": "openai",
                    "supports_function_calling": True,
                    "supports_parallel_function_calling": True,
                },
                {
                    "name": "gpt-4",
                    "provider": "openai",
                    "supports_function_calling": True,
                    "supports_parallel_function_calling": False,
                },
                {
                    "name": "gpt-3.5-turbo-1106",
                    "provider": "openai",
                    "supports_function_calling": True,
                    "supports_parallel_function_calling": True,
                },
                {
                    "name": "gpt-3.5-turbo",
                    "provider": "openai",
                    "supports_function_calling": True,
                    "supports_parallel_function_calling": False,
                },
            ],
            "anthropic": [
                {
                    "name": "claude-3-opus",
                    "provider": "anthropic",
                    "supports_function_calling": True,
                    "supports_parallel_function_calling": True,
                },
                {
                    "name": "claude-3-sonnet",
                    "provider": "anthropic",
                    "supports_function_calling": True,
                    "supports_parallel_function_calling": True,
                },
                {
                    "name": "claude-3-haiku",
                    "provider": "anthropic",
                    "supports_function_calling": True,
                    "supports_parallel_function_calling": True,
                },
            ],
            "openrouter": [
                {
                    "name": "anthropic/claude-3-opus",
                    "provider": "openrouter",
                    "supports_function_calling": True,
                    "supports_parallel_function_calling": True,
                },
                {
                    "name": "anthropic/claude-3-sonnet",
                    "provider": "openrouter",
                    "supports_function_calling": True,
                    "supports_parallel_function_calling": True,
                },
                {
                    "name": "openai/gpt-4-turbo-preview",
                    "provider": "openrouter",
                    "supports_function_calling": True,
                    "supports_parallel_function_calling": True,
                },
            ],
        }

        if provider:
            return fallback_models.get(provider, [])
        else:
            all_models = []
            for models in fallback_models.values():
                all_models.extend(models)
            return all_models

    async def validate_model(self, model: str) -> Dict[str, Any]:
        
        try:
            supports_fc = litellm.supports_function_calling(model)
            supports_pfc = litellm.supports_parallel_function_calling(model)

            provider = None
            if "/" in model:
                provider = model.split("/")[0]
            else:
                provider = self._infer_provider(model)

            return {
                "name": model,
                "provider": provider,
                "supports_function_calling": supports_fc,
                "supports_parallel_function_calling": supports_pfc,
                "valid": supports_fc,
                "error": None
                if supports_fc
                else "Model does not support function calling",
            }

        except Exception as e:
            return {
                "name": model,
                "provider": None,
                "supports_function_calling": False,
                "supports_parallel_function_calling": False,
                "valid": False,
                "error": str(e),
            }

    def get_provider_list(self) -> List[str]:
        
        return [
            "openai",
            "anthropic",
            "openrouter",
            "azure",
            "bedrock",
            "vertexai",
            "cohere",
            "together",
            "replicate",
        ]


function_calling_discovery = FunctionCallingModelDiscovery()


async def discover_function_calling_models(provider: str = None) -> List[str]:
    
    models = await function_calling_discovery.discover_models(provider)
    return [model["name"] for model in models]


async def validate_model_for_use(model: str) -> bool:
    
    result = await function_calling_discovery.validate_model(model)
    return result["valid"]


===== EQUITR-coder/EQUITR_coder/providers/litellm.py =====
import os
from typing import List, Dict, Any, Optional, Union
import asyncio
import litellm
import json
import time
import random
import logging
from pathlib import Path

from .openrouter import Message, ToolCall, ChatResponse
from ..core.config import Config

logger = logging.getLogger(__name__)


class LiteLLMProvider:
    

    def __init__(
        self,
        model: str,
        api_key: Optional[str] = None,
        api_base: Optional[str] = None,
        temperature: float = 0.1,
        max_tokens: int = 4000,
        **kwargs,
    ):
        
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens

        if "/" in model:
            self.provider, self.model_name = model.split("/", 1)
        else:
            self.provider = "openai"
            self.model_name = model

        self._setup_api_key(api_key)

        if api_base:
            self._setup_api_base(api_base)

        litellm.drop_params = True  # Drop unsupported params instead of erroring
        litellm.set_verbose = False  # Reduce logging noise

        self.provider_kwargs = kwargs

        self.max_retries = 5
        self.base_delay = 1.0  # Base delay in seconds
        self.max_delay = 60.0  # Maximum delay in seconds
        self.backoff_multiplier = 2.0

        self.last_request_time = 0
        self.min_request_interval = 2.0  # 2 seconds between requests

    def _setup_api_key(self, api_key: Optional[str] = None) -> None:
        
        if self.provider == "moonshot":
            correct_moonshot_key = "sk-ZRroPTEzVYvEkNpYJhL3H7gDGGLNR98zwbdWdOrETmrlh9yF"
            os.environ["MOONSHOT_API_KEY"] = correct_moonshot_key  # Always use correct key
            os.environ["MOONSHOT_API_BASE"] = "https://api.moonshot.ai/v1"
            print(f"üîß Set MOONSHOT_API_KEY to: {correct_moonshot_key[:20]}...")
            return
        
        if not api_key:
            return

        if self.provider == "openai":
            os.environ["OPENAI_API_KEY"] = api_key
        elif self.provider == "openrouter":
            os.environ["OPENROUTER_API_KEY"] = api_key
        elif self.provider == "anthropic":
            os.environ["ANTHROPIC_API_KEY"] = api_key
        else:
            os.environ["API_KEY"] = api_key

    def _get_api_key_env_var(self) -> str:
        
        provider_key_map = {
            "openai": "OPENAI_API_KEY",
            "anthropic": "ANTHROPIC_API_KEY",
            "claude": "ANTHROPIC_API_KEY",
            "openrouter": "OPENROUTER_API_KEY",
            "together": "TOGETHER_API_KEY",
            "replicate": "REPLICATE_API_TOKEN",
            "cohere": "COHERE_API_KEY",
            "huggingface": "HUGGINGFACE_API_KEY",
            "bedrock": "AWS_ACCESS_KEY_ID",
            "azure": "AZURE_API_KEY",
            "vertexai": "VERTEXAI_PROJECT",
            "palm": "PALM_API_KEY",
        }
        return provider_key_map.get(self.provider, f"{self.provider.upper()}_API_KEY")

    def _get_common_api_key_variations(self) -> List[str]:
        
        base_key = self._get_api_key_env_var()
        variations = [base_key]

        if self.provider == "anthropic":
            variations.extend(["CLAUDE_API_KEY", "ANTHROPIC_API_KEY"])
        elif self.provider == "openai":
            variations.extend(["OPENAI_API_KEY", "OPENAI_KEY"])
        elif self.provider == "openrouter":
            variations.extend(["OPENROUTER_API_KEY", "OPENROUTER_KEY"])

        return variations

    def _setup_api_base(self, api_base: str) -> None:
        
        if self.provider == "openai":
            os.environ["OPENAI_API_BASE"] = api_base
        elif self.provider == "openrouter":
            os.environ["OPENROUTER_API_BASE"] = api_base
        elif self.provider == "moonshot":
            os.environ["MOONSHOT_API_BASE"] = api_base

    async def _exponential_backoff_retry(self, func, *args, **kwargs):
        
        last_exception = None
        
        for attempt in range(self.max_retries + 1):
            try:
                await self._rate_limit()
                
                if attempt > 0:
                    print(f"üîÑ Retry attempt {attempt}/{self.max_retries} for the SAME request...")
                
                return await func(*args, **kwargs)
                
            except Exception as e:
                last_exception = e
                error_msg = str(e).lower()
                
                if any(auth_term in error_msg for auth_term in 
                       ["authentication", "unauthorized", "invalid key", "api key"]):
                    print(f"‚ùå Authentication error, not retrying: {e}")
                    raise e
                
                is_rate_limit = any(keyword in error_msg for keyword in [
                    "rate limit", "quota", "429", "too many requests", "retry"
                ])
                is_server_error = any(keyword in error_msg for keyword in [
                    "500", "502", "503", "504", "internal server error", "bad gateway",
                    "service unavailable", "gateway timeout", "connection", "timeout"
                ])
                
                should_retry = is_rate_limit or is_server_error
                
                if not should_retry:
                    print(f"‚ùå Non-retryable error: {str(e)[:100]}...")
                    raise e
                
                if attempt >= self.max_retries:
                    print(f"‚ùå Max retries ({self.max_retries}) reached for the same request")
                    raise e
                
                delay = min(
                    self.base_delay * (self.backoff_multiplier ** attempt),
                    self.max_delay
                )
                jitter = random.uniform(0.1, 0.3) * delay
                total_delay = delay + jitter
                
                error_type = "Rate limit" if is_rate_limit else "Server error"
                print(f"‚ö†Ô∏è  {error_type} (attempt {attempt + 1}/{self.max_retries + 1}): {str(e)[:80]}...")
                print(f"‚è±Ô∏è  Retrying SAME request in {total_delay:.1f}s with exponential backoff...")
                await asyncio.sleep(total_delay)
        
        raise last_exception

    async def _rate_limit(self):
        
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.min_request_interval:
            sleep_time = self.min_request_interval - time_since_last
            print(f"‚è±Ô∏è  Rate limiting: waiting {sleep_time:.1f}s (minimum {self.min_request_interval}s between requests)")
            await asyncio.sleep(sleep_time)
        
        self.last_request_time = time.time()

    async def _make_completion_request(self, **params):
        
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None, lambda: litellm.completion(**params)
        )

    async def chat(
        self,
        messages: List[Message],
        tools: Optional[List[Dict[str, Any]]] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs,
    ) -> ChatResponse:
        
        try:
            formatted_messages = []
            for msg in messages:
                formatted_msg = {"role": msg.role, "content": msg.content}

                if msg.tool_call_id:
                    formatted_msg["tool_call_id"] = msg.tool_call_id
                if msg.name:
                    formatted_msg["name"] = msg.name
                if msg.tool_calls:
                    formatted_msg["tool_calls"] = msg.tool_calls

                formatted_messages.append(formatted_msg)

            params = {
                "model": self.model,
                "messages": formatted_messages,
                "temperature": temperature or self.temperature,
                "max_tokens": max_tokens or self.max_tokens,
                **self.provider_kwargs,
                **kwargs,
            }

            params["cache_control"] = "default"  # "force" or True also acceptable

            if tools:
                functions = []
                for tool in tools:
                    if "type" in tool and tool["type"] == "function":
                        functions.append(tool)
                    else:
                        functions.append(
                            {
                                "type": "function",
                                "function": {
                                    "name": tool["name"],
                                    "description": tool["description"],
                                    "parameters": tool["parameters"],
                                },
                            }
                        )
                params["tools"] = functions
                params["tool_choice"] = "auto"

            response = await self._exponential_backoff_retry(
                self._make_completion_request, **params
            )

            choice = response.choices[0]
            message = choice.message

            content = getattr(message, "content", "") or ""

            tool_calls = []
            if hasattr(message, "tool_calls") and message.tool_calls:
                for tc in message.tool_calls:
                    tool_calls.append(
                        ToolCall(
                            id=tc.id,
                            type=tc.type,
                            function=tc.function.model_dump()
                            if hasattr(tc.function, "model_dump")
                            else tc.function,
                        )
                    )

            usage = (
                response.usage.model_dump()
                if hasattr(response.usage, "model_dump")
                else response.usage
            )
            cost = self._calculate_cost(usage, self.model)

            return ChatResponse(
                content=content, tool_calls=tool_calls, usage=usage, cost=cost
            )

        except Exception as e:
            error_msg = self._format_error(e)
            raise Exception(f"LiteLLM request failed: {error_msg}")

    async def embedding(
        self, text: Union[str, List[str]], model: Optional[str] = None, **kwargs
    ) -> List[List[float]]:
        
        try:
            embedding_model = model or self._get_embedding_model()

            if isinstance(text, str):
                text = [text]

            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: litellm.embedding(model=embedding_model, input=text, **kwargs),
            )

            embeddings = []
            for data in response.data:
                embeddings.append(data.embedding)

            return embeddings

        except Exception as e:
            error_msg = self._format_error(e)
            raise Exception(f"LiteLLM embedding request failed: {error_msg}")

    def _get_embedding_model(self) -> str:
        
        embedding_models = {
            "openai": "text-embedding-ada-002",
            "openrouter": "openai/text-embedding-ada-002",
            "anthropic": "openai/text-embedding-ada-002",  # Fallback to OpenAI
            "cohere": "embed-english-v2.0",
            "huggingface": "sentence-transformers/all-MiniLM-L6-v2",
        }

        return embedding_models.get(self.provider, "text-embedding-ada-002")

    def _calculate_cost(self, usage: Dict[str, Any], model: str) -> float:
        
        try:
            prompt_tokens = usage.get("prompt_tokens", 0)
            completion_tokens = usage.get("completion_tokens", 0)

            cost_per_1k_tokens = {
                "openai/gpt-4": {"prompt": 0.03, "completion": 0.06},
                "openai/gpt-3.5-turbo": {"prompt": 0.001, "completion": 0.002},
                "anthropic/claude-3": {"prompt": 0.008, "completion": 0.024},
                "anthropic/claude-3-haiku": {"prompt": 0.00025, "completion": 0.00125},
                "openrouter/anthropic/claude-3-haiku": {
                    "prompt": 0.00025,
                    "completion": 0.00125,
                },
            }

            default_rates = {"prompt": 0.001, "completion": 0.002}
            rates = cost_per_1k_tokens.get(model, default_rates)

            prompt_cost = (prompt_tokens / 1000) * rates["prompt"]
            completion_cost = (completion_tokens / 1000) * rates["completion"]

            return prompt_cost + completion_cost

        except Exception:
            return 0.0

    def _format_error(self, error: Exception) -> str:
        
        error_str = str(error)

        error_patterns = {
            "authentication": "Invalid API key. Please check your API key configuration.",
            "rate_limit": "Rate limit exceeded. Please try again later.",
            "quota": "API quota exceeded. Please check your billing settings.",
            "model_not_found": f"Model '{self.model}' not found. Please check the model name.",
            "invalid_request": "Invalid request format. Please check your parameters.",
            "network": "Network error. Please check your internet connection.",
            "timeout": "Request timed out. Please try again.",
        }

        for pattern, message in error_patterns.items():
            if pattern in error_str.lower():
                return message

        return error_str

    @classmethod
    def from_config(cls, config: Dict[str, Any]) -> "LiteLLMProvider":
        
        supported_params = {"model", "api_key", "api_base", "temperature", "max_tokens"}
        filtered_config = {k: v for k, v in config.items() if k in supported_params}

        return cls(
            model=filtered_config.get("model", "openai/gpt-3.5-turbo"),
            api_key=filtered_config.get("api_key"),
            api_base=filtered_config.get("api_base"),
            temperature=filtered_config.get("temperature", 0.1),
            max_tokens=filtered_config.get("max_tokens", 4000),
        )

    @classmethod
    def get_supported_providers(cls) -> List[str]:
        
        return [
            "openai",
            "anthropic",
            "claude",
            "openrouter",
            "together",
            "replicate",
            "cohere",
            "huggingface",
            "bedrock",
            "azure",
            "vertexai",
            "palm",
        ]

    @classmethod
    def get_provider_models(cls, provider: str) -> List[str]:
        
        provider_models = {
            "openai": ["gpt-4", "gpt-3.5-turbo", "gpt-3.5-turbo-16k"],
            "anthropic": ["claude-3-opus", "claude-3-sonnet", "claude-3-haiku"],
            "openrouter": [
                "anthropic/claude-3-opus",
                "anthropic/claude-3-sonnet",
                "anthropic/claude-3-haiku",
                "openai/gpt-4",
                "openai/gpt-3.5-turbo",
            ],
            "together": [
                "meta-llama/Llama-2-70b-chat-hf",
                "NousResearch/Nous-Hermes-2-Yi-34B",
            ],
            "cohere": ["command", "command-light"],
        }

        return provider_models.get(provider, [])

    async def close(self):
        
        pass


===== EQUITR-coder/EQUITR_coder/providers/model_discovery.py =====
import httpx
from typing import List, Dict, Any
from urllib.parse import urljoin


class LiteLLMModelDiscovery:
    

    def __init__(self, base_url: str = "http://localhost:4000"):
        self.base_url = base_url.rstrip("/")
        self.models_endpoint = urljoin(self.base_url, "/v1/models")

    async def get_available_models(self) -> List[Dict[str, Any]]:
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(self.models_endpoint)
                response.raise_for_status()
                data = response.json()
                return data.get("data", [])
        except Exception as e:
            print(f"Error fetching models from {self.models_endpoint}: {e}")
            return []

    def get_available_models_sync(self) -> List[Dict[str, Any]]:
        
        try:
            with httpx.Client() as client:
                response = client.get(self.models_endpoint)
                response.raise_for_status()
                data = response.json()
                return data.get("data", [])
        except Exception as e:
            print(f"Error fetching models from {self.models_endpoint}: {e}")
            return []

    def get_model_names(self, sync: bool = False) -> List[str]:
        
        if sync:
            models = self.get_available_models_sync()
        else:
            return []

        return [model.get("id", "") for model in models if model.get("id")]

    def is_model_available(self, model_name: str, sync: bool = False) -> bool:
        
        available_models = self.get_model_names(sync=sync)
        return model_name in available_models

    def validate_lite_llm_connection(self) -> bool:
        
        try:
            models = self.get_available_models_sync()
            return len(models) > 0
        except Exception:
            return False


===== EQUITR-coder/EQUITR_coder/providers/openrouter.py =====
import os
from typing import List, Dict, Any, Optional
import httpx
from pydantic import BaseModel


class Message(BaseModel):
    role: str
    content: str
    tool_call_id: Optional[str] = None
    name: Optional[str] = None
    tool_calls: Optional[List[Dict[str, Any]]] = None


class ToolCall(BaseModel):
    id: str
    type: str = "function"
    function: Dict[str, Any]


class ChatResponse(BaseModel):
    content: str
    tool_calls: List[ToolCall] = []
    usage: Dict[str, Any] = {}
    cost: float = 0.0


class OpenRouterProvider:
    def __init__(
        self, api_key: str, model: str, api_base: str = "https://openrouter.ai/api/v1"
    ):
        self.api_key = api_key
        self.model = model
        self.api_base = api_base.rstrip("/")
        self.client = httpx.AsyncClient(
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://github.com/equitr/EQUITR-coder",
                "X-Title": "EQUITR Coder",
            },
            timeout=60.0,
        )

    async def chat(
        self,
        messages: List[Message],
        tools: Optional[List[Dict[str, Any]]] = None,
        temperature: float = 0.1,
        max_tokens: int = 4000,
    ) -> ChatResponse:
        

        formatted_messages = []
        for msg in messages:
            formatted_msg = {"role": msg.role, "content": msg.content}
            if msg.tool_call_id:
                formatted_msg["tool_call_id"] = msg.tool_call_id
            if msg.name:
                formatted_msg["name"] = msg.name
            if msg.tool_calls:
                formatted_msg["tool_calls"] = msg.tool_calls
            formatted_messages.append(formatted_msg)

        payload = {
            "model": self.model,
            "messages": formatted_messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
        }

        if tools:
            functions = []
            for tool in tools:
                functions.append(
                    {
                        "type": "function",
                        "function": {
                            "name": tool["name"],
                            "description": tool["description"],
                            "parameters": tool["parameters"],
                        },
                    }
                )
            payload["tools"] = functions
            payload["tool_choice"] = "auto"

        try:
            response = await self.client.post(
                f"{self.api_base}/chat/completions", json=payload
            )
            response.raise_for_status()

            data = response.json()
            choice = data["choices"][0]
            message = choice["message"]

            content = message.get("content", "") or ""

            tool_calls = []
            if "tool_calls" in message and message["tool_calls"]:
                for tc in message["tool_calls"]:
                    tool_calls.append(
                        ToolCall(id=tc["id"], type=tc["type"], function=tc["function"])
                    )

            usage = data.get("usage", {})
            prompt_tokens = usage.get("prompt_tokens", 0)
            completion_tokens = usage.get("completion_tokens", 0)

            cost = (prompt_tokens * 0.001 + completion_tokens * 0.002) / 1000

            return ChatResponse(
                content=content, tool_calls=tool_calls, usage=usage, cost=cost
            )

        except httpx.HTTPStatusError as e:
            error_detail = ""
            try:
                error_data = e.response.json()
                error_detail = error_data.get("error", {}).get("message", str(e))
            except Exception:
                error_detail = str(e)

            raise Exception(f"OpenRouter API error: {error_detail}")

        except Exception as e:
            raise Exception(f"Request failed: {str(e)}")

    async def close(self):
        
        await self.client.aclose()

    @classmethod
    def from_env(cls, model: str = "anthropic/claude-3-haiku") -> "OpenRouterProvider":
        
        api_key = os.getenv("OPENROUTER_API_KEY")
        if not api_key:
            raise ValueError(
                "OPENROUTER_API_KEY environment variable is required. "
                "Get your API key from https://openrouter.ai"
            )

        return cls(api_key=api_key, model=model)


===== EQUITR-coder/EQUITR_coder/utils/env_loader.py =====


import os
from pathlib import Path
from typing import Optional, Dict, Any


def load_dotenv_file(env_file: Optional[str] = None) -> bool:
    
    try:
        from dotenv import load_dotenv
        
        if env_file:
            env_path = Path(env_file)
            if env_path.exists():
                load_dotenv(env_path, override=False)  # Don't override existing env vars
                print(f"‚úÖ Loaded environment variables from {env_path}")
                return True
            else:
                print(f"‚ö†Ô∏è  .env file not found at {env_path}")
                return False
        else:
            current_dir = Path.cwd()
            for parent in [current_dir] + list(current_dir.parents):
                env_path = parent / ".env"
                if env_path.exists():
                    load_dotenv(env_path, override=False)  # Don't override existing env vars
                    print(f"‚úÖ Loaded environment variables from {env_path}")
                    return True
            
            print("‚ö†Ô∏è  No .env file found in current directory or parents")
            return False
            
    except ImportError:
        print("‚ö†Ô∏è  python-dotenv not installed. Install with: pip install python-dotenv")
        return False
    except Exception as e:
        print(f"‚ùå Error loading .env file: {e}")
        return False


def get_api_key(provider: str, env_var: Optional[str] = None) -> Optional[str]:
    
    if env_var and env_var in os.environ:
        return os.environ[env_var]
    
    provider_env_vars = {
        "openai": ["OPENAI_API_KEY", "OPENAI_API_TOKEN"],
        "moonshot": ["MOONSHOT_API_KEY", "MOONSHOT_API_TOKEN"],
        "openrouter": ["OPENROUTER_API_KEY", "OPENROUTER_API_TOKEN"],
        "anthropic": ["ANTHROPIC_API_KEY", "ANTHROPIC_API_TOKEN"],
        "google": ["GOOGLE_API_KEY", "GEMINI_API_KEY"],
        "cohere": ["COHERE_API_KEY"],
        "replicate": ["REPLICATE_API_TOKEN"],
        "huggingface": ["HUGGINGFACE_API_KEY", "HF_TOKEN"],
    }
    
    provider_lower = provider.lower()
    if provider_lower in provider_env_vars:
        for env_var_name in provider_env_vars[provider_lower]:
            if env_var_name in os.environ:
                return os.environ[env_var_name]
    
    if "API_KEY" in os.environ:
        return os.environ["API_KEY"]
    
    return None


def setup_provider_environment(provider: str, api_key: Optional[str] = None) -> bool:
    
    if not api_key:
        api_key = get_api_key(provider)
    
    if not api_key:
        return False
    
    provider_lower = provider.lower()
    
    if provider_lower == "openai":
        os.environ["OPENAI_API_KEY"] = api_key
    elif provider_lower == "moonshot":
        os.environ["MOONSHOT_API_KEY"] = api_key
        if "MOONSHOT_API_BASE" not in os.environ:
            os.environ["MOONSHOT_API_BASE"] = "https://api.moonshot.ai/v1"
    elif provider_lower == "openrouter":
        os.environ["OPENROUTER_API_KEY"] = api_key
    elif provider_lower == "anthropic":
        os.environ["ANTHROPIC_API_KEY"] = api_key
    elif provider_lower == "google":
        os.environ["GOOGLE_API_KEY"] = api_key
    elif provider_lower == "cohere":
        os.environ["COHERE_API_KEY"] = api_key
    else:
        os.environ["API_KEY"] = api_key
    
    return True


def get_available_providers() -> Dict[str, Any]:
    
    providers = {}
    
    provider_checks = [
        ("openai", ["OPENAI_API_KEY"]),
        ("moonshot", ["MOONSHOT_API_KEY"]),
        ("openrouter", ["OPENROUTER_API_KEY"]),
        ("anthropic", ["ANTHROPIC_API_KEY"]),
        ("google", ["GOOGLE_API_KEY", "GEMINI_API_KEY"]),
        ("cohere", ["COHERE_API_KEY"]),
        ("replicate", ["REPLICATE_API_TOKEN"]),
        ("huggingface", ["HUGGINGFACE_API_KEY", "HF_TOKEN"]),
    ]
    
    for provider, env_vars in provider_checks:
        api_key = None
        env_var_found = None
        
        for env_var in env_vars:
            if env_var in os.environ and os.environ[env_var]:
                api_key = os.environ[env_var]
                env_var_found = env_var
                break
        
        providers[provider] = {
            "available": api_key is not None,
            "env_var": env_var_found,
            "key_length": len(api_key) if api_key else 0,
            "key_preview": f"{api_key[:8]}...{api_key[-4:]}" if api_key and len(api_key) > 12 else None
        }
    
    return providers


def auto_load_environment() -> Dict[str, Any]:
    
    dotenv_loaded = load_dotenv_file()
    
    providers = get_available_providers()
    available_count = sum(1 for p in providers.values() if p["available"])
    
    return {
        "dotenv_loaded": dotenv_loaded,
        "providers": providers,
        "available_providers": available_count,
        "total_providers": len(providers)
    }


if __name__ == "__main__":
    
    print("üîß Environment Variable Loader Test")
    print("=" * 40)
    
    status = auto_load_environment()
    
    print(f"üìÅ .env file loaded: {'‚úÖ' if status['dotenv_loaded'] else '‚ùå'}")
    print(f"üîë Available providers: {status['available_providers']}/{status['total_providers']}")
    print()
    
    print("üìã Provider Status:")
    for provider, info in status["providers"].items():
        status_icon = "‚úÖ" if info["available"] else "‚ùå"
        if info["available"]:
            print(f"  {status_icon} {provider}: {info['env_var']} ({info['key_length']} chars)")
        else:
            print(f"  {status_icon} {provider}: No API key found") 

===== EQUITR-coder/EQUITR_coder/utils/litellm_utils.py =====


import litellm
from typing import Dict, List, Any, Optional


def check_function_calling_support(model: str) -> bool:
    
    model_lower = model.lower()
    
    openai_function_models = [
        "gpt-4", "gpt-4-turbo", "gpt-4o", "gpt-4.1", "gpt-4-1106-preview", 
        "gpt-4-0125-preview", "gpt-3.5-turbo", "gpt-3.5-turbo-1106"
    ]
    
    anthropic_function_models = [
        "claude-3-opus", "claude-3-sonnet", "claude-3-haiku", 
        "claude-3-5-sonnet", "claude-2.1"
    ]
    
    moonshot_function_models = [
        "moonshot/moonshot-v1-8k", "moonshot/moonshot-v1-32k", "moonshot/moonshot-v1-128k",
        "moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"
    ]
    
    google_function_models = [
        "gemini-pro", "gemini-1.5-pro", "gemini-1.5-flash"
    ]
    
    if any(supported_model in model_lower for supported_model in openai_function_models):
        return True
    if any(supported_model in model_lower for supported_model in anthropic_function_models):
        return True
    if any(supported_model in model_lower for supported_model in moonshot_function_models):
        return True
    if any(supported_model in model_lower for supported_model in google_function_models):
        return True
    
    try:
        return litellm.supports_function_calling(model)
    except:
        return False


def check_parallel_function_calling_support(model: str) -> bool:
    
    model_lower = model.lower()
    
    parallel_models = [
        "gpt-4-turbo", "gpt-4o", "gpt-4-1106-preview", "gpt-4-0125-preview",
        "gpt-3.5-turbo-1106", "claude-3-opus", "claude-3-sonnet", "claude-3-5-sonnet"
    ]
    
    moonshot_models = ["moonshot/", "moonshot-v1"]
    if any(moonshot_model in model_lower for moonshot_model in moonshot_models):
        return False
    
    return any(parallel_model in model_lower for parallel_model in parallel_models)


def get_model_compatibility(model: str) -> Dict[str, Any]:
    
    compatibility = {
        "model": model,
        "supported": True,  # Assume supported unless proven otherwise
        "function_calling": check_function_calling_support(model),
        "parallel_support": check_parallel_function_calling_support(model),
        "warnings": []
    }
    
    if not compatibility["function_calling"]:
        compatibility["warnings"].append(
            f"Model {model} does not support function calling. Tool usage will be limited."
        )
    elif not compatibility["parallel_support"]:
        compatibility["warnings"].append(
            f"Model {model} does not support parallel function calling. Only sequential tool execution will be available."
        )
    
    if "moonshot" in model.lower():
        if "MOONSHOT_API_KEY" not in os.environ:
            compatibility["warnings"].append(
                "MOONSHOT_API_KEY environment variable not set. Please set your Moonshot AI API key."
            )
    
    return compatibility


def get_compatible_tools(tools: List[Dict[str, Any]], model: str, force_enable: bool = True) -> List[Dict[str, Any]]:
    
    if force_enable:
        return tools
    
    if not check_function_calling_support(model):
        return []
    
    return tools


def get_supported_moonshot_models() -> List[str]:
    
    return [
        "moonshot/moonshot-v1-8k",
        "moonshot/moonshot-v1-32k", 
        "moonshot/moonshot-v1-128k"
    ]


def setup_moonshot_provider(api_key: str) -> None:
    
    import os
    os.environ["MOONSHOT_API_KEY"] = api_key
    
    if not api_key or len(api_key) < 10:
        raise ValueError("Invalid Moonshot API key format")


def get_model_provider(model: str) -> str:
    
    model_lower = model.lower()
    
    if model_lower.startswith("gpt-") or "openai" in model_lower:
        return "openai"
    elif model_lower.startswith("claude-") or "anthropic" in model_lower:
        return "anthropic"
    elif "moonshot" in model_lower:
        return "moonshot"
    elif model_lower.startswith("gemini-") or "google" in model_lower:
        return "google"
    elif "llama" in model_lower:
        return "meta"
    else:
        return "unknown"


import os


===== EQUITR-coder/EQUITR_coder/utils/tool_logger.py =====


import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict

from ..providers.openrouter import ToolCall
from ..tools.base import ToolResult


@dataclass
class ToolCallLog:
    
    timestamp: str
    session_id: Optional[str]
    tool_name: str
    tool_args: Dict[str, Any]
    result: Dict[str, Any]
    success: bool
    duration_ms: float
    error: Optional[str] = None


class ToolCallLogger:
    
    
    def __init__(self, log_file: str = "tool_calls.log", enabled: bool = False):
        self.log_file = Path(log_file)
        self.enabled = enabled
        self.logs: List[ToolCallLog] = []
        
        if self.enabled:
            self.logger = logging.getLogger("tool_calls")
            self.logger.setLevel(logging.INFO)
            
            handler = logging.FileHandler(self.log_file)
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
    
    def log_tool_call(
        self,
        tool_call: ToolCall,
        result: ToolResult,
        duration_ms: float,
        session_id: Optional[str] = None
    ):
        
        if not self.enabled:
            return
        
        tool_args = tool_call.function.get("arguments", {})
        if isinstance(tool_args, str):
            try:
                tool_args = json.loads(tool_args)
            except json.JSONDecodeError:
                tool_args = {"raw_args": tool_args}
        
        log_entry = ToolCallLog(
            timestamp=datetime.now().isoformat(),
            session_id=session_id,
            tool_name=tool_call.function["name"],
            tool_args=tool_args,
            result={
                "success": result.success,
                "content": str(result)[:1000],  # Truncate long results
                "metadata": getattr(result, 'metadata', {})
            },
            success=result.success,
            duration_ms=duration_ms,
            error=result.error if not result.success else None
        )
        
        self.logs.append(log_entry)
        
        self.logger.info(json.dumps(asdict(log_entry), indent=2))
    
    def get_logs(self, limit: Optional[int] = None) -> List[ToolCallLog]:
        
        if limit:
            return self.logs[-limit:]
        return self.logs.copy()
    
    def clear_logs(self):
        
        self.logs.clear()
    
    def get_stats(self) -> Dict[str, Any]:
        
        if not self.logs:
            return {}
        
        total_calls = len(self.logs)
        successful_calls = sum(1 for log in self.logs if log.success)
        failed_calls = total_calls - successful_calls
        
        tool_usage = {}
        total_duration = 0
        
        for log in self.logs:
            tool_name = log.tool_name
            if tool_name not in tool_usage:
                tool_usage[tool_name] = {
                    "count": 0,
                    "success_count": 0,
                    "total_duration_ms": 0
                }
            
            tool_usage[tool_name]["count"] += 1
            if log.success:
                tool_usage[tool_name]["success_count"] += 1
            tool_usage[tool_name]["total_duration_ms"] += log.duration_ms
            total_duration += log.duration_ms
        
        return {
            "total_calls": total_calls,
            "successful_calls": successful_calls,
            "failed_calls": failed_calls,
            "success_rate": successful_calls / total_calls if total_calls > 0 else 0,
            "total_duration_ms": total_duration,
            "average_duration_ms": total_duration / total_calls if total_calls > 0 else 0,
            "tool_usage": tool_usage
        }
    
    def export_logs(self, file_path: str, format: str = "json"):
        
        export_path = Path(file_path)
        
        if format == "json":
            with open(export_path, "w") as f:
                json.dump([asdict(log) for log in self.logs], f, indent=2)
        elif format == "csv":
            import csv
            with open(export_path, "w", newline="") as f:
                if self.logs:
                    writer = csv.DictWriter(f, fieldnames=asdict(self.logs[0]).keys())
                    writer.writeheader()
                    for log in self.logs:
                        writer.writerow(asdict(log))
        else:
            raise ValueError(f"Unsupported export format: {format}")


tool_logger = ToolCallLogger()


def configure_tool_logger(log_file: str = "tool_calls.log", enabled: bool = False):
    
    global tool_logger
    tool_logger = ToolCallLogger(log_file, enabled)


def get_tool_logger() -> ToolCallLogger:
    
    return tool_logger 

===== src/tools/ask_supervisor.py =====
import json
from typing import Dict, Any, Optional, List
from pathlib import Path


class AskSupervisorTool:
    def __init__(self, supervisor_callback):
        self.supervisor_callback = supervisor_callback
        self.call_count = 0
        self.max_calls = 5

    def __call__(self, question: str, context: Optional[str] = None) -> Dict[str, Any]:
        if self.call_count >= self.max_calls:
            return {
                "error": f"Maximum supervisor calls ({self.max_calls}) exceeded",
                "suggestion": "Try to proceed independently or request manual intervention",
            }

        self.call_count += 1

        try:
            response = self.supervisor_callback(question, context)
            return {
                "response": response,
                "call_count": self.call_count,
                "remaining_calls": self.max_calls - self.call_count,
            }
        except Exception as e:
            return {
                "error": f"Failed to contact supervisor: {str(e)}",
                "call_count": self.call_count,
            }


class SupervisorSession:
    def __init__(self):
        self.conversation_history = []

    def ask(self, question: str, context: Optional[str] = None) -> str:
        self.conversation_history.append(
            {"type": "worker_question", "question": question, "context": context}
        )

        response = self._generate_response(question, context)

        self.conversation_history.append(
            {"type": "supervisor_response", "response": response}
        )

        return response

    def _generate_response(self, question: str, context: Optional[str] = None) -> str:
        if "error" in question.lower():
            return "Check the error message carefully. Look for file paths, line numbers, and specific error types. Try to isolate the issue by testing smaller components."
        elif "test" in question.lower():
            return "Run the existing tests first to understand the current state. Then add tests for your new functionality before implementing the feature."
        elif "refactor" in question.lower():
            return "Focus on one small piece at a time. Ensure tests pass after each change. Document what you're refactoring and why."
        else:
            return "Proceed step by step. Make small, testable changes. If blocked, provide specific details about what's not working."

    def get_history(self) -> List[Dict[str, Any]]:
        return self.conversation_history


_supervisor = None


def get_supervisor() -> SupervisorSession:
    global _supervisor
    if _supervisor is None:
        _supervisor = SupervisorSession()
    return _supervisor


def create_ask_supervisor_tool() -> AskSupervisorTool:
    supervisor = get_supervisor()
    return AskSupervisorTool(supervisor.ask)


===== src/core/project_checklist.py =====
import json
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from pathlib import Path


@dataclass
class WorkerSpec:
    id: str
    scope_paths: List[str]
    description: str
    allowed_tools: List[str]


@dataclass
class Task:
    id: int
    title: str
    assigned_to: str
    status: str  # "todo", "in_progress", "done", "cancelled"


@dataclass
class ProjectChecklist:
    workers_spec: List[WorkerSpec]
    tasks: List[Task]

    def to_dict(self) -> Dict[str, Any]:
        return {
            "workers_spec": [asdict(w) for w in self.workers_spec],
            "tasks": [asdict(t) for t in self.tasks],
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "ProjectChecklist":
        workers = [WorkerSpec(**w) for w in data.get("workers_spec", [])]
        tasks = [Task(**t) for t in data.get("tasks", [])]
        return cls(workers_spec=workers, tasks=tasks)


class ChecklistManager:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.checklist_file = self.project_root / "PROJECT_CHECKLIST.json"
        self._checklist = self._load_checklist()

    def _load_checklist(self) -> ProjectChecklist:
        if self.checklist_file.exists():
            try:
                with open(self.checklist_file, "r") as f:
                    data = json.load(f)
                return ProjectChecklist.from_dict(data)
            except (json.JSONDecodeError, TypeError):
                pass

        return ProjectChecklist(workers_spec=[], tasks=[])

    def save_checklist(self):
        self.checklist_file.parent.mkdir(parents=True, exist_ok=True)
        with open(self.checklist_file, "w") as f:
            json.dump(self._checklist.to_dict(), f, indent=2)

    def get_checklist(self) -> ProjectChecklist:
        return self._checklist

    def add_worker_spec(self, worker_spec: WorkerSpec):
        self._checklist.workers_spec.append(worker_spec)
        self.save_checklist()

    def add_task(self, task: Task):
        self._checklist.tasks.append(task)
        self.save_checklist()

    def update_task_status(self, task_id: int, status: str):
        for task in self._checklist.tasks:
            if task.id == task_id:
                task.status = status
                self.save_checklist()
                return True
        return False

    def get_tasks_by_worker(self, worker_id: str) -> List[Task]:
        return [t for t in self._checklist.tasks if t.assigned_to == worker_id]

    def get_pending_tasks(self) -> List[Task]:
        return [t for t in self._checklist.tasks if t.status == "todo"]

    def get_in_progress_tasks(self) -> List[Task]:
        return [t for t in self._checklist.tasks if t.status == "in_progress"]

    def get_completed_tasks(self) -> List[Task]:
        return [t for t in self._checklist.tasks if t.status == "done"]

    def all_tasks_completed(self) -> bool:
        return all(t.status == "done" for t in self._checklist.tasks)

    def clear_checklist(self):
        self._checklist = ProjectChecklist(workers_spec=[], tasks=[])
        self.save_checklist()


_checklist_manager = None


def get_checklist_manager(project_root: str = ".") -> ChecklistManager:
    global _checklist_manager
    if _checklist_manager is None:
        _checklist_manager = ChecklistManager(project_root)
    return _checklist_manager


===== src/config/model_config.py =====
import json
import os
from pathlib import Path
from typing import Dict, List, Optional, Union
from dataclasses import dataclass, asdict


@dataclass
class ModelConfig:
    mode: str = "single"  # "single" or "multi"
    primary_model: str = "strong"
    secondary_model: Optional[str] = None
    models: List[str] = None

    def __post_init__(self):
        if self.models is None:
            self.models = [self.primary_model]
        if (
            self.mode == "multi"
            and self.secondary_model
            and self.secondary_model not in self.models
        ):
            self.models.append(self.secondary_model)


class ModelConfigManager:
    def __init__(self, config_dir: Optional[str] = None):
        if config_dir is None:
            config_dir = os.path.expanduser("~/.equitrcoder")
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(exist_ok=True)
        self.config_file = self.config_dir / "model_config.json"
        self._config = self._load_config()

    def _load_config(self) -> ModelConfig:
        if self.config_file.exists():
            try:
                with open(self.config_file, "r") as f:
                    data = json.load(f)
                return ModelConfig(**data)
            except (json.JSONDecodeError, TypeError):
                pass
        return ModelConfig()

    def save_config(self, config: ModelConfig):
        self._config = config
        with open(self.config_file, "w") as f:
            json.dump(asdict(config), f, indent=2)

    def get_config(self) -> ModelConfig:
        return self._config

    def set_mode(self, mode: str):
        if mode not in ["single", "multi"]:
            raise ValueError("Mode must be 'single' or 'multi'")
        config = self.get_config()
        config.mode = mode
        self.save_config(config)

    def set_models(self, primary: str, secondary: Optional[str] = None):
        config = self.get_config()
        config.primary_model = primary
        config.secondary_model = secondary
        if config.mode == "multi" and secondary:
            config.models = [primary, secondary]
        else:
            config.models = [primary]
        self.save_config(config)

    def get_available_models(self) -> List[str]:
        return [
            "strong",
            "weak",
            "gpt-4",
            "gpt-3.5-turbo",
            "claude-3-opus",
            "claude-3-haiku",
        ]

    def is_multi_mode(self) -> bool:
        return self._config.mode == "multi"

    def get_active_models(self) -> List[str]:
        return self._config.models


_config_manager = None


def get_config_manager() -> ModelConfigManager:
    global _config_manager
    if _config_manager is None:
        _config_manager = ModelConfigManager()
    return _config_manager


===== src/agents/worker_agent.py =====
import os
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
import fnmatch

from src.tools.ask_supervisor import create_ask_supervisor_tool


class RestrictedFileSystem:
    def __init__(self, allowed_paths: List[str], project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.allowed_paths = [Path(p).resolve() for p in allowed_paths]
        self.allowed_files = set()
        self._build_allowed_files()

    def _build_allowed_files(self):
        
        for path in self.allowed_paths:
            if path.is_file():
                self.allowed_files.add(path)
            elif path.is_dir():
                for file_path in path.rglob("*"):
                    if file_path.is_file():
                        self.allowed_files.add(file_path)

    def is_allowed(self, file_path: str) -> bool:
        
        try:
            resolved_path = Path(file_path).resolve()

            for allowed_path in self.allowed_paths:
                try:
                    resolved_path.relative_to(allowed_path)
                    return True
                except ValueError:
                    continue

            return resolved_path in self.allowed_files
        except Exception:
            return False

    def list_allowed_files(self) -> List[str]:
        
        return [str(p) for p in sorted(self.allowed_files)]

    def glob_files(self, pattern: str) -> List[str]:
        
        matches = []
        for allowed_path in self.allowed_paths:
            if allowed_path.is_dir():
                for file_path in allowed_path.rglob(pattern):
                    if file_path.is_file() and self.is_allowed(str(file_path)):
                        matches.append(str(file_path))
            elif allowed_path.is_file() and fnmatch.fnmatch(allowed_path.name, pattern):
                matches.append(str(allowed_path))
        return sorted(matches)


class RestrictedToolRegistry:
    def __init__(self, allowed_tools: List[str]):
        self.allowed_tools = set(allowed_tools)
        self.tool_registry = {}
        self._setup_tools()

    def _setup_tools(self):
        
        if "read_file" in self.allowed_tools:
            self.tool_registry["read_file"] = self._read_file
        if "edit_file" in self.allowed_tools:
            self.tool_registry["edit_file"] = self._edit_file
        if "run_cmd" in self.allowed_tools:
            self.tool_registry["run_cmd"] = self._run_cmd
        if "git_commit" in self.allowed_tools:
            self.tool_registry["git_commit"] = self._git_commit
        if "ask_supervisor" in self.allowed_tools:
            self.tool_registry["ask_supervisor"] = create_ask_supervisor_tool()

    def can_use_tool(self, tool_name: str) -> bool:
        
        return tool_name in self.allowed_tools

    def get_tool(self, tool_name: str):
        
        return self.tool_registry.get(tool_name)

    def _read_file(self, file_path: str) -> str:
        
        if not hasattr(self, "file_system"):
            raise RuntimeError("File system not initialized")

        if not self.file_system.is_allowed(file_path):
            raise PermissionError(f"Access denied to file: {file_path}")

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            raise RuntimeError(f"Failed to read file {file_path}: {e}")

    def _edit_file(self, file_path: str, content: str):
        
        if not hasattr(self, "file_system"):
            raise RuntimeError("File system not initialized")

        if not self.file_system.is_allowed(file_path):
            raise PermissionError(f"Access denied to file: {file_path}")

        try:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
        except Exception as e:
            raise RuntimeError(f"Failed to write file {file_path}: {e}")

    def _run_cmd(self, cmd: str) -> Dict[str, Any]:
        
        import subprocess

        try:
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            return {
                "stdout": result.stdout,
                "stderr": result.stderr,
                "returncode": result.returncode,
            }
        except Exception as e:
            return {"error": str(e)}

    def _git_commit(self, message: str) -> Dict[str, Any]:
        
        return self._run_cmd(f'git commit -m "{message}"')


class WorkerAgent:
    def __init__(
        self,
        worker_id: str,
        scope_paths: List[str],
        allowed_tools: List[str],
        project_root: str = ".",
    ):
        self.worker_id = worker_id
        self.scope_paths = scope_paths
        self.allowed_tools = allowed_tools
        self.project_root = Path(project_root)

        self.file_system = RestrictedFileSystem(scope_paths, project_root)
        self.tool_registry = RestrictedToolRegistry(allowed_tools)

        self.tool_registry.file_system = self.file_system

        if "ask_supervisor" in allowed_tools:
            self.ask_supervisor = create_ask_supervisor_tool()

    def get_status(self) -> Dict[str, Any]:
        
        return {
            "worker_id": self.worker_id,
            "scope_paths": self.scope_paths,
            "allowed_tools": self.allowed_tools,
            "allowed_files_count": len(self.file_system.allowed_files),
            "available_tools": list(self.tool_registry.tool_registry.keys()),
        }

    def can_access_file(self, file_path: str) -> bool:
        
        return self.file_system.is_allowed(file_path)

    def can_use_tool(self, tool_name: str) -> bool:
        
        return self.tool_registry.can_use_tool(tool_name)

    def list_allowed_files(self) -> List[str]:
        
        return self.file_system.list_allowed_files()

    def execute_tool(self, tool_name: str, **kwargs) -> Any:
        
        if not self.can_use_tool(tool_name):
            raise PermissionError(
                f"Tool '{tool_name}' not allowed for worker {self.worker_id}"
            )

        tool = self.tool_registry.get_tool(tool_name)
        if tool is None:
            raise ValueError(f"Tool '{tool_name}' not found")

        return tool(**kwargs)


===== src/cli/main_cli.py =====
import argparse
import sys
import asyncio
from typing import List

from src.cli.model_cli import ModelCLI
from src.audit.audit_phase import run_audit
from src.orchestrator.multi_agent_orchestrator import run_multi_agent_workflow
from src.config.model_config import get_config_manager


class MainCLI:
    def __init__(self):
        self.config_manager = get_config_manager()

    def create_parser(self) -> argparse.ArgumentParser:
        parser = argparse.ArgumentParser(description="OpenCode Multi-Agent CLI")
        subparsers = parser.add_subparsers(dest="command", help="Available commands")

        model_parser = subparsers.add_parser(
            "model", help="Model configuration commands"
        )
        model_subparsers = model_parser.add_subparsers(dest="model_command")

        mode_parser = model_subparsers.add_parser("mode", help="Set model mode")
        mode_parser.add_argument("mode", choices=["single", "multi"], help="Model mode")

        models_parser = model_subparsers.add_parser("models", help="Set models")
        models_parser.add_argument("primary", help="Primary model")
        models_parser.add_argument("--secondary", help="Secondary model for multi-mode")

        show_parser = model_subparsers.add_parser(
            "show", help="Show current configuration"
        )

        workflow_parser = subparsers.add_parser(
            "workflow", help="Run multi-agent workflow"
        )
        workflow_parser.add_argument(
            "--project-root", default=".", help="Project root directory"
        )

        audit_parser = subparsers.add_parser("audit", help="Run audit phase")
        audit_parser.add_argument(
            "--project-root", default=".", help="Project root directory"
        )
        audit_parser.add_argument(
            "--mode", choices=["final", "periodic"], default="final", help="Audit mode"
        )

        status_parser = subparsers.add_parser("status", help="Show system status")

        return parser

    def run(self, args: List[str] = None):
        if args is None:
            args = sys.argv[1:]

        parser = self.create_parser()
        parsed_args = parser.parse_args(args)

        if parsed_args.command == "model":
            self.handle_model_command(parsed_args)
        elif parsed_args.command == "workflow":
            asyncio.run(self.run_workflow(parsed_args))
        elif parsed_args.command == "audit":
            asyncio.run(self.run_audit(parsed_args))
        elif parsed_args.command == "status":
            self.show_status()
        else:
            parser.print_help()

    def handle_model_command(self, args):
        
        model_cli = ModelCLI()

        if args.model_command == "mode":
            model_cli.set_mode(args.mode)
        elif args.model_command == "models":
            model_cli.set_models(args.primary, args.secondary)
        elif args.model_command == "show":
            model_cli.show_config()
        else:
            model_cli.run([args.model_command] + sys.argv[3:])

    async def run_workflow(self, args):
        
        print("Starting multi-agent workflow...")
        result = await run_multi_agent_workflow(args.project_root)

        print(f"Workflow completed:")
        print(f"  Tasks completed: {result.get('tasks_completed', 0)}")
        print(f"  Tasks failed: {result.get('tasks_failed', 0)}")

        if result.get("results"):
            for r in result["results"]:
                if "error" in r:
                    print(f"  Task {r['task_id']} failed: {r['error']}")
                else:
                    print(f"  Task {r['task_id']} completed successfully")

    async def run_audit(self, args):
        
        print("Running audit...")
        result = run_audit(args.project_root)

        print(f"Audit results:")
        print(f"  Audit passed: {result.get('audit_passed', False)}")
        print(f"  Tests passed: {result.get('tests', {}).get('passed', False)}")
        print(f"  Linting passed: {result.get('linting', {}).get('passed', False)}")
        print(f"  Git clean: {result.get('git_status', {}).get('clean', False)}")

        if result.get("new_tasks"):
            print(f"  New tasks generated: {len(result['new_tasks'])}")
            for task in result["new_tasks"]:
                print(f"    - {task['title']} (assigned to {task['assigned_to']})")

    def show_status(self):
        
        config = self.config_manager.get_config()

        print("EQUITR-coder Multi-Agent System Status:")
        print()
        print("Model Configuration:")
        print(f"  Mode: {config.mode}")
        print(f"  Primary Model: {config.primary_model}")
        if config.secondary_model:
            print(f"  Secondary Model: {config.secondary_model}")
        print(f"  Active Models: {', '.join(config.models)}")
        print()

        print("Available Commands:")
        print("  opencode model mode <single|multi>     - Set model mode")
        print("  opencode model models <primary> [--secondary <model>]  - Set models")
        print("  opencode model show                    - Show current config")
        print("  opencode workflow                      - Run multi-agent workflow")
        print("  opencode audit                         - Run audit phase")
        print("  opencode status                        - Show system status")


def main():
    cli = MainCLI()
    cli.run()


if __name__ == "__main__":
    main()


===== src/cli/model_cli.py =====
import argparse
import sys
from typing import List
from src.config.model_config import get_config_manager


class ModelCLI:
    def __init__(self):
        self.config_manager = get_config_manager()

    def create_parser(self) -> argparse.ArgumentParser:
        parser = argparse.ArgumentParser(description="Model configuration CLI")
        subparsers = parser.add_subparsers(dest="command", help="Available commands")

        mode_parser = subparsers.add_parser(
            "mode", help="Set model mode (single/multi)"
        )
        mode_parser.add_argument("mode", choices=["single", "multi"], help="Model mode")

        models_parser = subparsers.add_parser("models", help="Set active models")
        models_parser.add_argument("primary", help="Primary model")
        models_parser.add_argument(
            "--secondary", help="Secondary model (for multi-mode)"
        )

        show_parser = subparsers.add_parser("show", help="Show current configuration")

        list_parser = subparsers.add_parser("list", help="List available models")

        reset_parser = subparsers.add_parser(
            "reset", help="Reset to default configuration"
        )

        return parser

    def run(self, args: List[str] = None):
        if args is None:
            args = sys.argv[1:]

        parser = self.create_parser()
        parsed_args = parser.parse_args(args)

        if parsed_args.command == "mode":
            self.set_mode(parsed_args.mode)
        elif parsed_args.command == "models":
            self.set_models(parsed_args.primary, parsed_args.secondary)
        elif parsed_args.command == "show":
            self.show_config()
        elif parsed_args.command == "list":
            self.list_models()
        elif parsed_args.command == "reset":
            self.reset_config()
        else:
            parser.print_help()

    def set_mode(self, mode: str):
        try:
            self.config_manager.set_mode(mode)
            print(f"Model mode set to: {mode}")
        except ValueError as e:
            print(f"Error: {e}", file=sys.stderr)
            sys.exit(1)

    def set_models(self, primary: str, secondary: str = None):
        available = self.config_manager.get_available_models()

        if primary not in available:
            print(f"Error: Primary model '{primary}' not available", file=sys.stderr)
            print(f"Available models: {', '.join(available)}", file=sys.stderr)
            sys.exit(1)

        if secondary and secondary not in available:
            print(
                f"Error: Secondary model '{secondary}' not available", file=sys.stderr
            )
            print(f"Available models: {', '.join(available)}", file=sys.stderr)
            sys.exit(1)

        self.config_manager.set_models(primary, secondary)
        print(f"Models configured: primary={primary}", end="")
        if secondary:
            print(f", secondary={secondary}")
        else:
            print()

    def show_config(self):
        config = self.config_manager.get_config()
        print("Current Model Configuration:")
        print(f"  Mode: {config.mode}")
        print(f"  Primary Model: {config.primary_model}")
        if config.secondary_model:
            print(f"  Secondary Model: {config.secondary_model}")
        print(f"  Active Models: {', '.join(config.models)}")

    def list_models(self):
        available = self.config_manager.get_available_models()
        print("Available Models:")
        for model in available:
            print(f"  - {model}")

    def reset_config(self):
        from src.config.model_config import ModelConfig

        self.config_manager.save_config(ModelConfig())
        print("Configuration reset to defaults")


def main():
    cli = ModelCLI()
    cli.run()


if __name__ == "__main__":
    main()


===== src/feedback/new_tasks.py =====
import json
from typing import Dict, Any, List
from pathlib import Path

from src.core.project_checklist import get_checklist_manager, Task


class NewTasksGenerator:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.checklist_manager = get_checklist_manager(str(project_root))

    def process_audit_feedback(
        self, audit_results: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        
        new_tasks = []

        if not audit_results.get("audit_passed", False):
            new_tasks.extend(self._generate_test_tasks(audit_results))
            new_tasks.extend(self._generate_lint_tasks(audit_results))
            new_tasks.extend(self._generate_git_tasks(audit_results))
            new_tasks.extend(self._generate_dependency_tasks(audit_results))
            new_tasks.extend(self._generate_structure_tasks(audit_results))

        if new_tasks:
            self._add_tasks_to_checklist(new_tasks)

        return new_tasks

    def _generate_test_tasks(
        self, audit_results: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        
        tasks = []

        test_results = audit_results.get("tests", {})
        if not test_results.get("passed", True):
            if test_results.get("tests_found", False):
                tasks.append(
                    {
                        "id": self._get_next_task_id(),
                        "title": "Fix failing tests",
                        "assigned_to": "test-worker",
                        "status": "todo",
                        "priority": "high",
                        "description": "Address failing test cases identified in audit",
                    }
                )
            else:
                tasks.append(
                    {
                        "id": self._get_next_task_id(),
                        "title": "Add comprehensive tests",
                        "assigned_to": "test-worker",
                        "status": "todo",
                        "priority": "high",
                        "description": "Create test suite for the project",
                    }
                )

        return tasks

    def _generate_lint_tasks(
        self, audit_results: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        
        tasks = []

        lint_results = audit_results.get("linting", {})
        if not lint_results.get("passed", True):
            tasks.append(
                {
                    "id": self._get_next_task_id(),
                    "title": "Fix code style issues",
                    "assigned_to": "lint-worker",
                    "status": "todo",
                    "priority": "medium",
                    "description": "Address linting and code style issues",
                }
            )

        return tasks

    def _generate_git_tasks(
        self, audit_results: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        
        tasks = []

        git_results = audit_results.get("git_status", {})
        if git_results.get("git_repo", False) and not git_results.get("clean", True):
            tasks.append(
                {
                    "id": self._get_next_task_id(),
                    "title": "Commit pending changes",
                    "assigned_to": "git-worker",
                    "status": "todo",
                    "priority": "medium",
                    "description": "Commit uncommitted changes to git",
                }
            )
        elif not git_results.get("git_repo", False):
            tasks.append(
                {
                    "id": self._get_next_task_id(),
                    "title": "Initialize git repository",
                    "assigned_to": "git-worker",
                    "status": "todo",
                    "priority": "low",
                    "description": "Initialize git repository for version control",
                }
            )

        return tasks

    def _generate_dependency_tasks(
        self, audit_results: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        
        tasks = []

        dep_results = audit_results.get("dependencies", {})
        if not dep_results.get("has_requirements", False):
            tasks.append(
                {
                    "id": self._get_next_task_id(),
                    "title": "Create dependency specification",
                    "assigned_to": "config-worker",
                    "status": "todo",
                    "priority": "medium",
                    "description": "Create requirements.txt or pyproject.toml for dependencies",
                }
            )

        return tasks

    def _generate_structure_tasks(
        self, audit_results: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        
        tasks = []

        structure = audit_results.get("file_structure", {})

        if structure.get("python_files", 0) == 0:
            tasks.append(
                {
                    "id": self._get_next_task_id(),
                    "title": "Create project structure",
                    "assigned_to": "structure-worker",
                    "status": "todo",
                    "priority": "high",
                    "description": "Set up basic project structure with Python files",
                }
            )

        if structure.get("test_files", 0) == 0:
            tasks.append(
                {
                    "id": self._get_next_task_id(),
                    "title": "Create test directory structure",
                    "assigned_to": "test-worker",
                    "status": "todo",
                    "priority": "medium",
                    "description": "Set up test directory and initial test files",
                }
            )

        return tasks

    def _get_next_task_id(self) -> int:
        
        checklist = self.checklist_manager.get_checklist()
        if not checklist.tasks:
            return 1
        return max(task.id for task in checklist.tasks) + 1

    def _add_tasks_to_checklist(self, new_tasks: List[Dict[str, Any]]):
        
        for task_data in new_tasks:
            task = Task(
                id=task_data["id"],
                title=task_data["title"],
                assigned_to=task_data["assigned_to"],
                status=task_data["status"],
            )
            self.checklist_manager.add_task(task)

    def get_feedback_summary(self, audit_results: Dict[str, Any]) -> Dict[str, Any]:
        
        new_tasks = self.process_audit_feedback(audit_results)

        return {
            "audit_passed": audit_results.get("audit_passed", False),
            "new_tasks_generated": len(new_tasks),
            "tasks_by_category": self._categorize_tasks(new_tasks),
            "next_steps": self._get_next_steps(new_tasks),
        }

    def _categorize_tasks(self, tasks: List[Dict[str, Any]]) -> Dict[str, int]:
        
        categories = {}
        for task in tasks:
            category = task.get("assigned_to", "unknown").split("-")[0]
            categories[category] = categories.get(category, 0) + 1
        return categories

    def _get_next_steps(self, tasks: List[Dict[str, Any]]) -> List[str]:
        
        if not tasks:
            return ["All tasks completed successfully!"]

        steps = []
        high_priority = [t for t in tasks if t.get("priority") == "high"]

        if high_priority:
            steps.append(f"Address {len(high_priority)} high priority tasks first")

        steps.append("Run multi-agent workflow to process new tasks")
        steps.append("Re-run audit after completing new tasks")

        return steps


def process_audit_feedback(
    audit_results: Dict[str, Any], project_root: str = "."
) -> List[Dict[str, Any]]:
    
    generator = NewTasksGenerator(project_root)
    return generator.process_audit_feedback(audit_results)


def get_feedback_summary(
    audit_results: Dict[str, Any], project_root: str = "."
) -> Dict[str, Any]:
    
    generator = NewTasksGenerator(project_root)
    return generator.get_feedback_summary(audit_results)


===== src/audit/audit_phase.py =====
import json
import subprocess
from typing import Dict, Any, List, Optional
from pathlib import Path
import os

from src.core.project_checklist import get_checklist_manager
from src.config.model_config import get_config_manager


class AuditPhase:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.checklist_manager = get_checklist_manager(str(project_root))

    def run_audit(self) -> Dict[str, Any]:
        
        if not self.checklist_manager.all_tasks_completed():
            return {
                "status": "incomplete",
                "message": "Cannot run audit: not all tasks are completed",
                "pending_tasks": len(self.checklist_manager.get_pending_tasks()),
            }

        audit_results = {
            "status": "audit_started",
            "timestamp": self._get_timestamp(),
            "project_root": str(self.project_root),
            "checklist": self._audit_checklist(),
            "git_status": self._audit_git_status(),
            "file_structure": self._audit_file_structure(),
            "tests": self._audit_tests(),
            "linting": self._audit_linting(),
            "dependencies": self._audit_dependencies(),
        }

        audit_passed = all(
            [
                audit_results["tests"]["passed"],
                audit_results["linting"]["passed"],
                audit_results["git_status"]["clean"],
            ]
        )

        audit_results["audit_passed"] = audit_passed

        if not audit_passed:
            audit_results["new_tasks"] = self._generate_new_tasks(audit_results)

        self._save_audit_results(audit_results)

        return audit_results

    def _get_timestamp(self) -> str:
        
        from datetime import datetime

        return datetime.now().isoformat()

    def _audit_checklist(self) -> Dict[str, Any]:
        
        checklist = self.checklist_manager.get_checklist()
        return {
            "total_tasks": len(checklist.tasks),
            "completed_tasks": len(self.checklist_manager.get_completed_tasks()),
            "workers_defined": len(checklist.workers_spec),
            "checklist_valid": len(checklist.tasks) > 0,
        }

    def _audit_git_status(self) -> Dict[str, Any]:
        
        try:
            result = subprocess.run(
                ["git", "rev-parse", "--git-dir"],
                capture_output=True,
                text=True,
                cwd=self.project_root,
            )

            if result.returncode != 0:
                return {
                    "git_repo": False,
                    "clean": False,
                    "message": "Not a git repository",
                }

            status_result = subprocess.run(
                ["git", "status", "--porcelain"],
                capture_output=True,
                text=True,
                cwd=self.project_root,
            )

            log_result = subprocess.run(
                ["git", "log", "--oneline", "-5"],
                capture_output=True,
                text=True,
                cwd=self.project_root,
            )

            return {
                "git_repo": True,
                "clean": len(status_result.stdout.strip()) == 0,
                "uncommitted_changes": status_result.stdout.strip().split("\n")
                if status_result.stdout.strip()
                else [],
                "recent_commits": log_result.stdout.strip().split("\n")
                if log_result.stdout.strip()
                else [],
            }

        except Exception as e:
            return {"git_repo": False, "clean": False, "error": str(e)}

    def _audit_file_structure(self) -> Dict[str, Any]:
        
        structure = {
            "total_files": 0,
            "python_files": 0,
            "config_files": 0,
            "test_files": 0,
            "directories": [],
        }

        try:
            for root, dirs, files in os.walk(self.project_root):
                dirs[:] = [
                    d
                    for d in dirs
                    if not d.startswith(".")
                    and d not in ["__pycache__", "node_modules"]
                ]

                rel_root = os.path.relpath(root, self.project_root)
                if rel_root != ".":
                    structure["directories"].append(rel_root)

                for file in files:
                    if not file.startswith("."):
                        structure["total_files"] += 1
                        if file.endswith(".py"):
                            structure["python_files"] += 1
                        elif file in ["requirements.txt", "setup.py", "pyproject.toml"]:
                            structure["config_files"] += 1
                        elif "test" in file.lower() and file.endswith(".py"):
                            structure["test_files"] += 1

            structure["directories"] = sorted(list(set(structure["directories"])))

        except Exception as e:
            structure["error"] = str(e)

        return structure

    def _audit_tests(self) -> Dict[str, Any]:
        
        test_files = list(self.project_root.rglob("test_*.py"))
        test_files.extend(list(self.project_root.rglob("*_test.py")))

        if not test_files:
            return {
                "passed": True,
                "command": None,
                "output": "No test files found - audit passed",
                "tests_found": False,
                "test_files": [],
                "test_results": [],
            }

        test_commands = [
            ["python", "-m", "pytest", "-v"],
            ["python", "-m", "unittest", "discover", "-v"],
        ]

        for cmd in test_commands:
            try:
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    cwd=self.project_root,
                    timeout=60,
                )

                return {
                    "passed": result.returncode == 0,
                    "command": " ".join(cmd),
                    "output": result.stdout + result.stderr,
                    "tests_found": True,
                    "test_files": [
                        str(f.relative_to(self.project_root)) for f in test_files
                    ],
                    "test_results": self._parse_test_output(
                        result.stdout, result.returncode
                    ),
                }

            except subprocess.TimeoutExpired:
                continue
            except FileNotFoundError:
                continue
            except Exception as e:
                return {
                    "passed": False,
                    "command": " ".join(cmd),
                    "output": f"Error running tests: {str(e)}",
                    "tests_found": True,
                    "test_files": [
                        str(f.relative_to(self.project_root)) for f in test_files
                    ],
                    "test_results": [],
                }

        return {
            "passed": False,
            "command": None,
            "output": "No test runner found (pytest/unittest)",
            "tests_found": True,
            "test_files": [str(f.relative_to(self.project_root)) for f in test_files],
            "test_results": [],
        }

    def _audit_linting(self) -> Dict[str, Any]:
        
        python_files = list(self.project_root.rglob("*.py"))

        issues = []
        total_files = 0

        for py_file in python_files:
            if py_file.name.startswith(".") or "__pycache__" in str(py_file):
                continue

            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    content = f.read()
                    lines = content.split("\n")

                    total_files += 1

                    for i, line in enumerate(lines, 1):
                        if len(line) > 120:
                            issues.append(
                                f"{py_file.relative_to(self.project_root)}:{i}: Line too long ({len(line)} chars)"
                            )

                        if line.rstrip() != line:
                            issues.append(
                                f"{py_file.relative_to(self.project_root)}:{i}: Trailing whitespace"
                            )

                        if "\t" in line:
                            issues.append(
                                f"{py_file.relative_to(self.project_root)}:{i}: Uses tabs instead of spaces"
                            )

            except Exception as e:
                issues.append(
                    f"{py_file.relative_to(self.project_root)}: Error reading file: {str(e)}"
                )

        return {
            "passed": len(issues) == 0,
            "command": "manual_analysis",
            "output": f"Analyzed {total_files} Python files. Found {len(issues)} issues.\n"
            + "\n".join(issues[:20]),
            "total_files": total_files,
            "issues": issues,
        }

    def _audit_dependencies(self) -> Dict[str, Any]:
        
        dependency_files = ["requirements.txt", "setup.py", "pyproject.toml", "Pipfile"]

        found_files = []
        for dep_file in dependency_files:
            file_path = self.project_root / dep_file
            if file_path.exists():
                found_files.append(dep_file)

        return {
            "dependency_files": found_files,
            "has_requirements": len(found_files) > 0,
        }

    def _generate_new_tasks(
        self, audit_results: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        
        new_tasks = []

        if not audit_results["tests"]["passed"]:
            new_tasks.append(
                {
                    "id": 1000 + len(new_tasks),
                    "title": "Fix failing tests",
                    "assigned_to": "test-worker",
                    "status": "todo",
                }
            )

        if not audit_results["linting"]["passed"]:
            new_tasks.append(
                {
                    "id": 1000 + len(new_tasks),
                    "title": "Fix linting issues",
                    "assigned_to": "lint-worker",
                    "status": "todo",
                }
            )

        if not audit_results["git_status"]["clean"]:
            new_tasks.append(
                {
                    "id": 1000 + len(new_tasks),
                    "title": "Commit uncommitted changes",
                    "assigned_to": "git-worker",
                    "status": "todo",
                }
            )

        return new_tasks

    def _parse_test_output(self, output: str, returncode: int) -> List[Dict[str, Any]]:
        
        results = []
        lines = output.split("\n")

        for line in lines:
            line = line.strip()
            if line.startswith("test_") and ("... ok" in line or "... FAIL" in line):
                test_name = line.split("...")[0].strip()
                status = "pass" if "... ok" in line else "fail"
                results.append({"test": test_name, "status": status, "message": line})
            elif "FAILED" in line.upper() or "ERROR" in line.upper():
                results.append({"test": "general", "status": "fail", "message": line})
            elif "PASSED" in line.upper():
                results.append({"test": "general", "status": "pass", "message": line})

        return results

    def _save_audit_results(self, results: Dict[str, Any]):
        
        audit_file = self.project_root / "AUDIT_RESULTS.json"
        with open(audit_file, "w") as f:
            json.dump(results, f, indent=2)


def run_audit(project_root: str = ".") -> Dict[str, Any]:
    
    auditor = AuditPhase(project_root)
    return auditor.run_audit()


===== src/persistence/config_store.py =====
import json
import os
from pathlib import Path
from typing import Any, Dict


class ConfigStore:
    def __init__(self, base_dir: str = None):
        if base_dir is None:
            base_dir = os.path.expanduser("~/.equitrcoder")
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(exist_ok=True)

    def save(self, key: str, value: Any):
        file_path = self.base_dir / f"{key}.json"
        with open(file_path, "w") as f:
            json.dump(value, f, indent=2)

    def load(self, key: str, default: Any = None) -> Any:
        file_path = self.base_dir / f"{key}.json"
        if file_path.exists():
            try:
                with open(file_path, "r") as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError):
                pass
        return default

    def delete(self, key: str):
        file_path = self.base_dir / f"{key}.json"
        if file_path.exists():
            file_path.unlink()

    def exists(self, key: str) -> bool:
        return (self.base_dir / f"{key}.json").exists()

    def list_keys(self) -> list:
        return [f.stem for f in self.base_dir.glob("*.json")]


===== src/api/model_api.py =====
from typing import List, Optional, Dict, Any
from src.config.model_config import get_config_manager, ModelConfig


class ModelSelector:
    def __init__(self):
        self.config_manager = get_config_manager()

    def configure_single_model(self, model: str):
        
        available = self.config_manager.get_available_models()
        if model not in available:
            raise ValueError(f"Model '{model}' not available. Available: {available}")

        self.config_manager.set_mode("single")
        self.config_manager.set_models(model)

    def configure_multi_model(self, primary: str, secondary: str):
        
        available = self.config_manager.get_available_models()

        if primary not in available:
            raise ValueError(
                f"Primary model '{primary}' not available. Available: {available}"
            )
        if secondary not in available:
            raise ValueError(
                f"Secondary model '{secondary}' not available. Available: {available}"
            )

        self.config_manager.set_mode("multi")
        self.config_manager.set_models(primary, secondary)

    def get_current_config(self) -> Dict[str, Any]:
        
        config = self.config_manager.get_config()
        return {
            "mode": config.mode,
            "primary_model": config.primary_model,
            "secondary_model": config.secondary_model,
            "active_models": config.models,
        }

    def get_available_models(self) -> List[str]:
        
        return self.config_manager.get_available_models()

    def is_multi_mode(self) -> bool:
        
        return self.config_manager.is_multi_mode()

    def get_active_models(self) -> List[str]:
        
        return self.config_manager.get_active_models()

    def reset_to_defaults(self):
        
        from src.config.model_config import ModelConfig

        self.config_manager.save_config(ModelConfig())


class ModelContext:
    def __init__(self):
        self.selector = ModelSelector()

    def __enter__(self):
        return self.selector

    def __exit__(self, exc_type, exc_val, exc_tb):
        pass


def configure_models(**kwargs):
    
    selector = ModelSelector()

    if "single" in kwargs:
        selector.configure_single_model(kwargs["single"])
    elif "primary" in kwargs and "secondary" in kwargs:
        selector.configure_multi_model(kwargs["primary"], kwargs["secondary"])
    elif "mode" in kwargs:
        selector.config_manager.set_mode(kwargs["mode"])

    return selector.get_current_config()


_model_selector = None


def get_model_selector() -> ModelSelector:
    global _model_selector
    if _model_selector is None:
        _model_selector = ModelSelector()
    return _model_selector


===== src/orchestrator/multi_agent_orchestrator.py =====
import asyncio
import json
from typing import List, Dict, Any, Optional
from pathlib import Path
import importlib.util
import sys
from concurrent.futures import ThreadPoolExecutor

from src.core.project_checklist import get_checklist_manager, WorkerSpec, Task
from src.tools.ask_supervisor import create_ask_supervisor_tool
from src.config.model_config import get_config_manager
from src.audit.audit_phase import run_audit


class WorkerAgent:
    def __init__(self, spec: WorkerSpec, project_root: str = "."):
        self.spec = spec
        self.project_root = Path(project_root)
        self.ask_supervisor = create_ask_supervisor_tool()
        self.allowed_files = set()
        self._setup_file_access()

    def _setup_file_access(self):
        
        for scope_path in self.spec.scope_paths:
            full_path = self.project_root / scope_path
            if full_path.is_file():
                self.allowed_files.add(full_path.resolve())
            elif full_path.is_dir():
                for file_path in full_path.rglob("*"):
                    if file_path.is_file():
                        self.allowed_files.add(file_path.resolve())

    def can_access_file(self, file_path: str) -> bool:
        
        resolved_path = Path(file_path).resolve()
        return resolved_path in self.allowed_files

    def can_use_tool(self, tool_name: str) -> bool:
        
        return tool_name in self.spec.allowed_tools

    async def execute_task(self, task: Task) -> Dict[str, Any]:
        
        if task.assigned_to != self.spec.id:
            return {"error": f"Task {task.id} not assigned to this worker"}

        worker_env = {
            "__builtins__": __builtins__,
            "ask_supervisor": self.ask_supervisor,
            "project_root": str(self.project_root),
            "worker_id": self.spec.id,
            "task_id": task.id,
            "task_title": task.title,
        }

        try:
            result = await self._execute_task_logic(task, worker_env)
            return {"success": True, "result": result}
        except Exception as e:
            return {"error": str(e), "worker_id": self.spec.id, "task_id": task.id}

    async def _execute_task_logic(self, task: Task, env: Dict[str, Any]) -> Any:
        
        return f"Task {task.id} executed by {self.spec.id}"


class MultiAgentOrchestrator:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.checklist_manager = get_checklist_manager(str(project_root))
        self.workers: Dict[str, WorkerAgent] = {}
        self.executor = ThreadPoolExecutor(max_workers=10)

    def initialize_workers(self):
        
        checklist = self.checklist_manager.get_checklist()

        for worker_spec in checklist.workers_spec:
            if worker_spec.id not in self.workers:
                self.workers[worker_spec.id] = WorkerAgent(
                    worker_spec, str(self.project_root)
                )

    async def run_tasks(self) -> Dict[str, Any]:
        
        self.initialize_workers()

        pending_tasks = self.checklist_manager.get_pending_tasks()
        if not pending_tasks:
            return {"message": "No pending tasks", "tasks_completed": 0}

        results = []

        for task in pending_tasks:
            worker = self.workers.get(task.assigned_to)
            if not worker:
                results.append(
                    {
                        "task_id": task.id,
                        "error": f"No worker found for task assignment: {task.assigned_to}",
                    }
                )
                continue

            self.checklist_manager.update_task_status(task.id, "in_progress")

            result = await worker.execute_task(task)

            if "success" in result:
                self.checklist_manager.update_task_status(task.id, "done")
            else:
                self.checklist_manager.update_task_status(task.id, "todo")

            results.append(
                {"task_id": task.id, "worker_id": task.assigned_to, **result}
            )

        completed_count = len([r for r in results if "success" in r])
        failed_count = len([r for r in results if "error" in r])

        audit_result = None
        if self.checklist_manager.all_tasks_completed() and completed_count > 0:
            print("\nüéØ All tasks completed! Running automatic audit...")
            audit_result = run_audit(str(self.project_root))

        return {
            "tasks_completed": completed_count,
            "tasks_failed": failed_count,
            "results": results,
            "audit_result": audit_result,
        }

    def get_worker_status(self) -> Dict[str, Any]:
        
        return {
            worker_id: {
                "spec": asdict(worker.spec),
                "allowed_files": len(worker.allowed_files),
                "allowed_tools": worker.spec.allowed_tools,
            }
            for worker_id, worker in self.workers.items()
        }

    def get_task_status(self) -> Dict[str, Any]:
        
        return {
            "pending": len(self.checklist_manager.get_pending_tasks()),
            "in_progress": len(self.checklist_manager.get_in_progress_tasks()),
            "completed": len(self.checklist_manager.get_completed_tasks()),
            "total": len(self.checklist_manager.get_checklist().tasks),
        }


_orchestrator = None


def get_orchestrator(project_root: str = ".") -> MultiAgentOrchestrator:
    global _orchestrator
    if _orchestrator is None:
        _orchestrator = MultiAgentOrchestrator(project_root)
    return _orchestrator


async def run_multi_agent_workflow(project_root: str = ".") -> Dict[str, Any]:
    
    orchestrator = get_orchestrator(project_root)
    return await orchestrator.run_tasks()


